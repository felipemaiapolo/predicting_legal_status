{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning classifiers (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run -i 'random_state.py'\n",
    "from packages import *\n",
    "from clean_functions import *\n",
    "from tokenizer import *\n",
    "from tuners import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyper_lstm = {'neurons': [10, 25, 50, 75, 100, 150, 200], #hidden LSTM\n",
    "             'lamb1': [.0, 10**-6, 5*10**-6, 10**-5, 5*10**-5, 10**-4, 5*10**-4, 10**-3, 5*10**-3], #regularization\n",
    "             'lamb2': [.0, 10**-6, 5*10**-6, 10**-5, 5*10**-5, 10**-4, 5*10**-4, 10**-3, 5*10**-3],\n",
    "             'score': [0], \n",
    "             'lower_ci': [0], \n",
    "             'upper_ci': [0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V/CNN/LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y=np.load('data/X_w2v.npy'),np.load('data/y_w2v.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning y into numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode={'H:Arquivado': 1,'H:Ativo': 2,'H:Suspenso': 3}\n",
    "decode={1:'H:Arquivado',2:'H:Ativo',3:'H:Suspenso'}\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y[i]=encode[y[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset in train, test and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4514, 5, 70, 100), (4514,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=2/3, random_state=random_seed)\n",
    "\n",
    "y_train2=np.array(pd.get_dummies(y_train))\n",
    "y_val2=np.array(pd.get_dummies(y_val))\n",
    "y_test2=np.array(pd.get_dummies(y_test))\n",
    "\n",
    "np.shape(X_train),np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper = {'ks': [3,6,9], #kernels\n",
    "         'neurons': [10, 25, 50, 75, 100, 150, 200],\n",
    "         'lamb1': [.0, 10**-6, 5*10**-6, 10**-5, 5*10**-5, 10**-4, 5*10**-4, 10**-3, 5*10**-3], #regularization\n",
    "         'lamb2': [.0, 10**-6, 5*10**-6, 10**-5, 5*10**-5, 10**-4, 5*10**-4, 10**-3, 5*10**-3],       \n",
    "         'score': [0], \n",
    "         'lower_ci': [0], \n",
    "         'upper_ci': [0]}\n",
    "\n",
    "hyper=expand_grid(hyper.copy(), random_seed=random_seed)\n",
    "hyper=hyper[['ks','neurons','lamb1','lamb2','score','lower_ci','upper_ci']]\n",
    "\n",
    "np.shape(hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [27:38<00:00, 33.17s/it]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "Adam=optimizers.Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "    \n",
    "for i in tqdm(range(hyper.shape[0])):\n",
    "    \n",
    "    #Cleaning session\n",
    "    tensorflow.keras.backend.clear_session()\n",
    "    \n",
    "    #Hyper\n",
    "    k=hyper.loc[i,'ks'] \n",
    "    neuron=hyper.loc[i,'neurons'] \n",
    "    lamb1=hyper.loc[i,'lamb1'] \n",
    "    lamb2=hyper.loc[i,'lamb2'] \n",
    "\n",
    "    #Model for features extraction\n",
    "    inputs = Input(shape=np.shape(X_train)[1:])\n",
    "    conv = TimeDistributed(Conv1D(k, 1, activation='linear', kernel_constraint=unit_norm(axis=1), use_bias=False))(inputs)\n",
    "    pool = TimeDistributed(GlobalMaxPooling1D())(conv)\n",
    "    model_feat = Model(inputs, pool)\n",
    "\n",
    "    #Model for classification\n",
    "    pooled_inputs = Input(shape=(5, k))\n",
    "    lstm = LSTM(neuron, kernel_regularizer=regularizers.l1_l2(lamb1, lamb2))(pooled_inputs)\n",
    "    soft = Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l1_l2(lamb1, lamb2))(lstm)\n",
    "    model_classific = Model(pooled_inputs, soft)\n",
    "\n",
    "    #Final model\n",
    "    outputs = model_classific(model_feat(inputs))\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    #Compiling\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam, metrics=['accuracy'])\n",
    "\n",
    "    #Running\n",
    "    modelo=model.fit(X_train, y_train2, epochs=50,\n",
    "                                              batch_size=500,\n",
    "                                              shuffle=True,\n",
    "                                              verbose=False,\n",
    "                                              validation_data=(X_val, y_val2))\n",
    "    \n",
    "    p=modelo.history['val_accuracy'][-1]\n",
    "    hyper.loc[i,'score']=p\n",
    "    hyper.loc[i,'lower_ci']=p-1.96*np.sqrt((p*(1-p)/np.shape(y_val)[0]))\n",
    "    hyper.loc[i,'upper_ci']=p+1.96*np.sqrt((p*(1-p)/np.shape(y_val)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyper.to_csv('hyper/hyper_lstm_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ks</th>\n",
       "      <th>neurons</th>\n",
       "      <th>lamb1</th>\n",
       "      <th>lamb2</th>\n",
       "      <th>score</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.925581</td>\n",
       "      <td>0.905327</td>\n",
       "      <td>0.945836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.927132</td>\n",
       "      <td>0.907072</td>\n",
       "      <td>0.947191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.927132</td>\n",
       "      <td>0.907072</td>\n",
       "      <td>0.947191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.928682</td>\n",
       "      <td>0.908821</td>\n",
       "      <td>0.948544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.928682</td>\n",
       "      <td>0.908821</td>\n",
       "      <td>0.948544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.928682</td>\n",
       "      <td>0.908821</td>\n",
       "      <td>0.948544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>9</td>\n",
       "      <td>75</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.928682</td>\n",
       "      <td>0.908821</td>\n",
       "      <td>0.948544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9</td>\n",
       "      <td>75</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.931783</td>\n",
       "      <td>0.912326</td>\n",
       "      <td>0.951240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.914083</td>\n",
       "      <td>0.952584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.914083</td>\n",
       "      <td>0.952584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.914083</td>\n",
       "      <td>0.952584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.914083</td>\n",
       "      <td>0.952584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.934884</td>\n",
       "      <td>0.915842</td>\n",
       "      <td>0.953925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.934884</td>\n",
       "      <td>0.915842</td>\n",
       "      <td>0.953925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.936434</td>\n",
       "      <td>0.917605</td>\n",
       "      <td>0.955263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>75</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.937984</td>\n",
       "      <td>0.919371</td>\n",
       "      <td>0.956598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.941085</td>\n",
       "      <td>0.922913</td>\n",
       "      <td>0.959257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.941085</td>\n",
       "      <td>0.922913</td>\n",
       "      <td>0.959257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.944186</td>\n",
       "      <td>0.926470</td>\n",
       "      <td>0.961902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.945736</td>\n",
       "      <td>0.928253</td>\n",
       "      <td>0.963219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ks  neurons     lamb1     lamb2     score  lower_ci  upper_ci\n",
       "32   9      100  0.000010  0.000050  0.925581  0.905327  0.945836\n",
       "3    6       25  0.000000  0.000100  0.927132  0.907072  0.947191\n",
       "20   6       10  0.000050  0.000005  0.927132  0.907072  0.947191\n",
       "8    9       10  0.005000  0.000001  0.928682  0.908821  0.948544\n",
       "44   3      100  0.000000  0.000100  0.928682  0.908821  0.948544\n",
       "49   3      200  0.000100  0.001000  0.928682  0.908821  0.948544\n",
       "48   9       75  0.000500  0.000500  0.928682  0.908821  0.948544\n",
       "37   9       75  0.005000  0.000010  0.931783  0.912326  0.951240\n",
       "33   3      100  0.000005  0.000000  0.933333  0.914083  0.952584\n",
       "13   3       10  0.000500  0.000010  0.933333  0.914083  0.952584\n",
       "25   6       25  0.000050  0.000001  0.933333  0.914083  0.952584\n",
       "1    6      100  0.000001  0.000000  0.933333  0.914083  0.952584\n",
       "38   3       10  0.000500  0.000500  0.934884  0.915842  0.953925\n",
       "26   6      100  0.000005  0.001000  0.934884  0.915842  0.953925\n",
       "41   6       50  0.001000  0.000005  0.936434  0.917605  0.955263\n",
       "14   9       75  0.000010  0.000500  0.937984  0.919371  0.956598\n",
       "28   6       25  0.000500  0.000050  0.941085  0.922913  0.959257\n",
       "18   3       25  0.000005  0.000010  0.941085  0.922913  0.959257\n",
       "43   6       50  0.000005  0.000500  0.944186  0.926470  0.961902\n",
       "9    9      100  0.000500  0.000100  0.945736  0.928253  0.963219"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper.iloc[np.argsort(hyper.loc[:,'score']),:].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT/LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = np.load('data/X_bert.npy'),np.load('data/y_bert.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning y into numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode={'H:Arquivado': 1,'H:Ativo': 2,'H:Suspenso': 3}\n",
    "decode={1:'H:Arquivado',2:'H:Ativo',3:'H:Suspenso'}\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y[i]=encode[y[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset in train, test and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4514, 5, 768), (4514,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=2/3, random_state=random_seed)\n",
    "\n",
    "y_train2=np.array(pd.get_dummies(y_train))\n",
    "y_val2=np.array(pd.get_dummies(y_val))\n",
    "y_test2=np.array(pd.get_dummies(y_test))\n",
    "\n",
    "np.shape(X_train),np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper=expand_grid(hyper_lstm.copy(), random_seed=random_seed)\n",
    "hyper=hyper[['neurons','lamb1','lamb2','score','lower_ci','upper_ci']]\n",
    "\n",
    "np.shape(hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:52<00:00, 13.05s/it]\n"
     ]
    }
   ],
   "source": [
    "hyper=tune_lstm(hyper, X_train, y_train2, X_val, y_val2)\n",
    "hyper.to_csv('hyper/hyper_lstm_bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neurons</th>\n",
       "      <th>lamb1</th>\n",
       "      <th>lamb2</th>\n",
       "      <th>score</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.920930</td>\n",
       "      <td>0.900105</td>\n",
       "      <td>0.941756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.920930</td>\n",
       "      <td>0.900105</td>\n",
       "      <td>0.941756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.901843</td>\n",
       "      <td>0.943118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.901843</td>\n",
       "      <td>0.943118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.924031</td>\n",
       "      <td>0.903584</td>\n",
       "      <td>0.944478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.925581</td>\n",
       "      <td>0.905327</td>\n",
       "      <td>0.945836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.925581</td>\n",
       "      <td>0.905327</td>\n",
       "      <td>0.945836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.928682</td>\n",
       "      <td>0.908821</td>\n",
       "      <td>0.948544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.928682</td>\n",
       "      <td>0.908821</td>\n",
       "      <td>0.948544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.928682</td>\n",
       "      <td>0.908821</td>\n",
       "      <td>0.948544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.928682</td>\n",
       "      <td>0.908821</td>\n",
       "      <td>0.948544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.910572</td>\n",
       "      <td>0.949893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.931783</td>\n",
       "      <td>0.912326</td>\n",
       "      <td>0.951240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.931783</td>\n",
       "      <td>0.912326</td>\n",
       "      <td>0.951240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.914083</td>\n",
       "      <td>0.952584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.914083</td>\n",
       "      <td>0.952584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.914083</td>\n",
       "      <td>0.952584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.934884</td>\n",
       "      <td>0.915842</td>\n",
       "      <td>0.953925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.934884</td>\n",
       "      <td>0.915842</td>\n",
       "      <td>0.953925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.941085</td>\n",
       "      <td>0.922913</td>\n",
       "      <td>0.959257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neurons     lamb1     lamb2     score  lower_ci  upper_ci\n",
       "36      200  0.000000  0.000050  0.920930  0.900105  0.941756\n",
       "13      200  0.000100  0.000001  0.920930  0.900105  0.941756\n",
       "31       50  0.000050  0.000100  0.922481  0.901843  0.943118\n",
       "10       75  0.000000  0.000001  0.922481  0.901843  0.943118\n",
       "8        75  0.000005  0.000100  0.924031  0.903584  0.944478\n",
       "43      150  0.000000  0.000000  0.925581  0.905327  0.945836\n",
       "49      150  0.000001  0.000001  0.925581  0.905327  0.945836\n",
       "12       75  0.000001  0.000010  0.928682  0.908821  0.948544\n",
       "29       50  0.000001  0.000005  0.928682  0.908821  0.948544\n",
       "19       75  0.000050  0.000010  0.928682  0.908821  0.948544\n",
       "21       25  0.000050  0.000100  0.928682  0.908821  0.948544\n",
       "44       25  0.000010  0.000000  0.930233  0.910572  0.949893\n",
       "42      100  0.000010  0.000005  0.931783  0.912326  0.951240\n",
       "16       10  0.000005  0.000050  0.931783  0.912326  0.951240\n",
       "11       50  0.000000  0.000050  0.933333  0.914083  0.952584\n",
       "1        10  0.000010  0.000010  0.933333  0.914083  0.952584\n",
       "23      100  0.000010  0.000001  0.933333  0.914083  0.952584\n",
       "40       25  0.000010  0.000010  0.934884  0.915842  0.953925\n",
       "46      150  0.000005  0.000010  0.934884  0.915842  0.953925\n",
       "38       25  0.000005  0.000010  0.941085  0.922913  0.959257"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper.iloc[np.argsort(hyper.loc[:,'score']),:].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec/LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y=np.load('data/X_d2v.npy'),np.load('data/y_d2v.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning y into numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode={'H:Arquivado': 1,'H:Ativo': 2,'H:Suspenso': 3}\n",
    "decode={1:'H:Arquivado',2:'H:Ativo',3:'H:Suspenso'}\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y[i]=encode[y[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset in train, test and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4514, 5, 100), (4514,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=2/3, random_state=random_seed)\n",
    "\n",
    "y_train2=np.array(pd.get_dummies(y_train))\n",
    "y_val2=np.array(pd.get_dummies(y_val))\n",
    "y_test2=np.array(pd.get_dummies(y_test))\n",
    "\n",
    "np.shape(X_train),np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper=expand_grid(hyper_lstm.copy(), random_seed=random_seed)\n",
    "hyper=hyper[['neurons','lamb1','lamb2','score','lower_ci','upper_ci']]\n",
    "\n",
    "np.shape(hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:41<00:00,  8.04s/it]\n"
     ]
    }
   ],
   "source": [
    "hyper=tune_lstm(hyper, X_train, y_train2, X_val, y_val2)\n",
    "hyper.to_csv('hyper/hyper_lstm_d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neurons</th>\n",
       "      <th>lamb1</th>\n",
       "      <th>lamb2</th>\n",
       "      <th>score</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.812403</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>0.842531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.783921</td>\n",
       "      <td>0.843986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.815504</td>\n",
       "      <td>0.785569</td>\n",
       "      <td>0.845439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.815504</td>\n",
       "      <td>0.785569</td>\n",
       "      <td>0.845439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.817054</td>\n",
       "      <td>0.787217</td>\n",
       "      <td>0.846892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.818605</td>\n",
       "      <td>0.788866</td>\n",
       "      <td>0.848344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.818605</td>\n",
       "      <td>0.788866</td>\n",
       "      <td>0.848344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.820155</td>\n",
       "      <td>0.790515</td>\n",
       "      <td>0.849795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.820155</td>\n",
       "      <td>0.790515</td>\n",
       "      <td>0.849795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.792166</td>\n",
       "      <td>0.851245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.824806</td>\n",
       "      <td>0.795469</td>\n",
       "      <td>0.854143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.824806</td>\n",
       "      <td>0.795469</td>\n",
       "      <td>0.854143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.827907</td>\n",
       "      <td>0.798776</td>\n",
       "      <td>0.857038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.832558</td>\n",
       "      <td>0.803743</td>\n",
       "      <td>0.861373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.832558</td>\n",
       "      <td>0.803743</td>\n",
       "      <td>0.861373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.835659</td>\n",
       "      <td>0.807059</td>\n",
       "      <td>0.864259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.808718</td>\n",
       "      <td>0.865700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.808718</td>\n",
       "      <td>0.865700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.846512</td>\n",
       "      <td>0.818693</td>\n",
       "      <td>0.874330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.857364</td>\n",
       "      <td>0.830376</td>\n",
       "      <td>0.884352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neurons     lamb1     lamb2     score  lower_ci  upper_ci\n",
       "21       25  0.000050  0.000100  0.812403  0.782275  0.842531\n",
       "48       50  0.000500  0.000500  0.813953  0.783921  0.843986\n",
       "38       25  0.000005  0.000010  0.815504  0.785569  0.845439\n",
       "9        10  0.000500  0.000100  0.815504  0.785569  0.845439\n",
       "0        25  0.000050  0.000500  0.817054  0.787217  0.846892\n",
       "26       50  0.000500  0.000010  0.818605  0.788866  0.848344\n",
       "16       10  0.000005  0.000050  0.818605  0.788866  0.848344\n",
       "18       25  0.001000  0.000050  0.820155  0.790515  0.849795\n",
       "31       50  0.000050  0.000100  0.820155  0.790515  0.849795\n",
       "47      100  0.001000  0.001000  0.821705  0.792166  0.851245\n",
       "23      100  0.000010  0.000001  0.824806  0.795469  0.854143\n",
       "24       10  0.000010  0.000001  0.824806  0.795469  0.854143\n",
       "44       25  0.000010  0.000000  0.827907  0.798776  0.857038\n",
       "35      150  0.000100  0.000500  0.832558  0.803743  0.861373\n",
       "20       10  0.000000  0.000005  0.832558  0.803743  0.861373\n",
       "30       10  0.000100  0.000001  0.835659  0.807059  0.864259\n",
       "5       200  0.000100  0.000010  0.837209  0.808718  0.865700\n",
       "1        10  0.000010  0.000010  0.837209  0.808718  0.865700\n",
       "40       25  0.000010  0.000010  0.846512  0.818693  0.874330\n",
       "37       25  0.000100  0.000001  0.857364  0.830376  0.884352"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper.iloc[np.argsort(hyper.loc[:,'score']),:].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF/LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y=np.load('data/X_tfidf.npy'),np.load('data/y_tfidf.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning y into numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode={'H:Arquivado': 1,'H:Ativo': 2,'H:Suspenso': 3}\n",
    "decode={1:'H:Arquivado',2:'H:Ativo',3:'H:Suspenso'}\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y[i]=encode[y[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset in train, test and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4514, 5, 4000), (4514,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=2/3, random_state=random_seed)\n",
    "\n",
    "y_train2=np.array(pd.get_dummies(y_train))\n",
    "y_val2=np.array(pd.get_dummies(y_val))\n",
    "y_test2=np.array(pd.get_dummies(y_test))\n",
    "\n",
    "np.shape(X_train),np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper=expand_grid(hyper_lstm.copy(), random_seed=random_seed)\n",
    "hyper=hyper[['neurons','lamb1','lamb2','score','lower_ci','upper_ci']]\n",
    "\n",
    "np.shape(hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [37:56<00:00, 45.52s/it]\n"
     ]
    }
   ],
   "source": [
    "hyper=tune_lstm(hyper, X_train, y_train2, X_val, y_val2)\n",
    "hyper.to_csv('hyper/hyper_lstm_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neurons</th>\n",
       "      <th>lamb1</th>\n",
       "      <th>lamb2</th>\n",
       "      <th>score</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.902326</td>\n",
       "      <td>0.879414</td>\n",
       "      <td>0.925237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.902326</td>\n",
       "      <td>0.879414</td>\n",
       "      <td>0.925237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.902326</td>\n",
       "      <td>0.879414</td>\n",
       "      <td>0.925237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.903876</td>\n",
       "      <td>0.881128</td>\n",
       "      <td>0.926624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.903876</td>\n",
       "      <td>0.881128</td>\n",
       "      <td>0.926624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.903876</td>\n",
       "      <td>0.881128</td>\n",
       "      <td>0.926624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.905426</td>\n",
       "      <td>0.882843</td>\n",
       "      <td>0.928010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.905426</td>\n",
       "      <td>0.882843</td>\n",
       "      <td>0.928010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.884560</td>\n",
       "      <td>0.929393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.884560</td>\n",
       "      <td>0.929393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.908527</td>\n",
       "      <td>0.886279</td>\n",
       "      <td>0.930775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.908527</td>\n",
       "      <td>0.886279</td>\n",
       "      <td>0.930775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.911628</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.933533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.911628</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.933533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>150</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.911628</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.933533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>150</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913178</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.934909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.893175</td>\n",
       "      <td>0.936282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.896635</td>\n",
       "      <td>0.939024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.920930</td>\n",
       "      <td>0.900105</td>\n",
       "      <td>0.941756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>150</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.924031</td>\n",
       "      <td>0.903584</td>\n",
       "      <td>0.944478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neurons     lamb1     lamb2     score  lower_ci  upper_ci\n",
       "21       25  0.000050  0.000100  0.902326  0.879414  0.925237\n",
       "20       10  0.000000  0.000005  0.902326  0.879414  0.925237\n",
       "16       10  0.000005  0.000050  0.902326  0.879414  0.925237\n",
       "45      100  0.000500  0.001000  0.903876  0.881128  0.926624\n",
       "17       50  0.000050  0.000050  0.903876  0.881128  0.926624\n",
       "9        10  0.000500  0.000100  0.903876  0.881128  0.926624\n",
       "1        10  0.000010  0.000010  0.905426  0.882843  0.928010\n",
       "42      100  0.000010  0.000005  0.905426  0.882843  0.928010\n",
       "23      100  0.000010  0.000001  0.906977  0.884560  0.929393\n",
       "26       50  0.000500  0.000010  0.906977  0.884560  0.929393\n",
       "39       75  0.000001  0.000005  0.908527  0.886279  0.930775\n",
       "33       50  0.001000  0.000010  0.908527  0.886279  0.930775\n",
       "6        75  0.001000  0.000000  0.911628  0.889723  0.933533\n",
       "49      150  0.000001  0.000001  0.911628  0.889723  0.933533\n",
       "41      150  0.005000  0.000500  0.911628  0.889723  0.933533\n",
       "7       150  0.005000  0.000000  0.913178  0.891448  0.934909\n",
       "46      150  0.000005  0.000010  0.914729  0.893175  0.936282\n",
       "47      100  0.001000  0.001000  0.917829  0.896635  0.939024\n",
       "18       25  0.001000  0.000050  0.920930  0.900105  0.941756\n",
       "25      150  0.001000  0.000500  0.924031  0.903584  0.944478"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper.iloc[np.argsort(hyper.loc[:,'score']),:].tail(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
