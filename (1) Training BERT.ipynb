{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert fine tuning\n",
    "\n",
    "This notebook was runned before we started to write the paper. Then, the directory names might not correspond to their current names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "kD140sFjh0LQ",
    "outputId": "0bab1f9e-bf7a-4f13-82d3-07fe5866ce78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 25 21:24:43 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# Check that we have a GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VNZZs-r6iKAV",
    "outputId": "c8404d6c-7662-4240-c8da-ee89edfaf51b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run -i 'random_state.py'\n",
    "from packages import *\n",
    "from clean_functions import *\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading NeuralMind's model for Portuguese (https://github.com/neuralmind-ai/portuguese-bert):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BzMqR-dzF4Ro"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('model_bert_neuralmind/vocab.txt', do_lower_case=False)\n",
    "bert_model = BertForMaskedLM.from_pretrained('model_bert_neuralmind/').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jU6JhBSTKiaM",
    "outputId": "35879a60-2915-4894-f702-2d649cfa398a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109545058"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.num_parameters()\n",
    "# => 108 million parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.63 s, sys: 964 ms, total: 8.59 s\n",
      "Wall time: 8.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(\"data/mov_treino.txt\", \"rb\") as fp:   # Unpickling\n",
    "    mov = pickle.load(fp)\n",
    "    \n",
    "max_len=512\n",
    "\n",
    "texts_mov=[]\n",
    "\n",
    "total=0\n",
    "\n",
    "for i in range(len(mov)): #\n",
    "    for j in range(len(mov[i])):\n",
    "        \n",
    "        t=clean_bert(mov[i][j][1])\n",
    "        total+=1\n",
    "        texts_mov.append(t) \n",
    "\n",
    "texts_mov=pd.Series(texts_mov)\n",
    "\n",
    "changed_text=pd.Series(texts_mov).apply(lambda x:x+\"\\n\"+\"\\n\")\n",
    "\n",
    "open('data/train_corpus.txt', \"w\").write(''.join(changed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "GlvP_A-THEEl",
    "outputId": "e0510a33-7937-4a04-fa1c-d4e20b758bb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 11s, sys: 3.68 s, total: 28min 15s\n",
      "Wall time: 28min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=bert_tokenizer,\n",
    "    file_path=\"data/train_corpus.txt\",\n",
    "    block_size=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDLs73HcIHk5"
   },
   "source": [
    "Like in the [`run_language_modeling.py`](https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_language_modeling.py) script, we need to define a data_collator.\n",
    "\n",
    "This is just a small helper that will help us batch different samples of the dataset together into an object that PyTorch knows how to perform backprop on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zTgWPa9Dipk2"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=bert_tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ri2BIQKqjfHm"
   },
   "source": [
    "### Finally, we are all set to initialize our Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YpvnFFmZJD-N"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./model_bert\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_gpu_train_batch_size=4,\n",
    "    save_steps=-1,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=bert_model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    "    prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6sASa36Nf-N"
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738,
     "referenced_widgets": [
      "a58a66392b644b1384661e850c077a6c",
      "a491e8caa0a048beb3b5259f14eb233f",
      "837c9ddc3d594e088891874560c646b8",
      "dbf50873d62c4ba39321faefbed0cca5",
      "40bf955ba0284e84b198da6be8654219",
      "fe20a8dae6e84628b5076d02183090f5",
      "93b3f9eae3cb4e3e859cf456e3547c6d",
      "6feb10aeb43147e6aba028d065947ae8",
      "0989d41a4da24e9ebff377e02127642c",
      "42c6061ef7e44f179db5a6e3551c0f17",
      "d295dd80550447d88da0f04ce36a22ff",
      "04e7e6d291da49d5816dc98a2904e95c",
      "e7d8c3a4fecd40778e32966b29ea65a1",
      "016d7c8318f742c1943464b08232a510",
      "8388e9da9da4492c98c19235ca5fc1b5",
      "39c23c6a972b419eb2eeeebafeaedc22"
     ]
    },
    "colab_type": "code",
    "id": "VmaHZXzmkNtJ",
    "outputId": "a19880cb-bcc6-4885-bf24-c2c6d0f56d1e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66b061c129443b3b096bfefeb1cabf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bce843c40b4ee08e731170ab47825f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=726059.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 4.996556753652252e-05, \"loss\": 1.946629903705325, \"step\": 500}\n",
      "{\"learning_rate\": 4.9931135073045034e-05, \"loss\": 1.5757096708603204, \"step\": 1000}\n",
      "{\"learning_rate\": 4.989670260956755e-05, \"loss\": 1.4144320277136284, \"step\": 1500}\n",
      "{\"learning_rate\": 4.986227014609006e-05, \"loss\": 1.387831468205899, \"step\": 2000}\n",
      "{\"learning_rate\": 4.982783768261257e-05, \"loss\": 1.357393349929669, \"step\": 2500}\n",
      "{\"learning_rate\": 4.9793405219135084e-05, \"loss\": 1.3663083375898823, \"step\": 3000}\n",
      "{\"learning_rate\": 4.97589727556576e-05, \"loss\": 1.286343130175257, \"step\": 3500}\n",
      "{\"learning_rate\": 4.9724540292180116e-05, \"loss\": 1.2652709064630325, \"step\": 4000}\n",
      "{\"learning_rate\": 4.969010782870263e-05, \"loss\": 1.2699733645915985, \"step\": 4500}\n",
      "{\"learning_rate\": 4.965567536522514e-05, \"loss\": 1.2236726535070557, \"step\": 5000}\n",
      "{\"learning_rate\": 4.962124290174766e-05, \"loss\": 1.150329444538027, \"step\": 5500}\n",
      "{\"learning_rate\": 4.958681043827017e-05, \"loss\": 1.2318150872066036, \"step\": 6000}\n",
      "{\"learning_rate\": 4.955237797479268e-05, \"loss\": 1.1578686289271753, \"step\": 6500}\n",
      "{\"learning_rate\": 4.95179455113152e-05, \"loss\": 1.171802905744553, \"step\": 7000}\n",
      "{\"learning_rate\": 4.9483513047837714e-05, \"loss\": 1.1571426456597838, \"step\": 7500}\n",
      "{\"learning_rate\": 4.944908058436022e-05, \"loss\": 1.139851774807088, \"step\": 8000}\n",
      "{\"learning_rate\": 4.941464812088274e-05, \"loss\": 1.1398603317945162, \"step\": 8500}\n",
      "{\"learning_rate\": 4.9380215657405255e-05, \"loss\": 1.0737791190699426, \"step\": 9000}\n",
      "{\"learning_rate\": 4.934578319392777e-05, \"loss\": 1.1254950705493465, \"step\": 9500}\n",
      "{\"learning_rate\": 4.931135073045029e-05, \"loss\": 1.1122392213669954, \"step\": 10000}\n",
      "{\"learning_rate\": 4.9276918266972796e-05, \"loss\": 1.124952568390072, \"step\": 10500}\n",
      "{\"learning_rate\": 4.9242485803495305e-05, \"loss\": 1.0874326402193837, \"step\": 11000}\n",
      "{\"learning_rate\": 4.920805334001782e-05, \"loss\": 1.1268184506514518, \"step\": 11500}\n",
      "{\"learning_rate\": 4.917362087654034e-05, \"loss\": 1.112748997378025, \"step\": 12000}\n",
      "{\"learning_rate\": 4.913918841306285e-05, \"loss\": 1.1013527309193158, \"step\": 12500}\n",
      "{\"learning_rate\": 4.910475594958537e-05, \"loss\": 1.0617871309816183, \"step\": 13000}\n",
      "{\"learning_rate\": 4.9070323486107885e-05, \"loss\": 1.0123886598426144, \"step\": 13500}\n",
      "{\"learning_rate\": 4.9035891022630394e-05, \"loss\": 1.0912608772248422, \"step\": 14000}\n",
      "{\"learning_rate\": 4.900145855915291e-05, \"loss\": 1.0680020240364247, \"step\": 14500}\n",
      "{\"learning_rate\": 4.896702609567542e-05, \"loss\": 1.0379280152905703, \"step\": 15000}\n",
      "{\"learning_rate\": 4.8932593632197935e-05, \"loss\": 1.0500156174856239, \"step\": 15500}\n",
      "{\"learning_rate\": 4.889816116872045e-05, \"loss\": 1.006869429382299, \"step\": 16000}\n",
      "{\"learning_rate\": 4.886372870524297e-05, \"loss\": 1.0172527401614424, \"step\": 16500}\n",
      "{\"learning_rate\": 4.8829296241765476e-05, \"loss\": 1.079312227967377, \"step\": 17000}\n",
      "{\"learning_rate\": 4.879486377828799e-05, \"loss\": 1.0715667852484256, \"step\": 17500}\n",
      "{\"learning_rate\": 4.876043131481051e-05, \"loss\": 1.0624292062649912, \"step\": 18000}\n",
      "{\"learning_rate\": 4.8725998851333024e-05, \"loss\": 1.037022227630252, \"step\": 18500}\n",
      "{\"learning_rate\": 4.869156638785553e-05, \"loss\": 1.032965377427492, \"step\": 19000}\n",
      "{\"learning_rate\": 4.865713392437805e-05, \"loss\": 0.9800113736881467, \"step\": 19500}\n",
      "{\"learning_rate\": 4.862270146090056e-05, \"loss\": 0.9811943025290384, \"step\": 20000}\n",
      "{\"learning_rate\": 4.8588268997423074e-05, \"loss\": 1.0121491514011287, \"step\": 20500}\n",
      "{\"learning_rate\": 4.855383653394559e-05, \"loss\": 1.033313969698218, \"step\": 21000}\n",
      "{\"learning_rate\": 4.8519404070468106e-05, \"loss\": 0.9647763919729696, \"step\": 21500}\n",
      "{\"learning_rate\": 4.848497160699062e-05, \"loss\": 1.0679316230993063, \"step\": 22000}\n",
      "{\"learning_rate\": 4.845053914351314e-05, \"loss\": 1.0071541166507814, \"step\": 22500}\n",
      "{\"learning_rate\": 4.841610668003565e-05, \"loss\": 1.0131640900230705, \"step\": 23000}\n",
      "{\"learning_rate\": 4.838167421655816e-05, \"loss\": 1.0238822016108462, \"step\": 23500}\n",
      "{\"learning_rate\": 4.834724175308067e-05, \"loss\": 1.0224118352854565, \"step\": 24000}\n",
      "{\"learning_rate\": 4.831280928960319e-05, \"loss\": 0.9892263727049649, \"step\": 24500}\n",
      "{\"learning_rate\": 4.8278376826125704e-05, \"loss\": 1.0074957673360332, \"step\": 25000}\n",
      "{\"learning_rate\": 4.824394436264822e-05, \"loss\": 0.9710314858424536, \"step\": 25500}\n",
      "{\"learning_rate\": 4.820951189917073e-05, \"loss\": 1.014430608608236, \"step\": 26000}\n",
      "{\"learning_rate\": 4.8175079435693245e-05, \"loss\": 0.9703000524709642, \"step\": 26500}\n",
      "{\"learning_rate\": 4.814064697221576e-05, \"loss\": 1.0317590001322532, \"step\": 27000}\n",
      "{\"learning_rate\": 4.8106214508738276e-05, \"loss\": 0.986725219319771, \"step\": 27500}\n",
      "{\"learning_rate\": 4.8071782045260786e-05, \"loss\": 0.8946194489444242, \"step\": 28000}\n",
      "{\"learning_rate\": 4.80373495817833e-05, \"loss\": 0.9846791865090854, \"step\": 28500}\n",
      "{\"learning_rate\": 4.800291711830581e-05, \"loss\": 1.0014901376107372, \"step\": 29000}\n",
      "{\"learning_rate\": 4.7968484654828327e-05, \"loss\": 0.9826803958233795, \"step\": 29500}\n",
      "{\"learning_rate\": 4.793405219135084e-05, \"loss\": 0.9030326702792955, \"step\": 30000}\n",
      "{\"learning_rate\": 4.789961972787336e-05, \"loss\": 0.9090489609415235, \"step\": 30500}\n",
      "{\"learning_rate\": 4.7865187264395874e-05, \"loss\": 1.0361534073407237, \"step\": 31000}\n",
      "{\"learning_rate\": 4.783075480091839e-05, \"loss\": 0.9474353370635217, \"step\": 31500}\n",
      "{\"learning_rate\": 4.77963223374409e-05, \"loss\": 0.9728079067872605, \"step\": 32000}\n",
      "{\"learning_rate\": 4.776188987396341e-05, \"loss\": 0.9300528485811228, \"step\": 32500}\n",
      "{\"learning_rate\": 4.7727457410485924e-05, \"loss\": 0.9841218973494542, \"step\": 33000}\n",
      "{\"learning_rate\": 4.769302494700844e-05, \"loss\": 0.9441860607838607, \"step\": 33500}\n",
      "{\"learning_rate\": 4.7658592483530956e-05, \"loss\": 0.9808677568106942, \"step\": 34000}\n",
      "{\"learning_rate\": 4.762416002005347e-05, \"loss\": 0.9470310641084506, \"step\": 34500}\n",
      "{\"learning_rate\": 4.758972755657598e-05, \"loss\": 1.0034090188876, \"step\": 35000}\n",
      "{\"learning_rate\": 4.75552950930985e-05, \"loss\": 0.9972027257959853, \"step\": 35500}\n",
      "{\"learning_rate\": 4.752086262962101e-05, \"loss\": 0.9691424096066621, \"step\": 36000}\n",
      "{\"learning_rate\": 4.748643016614352e-05, \"loss\": 0.9077233201034979, \"step\": 36500}\n",
      "{\"learning_rate\": 4.745199770266604e-05, \"loss\": 0.9076669748529966, \"step\": 37000}\n",
      "{\"learning_rate\": 4.7417565239188554e-05, \"loss\": 1.03553030924841, \"step\": 37500}\n",
      "{\"learning_rate\": 4.738313277571106e-05, \"loss\": 0.9933533185319102, \"step\": 38000}\n",
      "{\"learning_rate\": 4.734870031223358e-05, \"loss\": 0.9711311600769404, \"step\": 38500}\n",
      "{\"learning_rate\": 4.7314267848756095e-05, \"loss\": 0.9652732555311959, \"step\": 39000}\n",
      "{\"learning_rate\": 4.727983538527861e-05, \"loss\": 0.9739836966872389, \"step\": 39500}\n",
      "{\"learning_rate\": 4.724540292180113e-05, \"loss\": 0.9500446132006036, \"step\": 40000}\n",
      "{\"learning_rate\": 4.7210970458323636e-05, \"loss\": 0.9813739157137897, \"step\": 40500}\n",
      "{\"learning_rate\": 4.717653799484615e-05, \"loss\": 0.861996815109771, \"step\": 41000}\n",
      "{\"learning_rate\": 4.714210553136866e-05, \"loss\": 0.9820811390040617, \"step\": 41500}\n",
      "{\"learning_rate\": 4.710767306789118e-05, \"loss\": 0.9866586441730033, \"step\": 42000}\n",
      "{\"learning_rate\": 4.707324060441369e-05, \"loss\": 0.9768128989574616, \"step\": 42500}\n",
      "{\"learning_rate\": 4.703880814093621e-05, \"loss\": 0.9199930887365626, \"step\": 43000}\n",
      "{\"learning_rate\": 4.7004375677458725e-05, \"loss\": 0.9452685370866966, \"step\": 43500}\n",
      "{\"learning_rate\": 4.696994321398124e-05, \"loss\": 0.9483621352612536, \"step\": 44000}\n",
      "{\"learning_rate\": 4.693551075050375e-05, \"loss\": 0.9265181326005258, \"step\": 44500}\n",
      "{\"learning_rate\": 4.690107828702626e-05, \"loss\": 0.91860139360014, \"step\": 45000}\n",
      "{\"learning_rate\": 4.6866645823548775e-05, \"loss\": 0.9728572109978267, \"step\": 45500}\n",
      "{\"learning_rate\": 4.683221336007129e-05, \"loss\": 0.916060271661845, \"step\": 46000}\n",
      "{\"learning_rate\": 4.679778089659381e-05, \"loss\": 0.9481390044001018, \"step\": 46500}\n",
      "{\"learning_rate\": 4.676334843311632e-05, \"loss\": 0.9032733869693474, \"step\": 47000}\n",
      "{\"learning_rate\": 4.672891596963883e-05, \"loss\": 0.9319137422421191, \"step\": 47500}\n",
      "{\"learning_rate\": 4.669448350616135e-05, \"loss\": 0.9211968393473071, \"step\": 48000}\n",
      "{\"learning_rate\": 4.6660051042683864e-05, \"loss\": 0.9479825395379303, \"step\": 48500}\n",
      "{\"learning_rate\": 4.662561857920637e-05, \"loss\": 0.9423622801663442, \"step\": 49000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 4.659118611572889e-05, \"loss\": 0.8747427927890531, \"step\": 49500}\n",
      "{\"learning_rate\": 4.6556753652251405e-05, \"loss\": 0.9232895197127946, \"step\": 50000}\n",
      "{\"learning_rate\": 4.6522321188773914e-05, \"loss\": 0.9202062168887205, \"step\": 50500}\n",
      "{\"learning_rate\": 4.648788872529643e-05, \"loss\": 0.9384902152312862, \"step\": 51000}\n",
      "{\"learning_rate\": 4.6453456261818946e-05, \"loss\": 0.977715319404495, \"step\": 51500}\n",
      "{\"learning_rate\": 4.641902379834146e-05, \"loss\": 0.983382265705528, \"step\": 52000}\n",
      "{\"learning_rate\": 4.638459133486398e-05, \"loss\": 0.9283531812552974, \"step\": 52500}\n",
      "{\"learning_rate\": 4.635015887138649e-05, \"loss\": 0.9540203712241637, \"step\": 53000}\n",
      "{\"learning_rate\": 4.6315726407908996e-05, \"loss\": 0.8939281047678669, \"step\": 53500}\n",
      "{\"learning_rate\": 4.628129394443151e-05, \"loss\": 0.9321549138821283, \"step\": 54000}\n",
      "{\"learning_rate\": 4.624686148095403e-05, \"loss\": 0.9600951310935779, \"step\": 54500}\n",
      "{\"learning_rate\": 4.6212429017476544e-05, \"loss\": 0.9522564356806397, \"step\": 55000}\n",
      "{\"learning_rate\": 4.617799655399906e-05, \"loss\": 0.904842061113959, \"step\": 55500}\n",
      "{\"learning_rate\": 4.6143564090521576e-05, \"loss\": 0.9812288113779359, \"step\": 56000}\n",
      "{\"learning_rate\": 4.6109131627044085e-05, \"loss\": 0.8924348520128551, \"step\": 56500}\n",
      "{\"learning_rate\": 4.60746991635666e-05, \"loss\": 0.9502685646822211, \"step\": 57000}\n",
      "{\"learning_rate\": 4.604026670008911e-05, \"loss\": 0.9259887226216961, \"step\": 57500}\n",
      "{\"learning_rate\": 4.6005834236611626e-05, \"loss\": 0.913809229493636, \"step\": 58000}\n",
      "{\"learning_rate\": 4.597140177313414e-05, \"loss\": 0.8992817254102119, \"step\": 58500}\n",
      "{\"learning_rate\": 4.593696930965666e-05, \"loss\": 0.9190595802774042, \"step\": 59000}\n",
      "{\"learning_rate\": 4.590253684617917e-05, \"loss\": 0.9732482310067426, \"step\": 59500}\n",
      "{\"learning_rate\": 4.586810438270168e-05, \"loss\": 0.876945217385146, \"step\": 60000}\n",
      "{\"learning_rate\": 4.58336719192242e-05, \"loss\": 0.929284079094301, \"step\": 60500}\n",
      "{\"learning_rate\": 4.5799239455746714e-05, \"loss\": 0.8811809053889883, \"step\": 61000}\n",
      "{\"learning_rate\": 4.5764806992269224e-05, \"loss\": 0.9718376700991502, \"step\": 61500}\n",
      "{\"learning_rate\": 4.573037452879174e-05, \"loss\": 0.9644300299798779, \"step\": 62000}\n",
      "{\"learning_rate\": 4.569594206531425e-05, \"loss\": 0.9129064554080832, \"step\": 62500}\n",
      "{\"learning_rate\": 4.5661509601836765e-05, \"loss\": 0.9151571459481638, \"step\": 63000}\n",
      "{\"learning_rate\": 4.562707713835928e-05, \"loss\": 0.917130982947172, \"step\": 63500}\n",
      "{\"learning_rate\": 4.5592644674881796e-05, \"loss\": 0.8610147261584352, \"step\": 64000}\n",
      "{\"learning_rate\": 4.555821221140431e-05, \"loss\": 0.9058891507305235, \"step\": 64500}\n",
      "{\"learning_rate\": 4.552377974792683e-05, \"loss\": 0.9137051437894698, \"step\": 65000}\n",
      "{\"learning_rate\": 4.548934728444934e-05, \"loss\": 0.9014414702590148, \"step\": 65500}\n",
      "{\"learning_rate\": 4.545491482097185e-05, \"loss\": 0.8520912922213901, \"step\": 66000}\n",
      "{\"learning_rate\": 4.542048235749436e-05, \"loss\": 0.9178244678885384, \"step\": 66500}\n",
      "{\"learning_rate\": 4.538604989401688e-05, \"loss\": 0.9133279335109983, \"step\": 67000}\n",
      "{\"learning_rate\": 4.5351617430539394e-05, \"loss\": 0.8605359782507584, \"step\": 67500}\n",
      "{\"learning_rate\": 4.531718496706191e-05, \"loss\": 0.9020864020046429, \"step\": 68000}\n",
      "{\"learning_rate\": 4.528275250358442e-05, \"loss\": 0.8795215068389952, \"step\": 68500}\n",
      "{\"learning_rate\": 4.5248320040106935e-05, \"loss\": 0.9235908776292053, \"step\": 69000}\n",
      "{\"learning_rate\": 4.521388757662945e-05, \"loss\": 0.8443964331792085, \"step\": 69500}\n",
      "{\"learning_rate\": 4.517945511315197e-05, \"loss\": 0.8824673076510954, \"step\": 70000}\n",
      "{\"learning_rate\": 4.5145022649674476e-05, \"loss\": 0.901747055562213, \"step\": 70500}\n",
      "{\"learning_rate\": 4.511059018619699e-05, \"loss\": 0.8532213370554091, \"step\": 71000}\n",
      "{\"learning_rate\": 4.50761577227195e-05, \"loss\": 0.8763201106535562, \"step\": 71500}\n",
      "{\"learning_rate\": 4.504172525924202e-05, \"loss\": 0.8216406605888915, \"step\": 72000}\n",
      "{\"learning_rate\": 4.500729279576453e-05, \"loss\": 0.9010262929739838, \"step\": 72500}\n",
      "{\"learning_rate\": 4.497286033228705e-05, \"loss\": 0.936505705744843, \"step\": 73000}\n",
      "{\"learning_rate\": 4.4938427868809565e-05, \"loss\": 0.9459103010188264, \"step\": 73500}\n",
      "{\"learning_rate\": 4.490399540533208e-05, \"loss\": 0.8349573910977924, \"step\": 74000}\n",
      "{\"learning_rate\": 4.486956294185459e-05, \"loss\": 0.9395647854156268, \"step\": 74500}\n",
      "{\"learning_rate\": 4.48351304783771e-05, \"loss\": 0.8976238850365625, \"step\": 75000}\n",
      "{\"learning_rate\": 4.4800698014899615e-05, \"loss\": 0.872535553274618, \"step\": 75500}\n",
      "{\"learning_rate\": 4.476626555142213e-05, \"loss\": 0.9075719610542874, \"step\": 76000}\n",
      "{\"learning_rate\": 4.473183308794465e-05, \"loss\": 0.9095908268570493, \"step\": 76500}\n",
      "{\"learning_rate\": 4.469740062446716e-05, \"loss\": 0.9150479412041023, \"step\": 77000}\n",
      "{\"learning_rate\": 4.466296816098967e-05, \"loss\": 0.9125445795662527, \"step\": 77500}\n",
      "{\"learning_rate\": 4.462853569751219e-05, \"loss\": 0.8892799424467958, \"step\": 78000}\n",
      "{\"learning_rate\": 4.4594103234034704e-05, \"loss\": 0.8468400375471974, \"step\": 78500}\n",
      "{\"learning_rate\": 4.455967077055721e-05, \"loss\": 0.8843220015002881, \"step\": 79000}\n",
      "{\"learning_rate\": 4.452523830707973e-05, \"loss\": 0.892114118768659, \"step\": 79500}\n",
      "{\"learning_rate\": 4.4490805843602245e-05, \"loss\": 0.89685850097402, \"step\": 80000}\n",
      "{\"learning_rate\": 4.445637338012476e-05, \"loss\": 0.8693917163354054, \"step\": 80500}\n",
      "{\"learning_rate\": 4.442194091664727e-05, \"loss\": 0.8875806973983418, \"step\": 81000}\n",
      "{\"learning_rate\": 4.4387508453169786e-05, \"loss\": 0.8417494371880312, \"step\": 81500}\n",
      "{\"learning_rate\": 4.43530759896923e-05, \"loss\": 0.93427097545375, \"step\": 82000}\n",
      "{\"learning_rate\": 4.431864352621482e-05, \"loss\": 0.8795614386469824, \"step\": 82500}\n",
      "{\"learning_rate\": 4.428421106273733e-05, \"loss\": 0.9184598530747753, \"step\": 83000}\n",
      "{\"learning_rate\": 4.424977859925984e-05, \"loss\": 0.8855581670205575, \"step\": 83500}\n",
      "{\"learning_rate\": 4.421534613578235e-05, \"loss\": 0.8877478041314462, \"step\": 84000}\n",
      "{\"learning_rate\": 4.418091367230487e-05, \"loss\": 0.8576896046827897, \"step\": 84500}\n",
      "{\"learning_rate\": 4.4146481208827384e-05, \"loss\": 0.9091928911319701, \"step\": 85000}\n",
      "{\"learning_rate\": 4.41120487453499e-05, \"loss\": 0.9133802592685679, \"step\": 85500}\n",
      "{\"learning_rate\": 4.4077616281872416e-05, \"loss\": 0.8782573224575608, \"step\": 86000}\n",
      "{\"learning_rate\": 4.404318381839493e-05, \"loss\": 0.8543987261558068, \"step\": 86500}\n",
      "{\"learning_rate\": 4.400875135491744e-05, \"loss\": 0.888077180817083, \"step\": 87000}\n",
      "{\"learning_rate\": 4.397431889143995e-05, \"loss\": 0.8809581897841418, \"step\": 87500}\n",
      "{\"learning_rate\": 4.3939886427962466e-05, \"loss\": 0.9309852272035205, \"step\": 88000}\n",
      "{\"learning_rate\": 4.390545396448498e-05, \"loss\": 0.8808972880121437, \"step\": 88500}\n",
      "{\"learning_rate\": 4.38710215010075e-05, \"loss\": 0.8298728699715284, \"step\": 89000}\n",
      "{\"learning_rate\": 4.3836589037530014e-05, \"loss\": 0.8572155001970241, \"step\": 89500}\n",
      "{\"learning_rate\": 4.380215657405252e-05, \"loss\": 0.8778915560193418, \"step\": 90000}\n",
      "{\"learning_rate\": 4.376772411057504e-05, \"loss\": 0.8038472588518926, \"step\": 90500}\n",
      "{\"learning_rate\": 4.3733291647097555e-05, \"loss\": 0.8761615046633524, \"step\": 91000}\n",
      "{\"learning_rate\": 4.3698859183620064e-05, \"loss\": 0.8650250739524781, \"step\": 91500}\n",
      "{\"learning_rate\": 4.366442672014258e-05, \"loss\": 0.839454024846782, \"step\": 92000}\n",
      "{\"learning_rate\": 4.3629994256665096e-05, \"loss\": 0.8571733009968593, \"step\": 92500}\n",
      "{\"learning_rate\": 4.3595561793187605e-05, \"loss\": 0.8549261881198618, \"step\": 93000}\n",
      "{\"learning_rate\": 4.356112932971012e-05, \"loss\": 0.8785246676291864, \"step\": 93500}\n",
      "{\"learning_rate\": 4.3526696866232637e-05, \"loss\": 0.8810880420770846, \"step\": 94000}\n",
      "{\"learning_rate\": 4.349226440275515e-05, \"loss\": 0.9710761562428087, \"step\": 94500}\n",
      "{\"learning_rate\": 4.345783193927767e-05, \"loss\": 0.8997905381061719, \"step\": 95000}\n",
      "{\"learning_rate\": 4.342339947580018e-05, \"loss\": 0.8081908753847238, \"step\": 95500}\n",
      "{\"learning_rate\": 4.338896701232269e-05, \"loss\": 0.8696594377009315, \"step\": 96000}\n",
      "{\"learning_rate\": 4.33545345488452e-05, \"loss\": 0.8338784552197612, \"step\": 96500}\n",
      "{\"learning_rate\": 4.332010208536772e-05, \"loss\": 0.9043935636594251, \"step\": 97000}\n",
      "{\"learning_rate\": 4.3285669621890234e-05, \"loss\": 0.9178970917694096, \"step\": 97500}\n",
      "{\"learning_rate\": 4.325123715841275e-05, \"loss\": 0.8639194309230079, \"step\": 98000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 4.3216804694935266e-05, \"loss\": 0.8925181904716591, \"step\": 98500}\n",
      "{\"learning_rate\": 4.3182372231457775e-05, \"loss\": 0.8437740849417751, \"step\": 99000}\n",
      "{\"learning_rate\": 4.314793976798029e-05, \"loss\": 0.8685495511001209, \"step\": 99500}\n",
      "{\"learning_rate\": 4.31135073045028e-05, \"loss\": 0.8342654318368877, \"step\": 100000}\n",
      "{\"learning_rate\": 4.3079074841025316e-05, \"loss\": 0.8312324295783182, \"step\": 100500}\n",
      "{\"learning_rate\": 4.304464237754783e-05, \"loss\": 0.8809644337498758, \"step\": 101000}\n",
      "{\"learning_rate\": 4.301020991407035e-05, \"loss\": 0.82307657155997, \"step\": 101500}\n",
      "{\"learning_rate\": 4.297577745059286e-05, \"loss\": 0.8997480523998674, \"step\": 102000}\n",
      "{\"learning_rate\": 4.294134498711537e-05, \"loss\": 0.8352785526247754, \"step\": 102500}\n",
      "{\"learning_rate\": 4.290691252363789e-05, \"loss\": 0.8977844277796394, \"step\": 103000}\n",
      "{\"learning_rate\": 4.2872480060160405e-05, \"loss\": 0.8420131958097918, \"step\": 103500}\n",
      "{\"learning_rate\": 4.2838047596682914e-05, \"loss\": 0.8817716982311976, \"step\": 104000}\n",
      "{\"learning_rate\": 4.280361513320543e-05, \"loss\": 0.8195159445533936, \"step\": 104500}\n",
      "{\"learning_rate\": 4.276918266972794e-05, \"loss\": 0.868734194424731, \"step\": 105000}\n",
      "{\"learning_rate\": 4.2734750206250455e-05, \"loss\": 0.8070583463036164, \"step\": 105500}\n",
      "{\"learning_rate\": 4.270031774277297e-05, \"loss\": 0.8809799180409463, \"step\": 106000}\n",
      "{\"learning_rate\": 4.266588527929549e-05, \"loss\": 0.8431838199496852, \"step\": 106500}\n",
      "{\"learning_rate\": 4.2631452815818e-05, \"loss\": 0.8276935685776989, \"step\": 107000}\n",
      "{\"learning_rate\": 4.259702035234052e-05, \"loss\": 0.886033833026333, \"step\": 107500}\n",
      "{\"learning_rate\": 4.256258788886303e-05, \"loss\": 0.8605499586332881, \"step\": 108000}\n",
      "{\"learning_rate\": 4.2528155425385544e-05, \"loss\": 0.8482314172769838, \"step\": 108500}\n",
      "{\"learning_rate\": 4.249372296190805e-05, \"loss\": 0.8455691932481132, \"step\": 109000}\n",
      "{\"learning_rate\": 4.245929049843057e-05, \"loss\": 0.8183532992803666, \"step\": 109500}\n",
      "{\"learning_rate\": 4.2424858034953085e-05, \"loss\": 0.8290791089542908, \"step\": 110000}\n",
      "{\"learning_rate\": 4.23904255714756e-05, \"loss\": 0.8490973854819313, \"step\": 110500}\n",
      "{\"learning_rate\": 4.235599310799811e-05, \"loss\": 0.8686551242056012, \"step\": 111000}\n",
      "{\"learning_rate\": 4.2321560644520626e-05, \"loss\": 0.8308347825988022, \"step\": 111500}\n",
      "{\"learning_rate\": 4.228712818104314e-05, \"loss\": 0.8237632714250358, \"step\": 112000}\n",
      "{\"learning_rate\": 4.225269571756566e-05, \"loss\": 0.9023903503656621, \"step\": 112500}\n",
      "{\"learning_rate\": 4.221826325408817e-05, \"loss\": 0.8838413543373462, \"step\": 113000}\n",
      "{\"learning_rate\": 4.218383079061068e-05, \"loss\": 0.8125491251684726, \"step\": 113500}\n",
      "{\"learning_rate\": 4.214939832713319e-05, \"loss\": 0.8685491467325482, \"step\": 114000}\n",
      "{\"learning_rate\": 4.211496586365571e-05, \"loss\": 0.8196368942486588, \"step\": 114500}\n",
      "{\"learning_rate\": 4.2080533400178224e-05, \"loss\": 0.893135927008756, \"step\": 115000}\n",
      "{\"learning_rate\": 4.204610093670074e-05, \"loss\": 0.8886477258483355, \"step\": 115500}\n",
      "{\"learning_rate\": 4.2011668473223256e-05, \"loss\": 0.8569157242927758, \"step\": 116000}\n",
      "{\"learning_rate\": 4.197723600974577e-05, \"loss\": 0.774561801548698, \"step\": 116500}\n",
      "{\"learning_rate\": 4.194280354626828e-05, \"loss\": 0.9017797135728178, \"step\": 117000}\n",
      "{\"learning_rate\": 4.190837108279079e-05, \"loss\": 0.8079219261819671, \"step\": 117500}\n",
      "{\"learning_rate\": 4.1873938619313306e-05, \"loss\": 0.8422194141955115, \"step\": 118000}\n",
      "{\"learning_rate\": 4.183950615583582e-05, \"loss\": 0.9013367210482829, \"step\": 118500}\n",
      "{\"learning_rate\": 4.180507369235834e-05, \"loss\": 0.8079490033932961, \"step\": 119000}\n",
      "{\"learning_rate\": 4.1770641228880854e-05, \"loss\": 0.8372460617013566, \"step\": 119500}\n",
      "{\"learning_rate\": 4.173620876540336e-05, \"loss\": 0.8756724453748611, \"step\": 120000}\n",
      "{\"learning_rate\": 4.170177630192588e-05, \"loss\": 0.8799382839103346, \"step\": 120500}\n",
      "{\"learning_rate\": 4.1667343838448395e-05, \"loss\": 0.8375219335143047, \"step\": 121000}\n",
      "{\"learning_rate\": 4.1632911374970904e-05, \"loss\": 0.8442886019003345, \"step\": 121500}\n",
      "{\"learning_rate\": 4.159847891149342e-05, \"loss\": 0.8594189385728969, \"step\": 122000}\n",
      "{\"learning_rate\": 4.1564046448015936e-05, \"loss\": 0.8328986901493336, \"step\": 122500}\n",
      "{\"learning_rate\": 4.152961398453845e-05, \"loss\": 0.8633940304364077, \"step\": 123000}\n",
      "{\"learning_rate\": 4.149518152106096e-05, \"loss\": 0.9238472002476629, \"step\": 123500}\n",
      "{\"learning_rate\": 4.146074905758348e-05, \"loss\": 0.8420437908163003, \"step\": 124000}\n",
      "{\"learning_rate\": 4.142631659410599e-05, \"loss\": 0.8470064594307914, \"step\": 124500}\n",
      "{\"learning_rate\": 4.139188413062851e-05, \"loss\": 0.8606332320317742, \"step\": 125000}\n",
      "{\"learning_rate\": 4.135745166715102e-05, \"loss\": 0.8474153995403031, \"step\": 125500}\n",
      "{\"learning_rate\": 4.1323019203673534e-05, \"loss\": 0.8767914932663261, \"step\": 126000}\n",
      "{\"learning_rate\": 4.128858674019604e-05, \"loss\": 0.8444562849384384, \"step\": 126500}\n",
      "{\"learning_rate\": 4.125415427671856e-05, \"loss\": 0.8283964840062253, \"step\": 127000}\n",
      "{\"learning_rate\": 4.1219721813241075e-05, \"loss\": 0.8457630704767071, \"step\": 127500}\n",
      "{\"learning_rate\": 4.118528934976359e-05, \"loss\": 0.8383407324386353, \"step\": 128000}\n",
      "{\"learning_rate\": 4.1150856886286106e-05, \"loss\": 0.8828292333041318, \"step\": 128500}\n",
      "{\"learning_rate\": 4.111642442280862e-05, \"loss\": 0.8084727477806155, \"step\": 129000}\n",
      "{\"learning_rate\": 4.108199195933113e-05, \"loss\": 0.8553023239262693, \"step\": 129500}\n",
      "{\"learning_rate\": 4.104755949585364e-05, \"loss\": 0.8644712463446486, \"step\": 130000}\n",
      "{\"learning_rate\": 4.1013127032376157e-05, \"loss\": 0.8389179138170147, \"step\": 130500}\n",
      "{\"learning_rate\": 4.097869456889867e-05, \"loss\": 0.8153913875042054, \"step\": 131000}\n",
      "{\"learning_rate\": 4.094426210542119e-05, \"loss\": 0.8131813892650535, \"step\": 131500}\n",
      "{\"learning_rate\": 4.0909829641943704e-05, \"loss\": 0.8229944471652852, \"step\": 132000}\n",
      "{\"learning_rate\": 4.0875397178466213e-05, \"loss\": 0.8280047676234972, \"step\": 132500}\n",
      "{\"learning_rate\": 4.084096471498873e-05, \"loss\": 0.8106258638422296, \"step\": 133000}\n",
      "{\"learning_rate\": 4.0806532251511245e-05, \"loss\": 0.8413387952501653, \"step\": 133500}\n",
      "{\"learning_rate\": 4.0772099788033754e-05, \"loss\": 0.8750610228526639, \"step\": 134000}\n",
      "{\"learning_rate\": 4.073766732455627e-05, \"loss\": 0.8417620814308757, \"step\": 134500}\n",
      "{\"learning_rate\": 4.0703234861078786e-05, \"loss\": 0.8260823763640947, \"step\": 135000}\n",
      "{\"learning_rate\": 4.0668802397601295e-05, \"loss\": 0.853117008595349, \"step\": 135500}\n",
      "{\"learning_rate\": 4.063436993412381e-05, \"loss\": 0.8046187168440083, \"step\": 136000}\n",
      "{\"learning_rate\": 4.059993747064633e-05, \"loss\": 0.8685055012851953, \"step\": 136500}\n",
      "{\"learning_rate\": 4.056550500716884e-05, \"loss\": 0.8363339468766062, \"step\": 137000}\n",
      "{\"learning_rate\": 4.053107254369136e-05, \"loss\": 0.7953409538505366, \"step\": 137500}\n",
      "{\"learning_rate\": 4.049664008021387e-05, \"loss\": 0.8281164035054389, \"step\": 138000}\n",
      "{\"learning_rate\": 4.046220761673638e-05, \"loss\": 0.7891188402504485, \"step\": 138500}\n",
      "{\"learning_rate\": 4.042777515325889e-05, \"loss\": 0.8419543657847098, \"step\": 139000}\n",
      "{\"learning_rate\": 4.039334268978141e-05, \"loss\": 0.8133071147340525, \"step\": 139500}\n",
      "{\"learning_rate\": 4.0358910226303925e-05, \"loss\": 0.8490937091899977, \"step\": 140000}\n",
      "{\"learning_rate\": 4.032447776282644e-05, \"loss\": 0.8507148595349281, \"step\": 140500}\n",
      "{\"learning_rate\": 4.029004529934896e-05, \"loss\": 0.8679262805135222, \"step\": 141000}\n",
      "{\"learning_rate\": 4.0255612835871466e-05, \"loss\": 0.8680017492421903, \"step\": 141500}\n",
      "{\"learning_rate\": 4.022118037239398e-05, \"loss\": 0.814028147669218, \"step\": 142000}\n",
      "{\"learning_rate\": 4.018674790891649e-05, \"loss\": 0.8369178345815163, \"step\": 142500}\n",
      "{\"learning_rate\": 4.015231544543901e-05, \"loss\": 0.8040855756991659, \"step\": 143000}\n",
      "{\"learning_rate\": 4.011788298196152e-05, \"loss\": 0.791384812252305, \"step\": 143500}\n",
      "{\"learning_rate\": 4.008345051848404e-05, \"loss\": 0.8778394572620164, \"step\": 144000}\n",
      "{\"learning_rate\": 4.004901805500655e-05, \"loss\": 0.8033560684276745, \"step\": 144500}\n",
      "{\"learning_rate\": 4.0014585591529064e-05, \"loss\": 0.8638124168952345, \"step\": 145000}\n",
      "{\"learning_rate\": 3.998015312805158e-05, \"loss\": 0.8351947218488786, \"step\": 145500}\n",
      "{\"learning_rate\": 3.9945720664574096e-05, \"loss\": 0.790726827546605, \"step\": 146000}\n",
      "{\"learning_rate\": 3.9911288201096605e-05, \"loss\": 0.8490927896166686, \"step\": 146500}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 3.987685573761912e-05, \"loss\": 0.8534135042590788, \"step\": 147000}\n",
      "{\"learning_rate\": 3.984242327414163e-05, \"loss\": 0.8165467953867628, \"step\": 147500}\n",
      "{\"learning_rate\": 3.9807990810664146e-05, \"loss\": 0.8286881811334752, \"step\": 148000}\n",
      "{\"learning_rate\": 3.977355834718666e-05, \"loss\": 0.8705444675046601, \"step\": 148500}\n",
      "{\"learning_rate\": 3.973912588370918e-05, \"loss\": 0.8283433238841826, \"step\": 149000}\n",
      "{\"learning_rate\": 3.9704693420231694e-05, \"loss\": 0.8403270889614941, \"step\": 149500}\n",
      "{\"learning_rate\": 3.967026095675421e-05, \"loss\": 0.8253813411883312, \"step\": 150000}\n",
      "{\"learning_rate\": 3.963582849327672e-05, \"loss\": 0.7713796430857037, \"step\": 150500}\n",
      "{\"learning_rate\": 3.9601396029799235e-05, \"loss\": 0.866889705835376, \"step\": 151000}\n",
      "{\"learning_rate\": 3.9566963566321744e-05, \"loss\": 0.7949972550484236, \"step\": 151500}\n",
      "{\"learning_rate\": 3.953253110284426e-05, \"loss\": 0.8102379525220021, \"step\": 152000}\n",
      "{\"learning_rate\": 3.9498098639366776e-05, \"loss\": 0.8578293781144893, \"step\": 152500}\n",
      "{\"learning_rate\": 3.946366617588929e-05, \"loss\": 0.7710428285984672, \"step\": 153000}\n",
      "{\"learning_rate\": 3.94292337124118e-05, \"loss\": 0.8630950520288315, \"step\": 153500}\n",
      "{\"learning_rate\": 3.939480124893432e-05, \"loss\": 0.8316879134823103, \"step\": 154000}\n",
      "{\"learning_rate\": 3.936036878545683e-05, \"loss\": 0.7916118122041226, \"step\": 154500}\n",
      "{\"learning_rate\": 3.932593632197935e-05, \"loss\": 0.8384886520217988, \"step\": 155000}\n",
      "{\"learning_rate\": 3.929150385850186e-05, \"loss\": 0.8111927242052624, \"step\": 155500}\n",
      "{\"learning_rate\": 3.9257071395024374e-05, \"loss\": 0.8220204059376847, \"step\": 156000}\n",
      "{\"learning_rate\": 3.922263893154688e-05, \"loss\": 0.8707389560136944, \"step\": 156500}\n",
      "{\"learning_rate\": 3.91882064680694e-05, \"loss\": 0.7957133923039074, \"step\": 157000}\n",
      "{\"learning_rate\": 3.9153774004591915e-05, \"loss\": 0.83523462619778, \"step\": 157500}\n",
      "{\"learning_rate\": 3.911934154111443e-05, \"loss\": 0.8530726082330803, \"step\": 158000}\n",
      "{\"learning_rate\": 3.9084909077636946e-05, \"loss\": 0.8185666677971604, \"step\": 158500}\n",
      "{\"learning_rate\": 3.905047661415946e-05, \"loss\": 0.8458441244385904, \"step\": 159000}\n",
      "{\"learning_rate\": 3.901604415068197e-05, \"loss\": 0.7770266060607391, \"step\": 159500}\n",
      "{\"learning_rate\": 3.898161168720448e-05, \"loss\": 0.8609267409741297, \"step\": 160000}\n",
      "{\"learning_rate\": 3.8947179223727e-05, \"loss\": 0.8563531468570582, \"step\": 160500}\n",
      "{\"learning_rate\": 3.891274676024951e-05, \"loss\": 0.7815319720954867, \"step\": 161000}\n",
      "{\"learning_rate\": 3.887831429677203e-05, \"loss\": 0.7976650121568819, \"step\": 161500}\n",
      "{\"learning_rate\": 3.8843881833294544e-05, \"loss\": 0.8196818073093309, \"step\": 162000}\n",
      "{\"learning_rate\": 3.880944936981706e-05, \"loss\": 0.7894172813090263, \"step\": 162500}\n",
      "{\"learning_rate\": 3.877501690633957e-05, \"loss\": 0.8167843664427638, \"step\": 163000}\n",
      "{\"learning_rate\": 3.8740584442862085e-05, \"loss\": 0.8768547602722537, \"step\": 163500}\n",
      "{\"learning_rate\": 3.8706151979384595e-05, \"loss\": 0.7718924969321815, \"step\": 164000}\n",
      "{\"learning_rate\": 3.867171951590711e-05, \"loss\": 0.8531434919604217, \"step\": 164500}\n",
      "{\"learning_rate\": 3.8637287052429626e-05, \"loss\": 0.7511682809297344, \"step\": 165000}\n",
      "{\"learning_rate\": 3.860285458895214e-05, \"loss\": 0.7500631555524305, \"step\": 165500}\n",
      "{\"learning_rate\": 3.856842212547465e-05, \"loss\": 0.7972833009763272, \"step\": 166000}\n",
      "{\"learning_rate\": 3.853398966199717e-05, \"loss\": 0.790941692240769, \"step\": 166500}\n",
      "{\"learning_rate\": 3.849955719851968e-05, \"loss\": 0.8360637964137714, \"step\": 167000}\n",
      "{\"learning_rate\": 3.84651247350422e-05, \"loss\": 0.828090805140906, \"step\": 167500}\n",
      "{\"learning_rate\": 3.843069227156471e-05, \"loss\": 0.8108400727813132, \"step\": 168000}\n",
      "{\"learning_rate\": 3.8396259808087224e-05, \"loss\": 0.7963304364586365, \"step\": 168500}\n",
      "{\"learning_rate\": 3.8361827344609733e-05, \"loss\": 0.7885009292726755, \"step\": 169000}\n",
      "{\"learning_rate\": 3.832739488113225e-05, \"loss\": 0.7983136767550022, \"step\": 169500}\n",
      "{\"learning_rate\": 3.8292962417654765e-05, \"loss\": 0.849291675933171, \"step\": 170000}\n",
      "{\"learning_rate\": 3.825852995417728e-05, \"loss\": 0.7844562416099361, \"step\": 170500}\n",
      "{\"learning_rate\": 3.82240974906998e-05, \"loss\": 0.8380819605436991, \"step\": 171000}\n",
      "{\"learning_rate\": 3.818966502722231e-05, \"loss\": 0.7637779661325621, \"step\": 171500}\n",
      "{\"learning_rate\": 3.815523256374482e-05, \"loss\": 0.8543084366579423, \"step\": 172000}\n",
      "{\"learning_rate\": 3.812080010026733e-05, \"loss\": 0.8579091169285239, \"step\": 172500}\n",
      "{\"learning_rate\": 3.808636763678985e-05, \"loss\": 0.7931596169655095, \"step\": 173000}\n",
      "{\"learning_rate\": 3.805193517331236e-05, \"loss\": 0.8061051818011911, \"step\": 173500}\n",
      "{\"learning_rate\": 3.801750270983488e-05, \"loss\": 0.865305579371925, \"step\": 174000}\n",
      "{\"learning_rate\": 3.7983070246357395e-05, \"loss\": 0.83651615984604, \"step\": 174500}\n",
      "{\"learning_rate\": 3.7948637782879904e-05, \"loss\": 0.7462202647951198, \"step\": 175000}\n",
      "{\"learning_rate\": 3.791420531940242e-05, \"loss\": 0.8488297278601676, \"step\": 175500}\n",
      "{\"learning_rate\": 3.7879772855924936e-05, \"loss\": 0.7946595864453703, \"step\": 176000}\n",
      "{\"learning_rate\": 3.7845340392447445e-05, \"loss\": 0.8004176111184642, \"step\": 176500}\n",
      "{\"learning_rate\": 3.781090792896996e-05, \"loss\": 0.8210299527102034, \"step\": 177000}\n",
      "{\"learning_rate\": 3.777647546549248e-05, \"loss\": 0.7952896791365347, \"step\": 177500}\n",
      "{\"learning_rate\": 3.7742043002014986e-05, \"loss\": 0.772268421265704, \"step\": 178000}\n",
      "{\"learning_rate\": 3.77076105385375e-05, \"loss\": 0.8130794077618629, \"step\": 178500}\n",
      "{\"learning_rate\": 3.767317807506002e-05, \"loss\": 0.7306273354959558, \"step\": 179000}\n",
      "{\"learning_rate\": 3.7638745611582534e-05, \"loss\": 0.77112636306684, \"step\": 179500}\n",
      "{\"learning_rate\": 3.760431314810505e-05, \"loss\": 0.8094404640323483, \"step\": 180000}\n",
      "{\"learning_rate\": 3.756988068462756e-05, \"loss\": 0.7885202072555548, \"step\": 180500}\n",
      "{\"learning_rate\": 3.753544822115007e-05, \"loss\": 0.8096072243629605, \"step\": 181000}\n",
      "{\"learning_rate\": 3.7501015757672584e-05, \"loss\": 0.777129968204128, \"step\": 181500}\n",
      "{\"learning_rate\": 3.74665832941951e-05, \"loss\": 0.7716213520698366, \"step\": 182000}\n",
      "{\"learning_rate\": 3.7432150830717616e-05, \"loss\": 0.7947350084693171, \"step\": 182500}\n",
      "{\"learning_rate\": 3.739771836724013e-05, \"loss\": 0.8225145603552227, \"step\": 183000}\n",
      "{\"learning_rate\": 3.736328590376265e-05, \"loss\": 0.7958620048966258, \"step\": 183500}\n",
      "{\"learning_rate\": 3.732885344028516e-05, \"loss\": 0.7994221528521739, \"step\": 184000}\n",
      "{\"learning_rate\": 3.729442097680767e-05, \"loss\": 0.7932300039540859, \"step\": 184500}\n",
      "{\"learning_rate\": 3.725998851333018e-05, \"loss\": 0.8057168811805896, \"step\": 185000}\n",
      "{\"learning_rate\": 3.72255560498527e-05, \"loss\": 0.7982712429804378, \"step\": 185500}\n",
      "{\"learning_rate\": 3.7191123586375214e-05, \"loss\": 0.7890258704993758, \"step\": 186000}\n",
      "{\"learning_rate\": 3.715669112289773e-05, \"loss\": 0.7544978960842709, \"step\": 186500}\n",
      "{\"learning_rate\": 3.712225865942024e-05, \"loss\": 0.811433963652351, \"step\": 187000}\n",
      "{\"learning_rate\": 3.7087826195942755e-05, \"loss\": 0.8096778252875665, \"step\": 187500}\n",
      "{\"learning_rate\": 3.705339373246527e-05, \"loss\": 0.8259823106405675, \"step\": 188000}\n",
      "{\"learning_rate\": 3.7018961268987787e-05, \"loss\": 0.8138681565036532, \"step\": 188500}\n",
      "{\"learning_rate\": 3.6984528805510296e-05, \"loss\": 0.8318993340099696, \"step\": 189000}\n",
      "{\"learning_rate\": 3.695009634203281e-05, \"loss\": 0.7916605723538087, \"step\": 189500}\n",
      "{\"learning_rate\": 3.691566387855532e-05, \"loss\": 0.8379341741395183, \"step\": 190000}\n",
      "{\"learning_rate\": 3.688123141507784e-05, \"loss\": 0.7921372601944604, \"step\": 190500}\n",
      "{\"learning_rate\": 3.684679895160035e-05, \"loss\": 0.7550502618411555, \"step\": 191000}\n",
      "{\"learning_rate\": 3.681236648812287e-05, \"loss\": 0.7874336593191837, \"step\": 191500}\n",
      "{\"learning_rate\": 3.6777934024645385e-05, \"loss\": 0.848487902831519, \"step\": 192000}\n",
      "{\"learning_rate\": 3.67435015611679e-05, \"loss\": 0.7470332738904981, \"step\": 192500}\n",
      "{\"learning_rate\": 3.670906909769041e-05, \"loss\": 0.806339344133623, \"step\": 193000}\n",
      "{\"learning_rate\": 3.6674636634212925e-05, \"loss\": 0.7543370943084592, \"step\": 193500}\n",
      "{\"learning_rate\": 3.6640204170735435e-05, \"loss\": 0.7606110347913345, \"step\": 194000}\n",
      "{\"learning_rate\": 3.660577170725795e-05, \"loss\": 0.7801534237979795, \"step\": 194500}\n",
      "{\"learning_rate\": 3.6571339243780466e-05, \"loss\": 0.7336315714871161, \"step\": 195000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 3.653690678030298e-05, \"loss\": 0.7749344609154505, \"step\": 195500}\n",
      "{\"learning_rate\": 3.650247431682549e-05, \"loss\": 0.7832830216216972, \"step\": 196000}\n",
      "{\"learning_rate\": 3.646804185334801e-05, \"loss\": 0.7947887608012534, \"step\": 196500}\n",
      "{\"learning_rate\": 3.6433609389870523e-05, \"loss\": 0.7720861472455436, \"step\": 197000}\n",
      "{\"learning_rate\": 3.639917692639304e-05, \"loss\": 0.7765870911176899, \"step\": 197500}\n",
      "{\"learning_rate\": 3.636474446291555e-05, \"loss\": 0.7913119195720647, \"step\": 198000}\n",
      "{\"learning_rate\": 3.6330311999438064e-05, \"loss\": 0.8074491033289233, \"step\": 198500}\n",
      "{\"learning_rate\": 3.6295879535960574e-05, \"loss\": 0.7533335728097591, \"step\": 199000}\n",
      "{\"learning_rate\": 3.626144707248309e-05, \"loss\": 0.8431416549878777, \"step\": 199500}\n",
      "{\"learning_rate\": 3.6227014609005605e-05, \"loss\": 0.7741141673230449, \"step\": 200000}\n",
      "{\"learning_rate\": 3.619258214552812e-05, \"loss\": 0.7737307393885566, \"step\": 200500}\n",
      "{\"learning_rate\": 3.615814968205064e-05, \"loss\": 0.8319742536100093, \"step\": 201000}\n",
      "{\"learning_rate\": 3.612371721857315e-05, \"loss\": 0.800512675331789, \"step\": 201500}\n",
      "{\"learning_rate\": 3.608928475509566e-05, \"loss\": 0.7377999104901101, \"step\": 202000}\n",
      "{\"learning_rate\": 3.605485229161817e-05, \"loss\": 0.8109429132122896, \"step\": 202500}\n",
      "{\"learning_rate\": 3.602041982814069e-05, \"loss\": 0.7654277077325387, \"step\": 203000}\n",
      "{\"learning_rate\": 3.59859873646632e-05, \"loss\": 0.8068550572213716, \"step\": 203500}\n",
      "{\"learning_rate\": 3.595155490118572e-05, \"loss\": 0.8558364773832727, \"step\": 204000}\n",
      "{\"learning_rate\": 3.5917122437708235e-05, \"loss\": 0.7646641921498231, \"step\": 204500}\n",
      "{\"learning_rate\": 3.588268997423075e-05, \"loss\": 0.7567500231850427, \"step\": 205000}\n",
      "{\"learning_rate\": 3.584825751075326e-05, \"loss\": 0.7990339376319898, \"step\": 205500}\n",
      "{\"learning_rate\": 3.5813825047275776e-05, \"loss\": 0.785943572290591, \"step\": 206000}\n",
      "{\"learning_rate\": 3.5779392583798285e-05, \"loss\": 0.7721872507261578, \"step\": 206500}\n",
      "{\"learning_rate\": 3.57449601203208e-05, \"loss\": 0.8012120566145168, \"step\": 207000}\n",
      "{\"learning_rate\": 3.571052765684332e-05, \"loss\": 0.80803259739629, \"step\": 207500}\n",
      "{\"learning_rate\": 3.567609519336583e-05, \"loss\": 0.8128117101467797, \"step\": 208000}\n",
      "{\"learning_rate\": 3.564166272988834e-05, \"loss\": 0.7906452004985185, \"step\": 208500}\n",
      "{\"learning_rate\": 3.560723026641086e-05, \"loss\": 0.7633617012692266, \"step\": 209000}\n",
      "{\"learning_rate\": 3.5572797802933374e-05, \"loss\": 0.7493711204411811, \"step\": 209500}\n",
      "{\"learning_rate\": 3.553836533945589e-05, \"loss\": 0.8472321655203705, \"step\": 210000}\n",
      "{\"learning_rate\": 3.55039328759784e-05, \"loss\": 0.7974902285044082, \"step\": 210500}\n",
      "{\"learning_rate\": 3.5469500412500915e-05, \"loss\": 0.7889839074461488, \"step\": 211000}\n",
      "{\"learning_rate\": 3.5435067949023424e-05, \"loss\": 0.7633347732662223, \"step\": 211500}\n",
      "{\"learning_rate\": 3.540063548554594e-05, \"loss\": 0.7676985098025761, \"step\": 212000}\n",
      "{\"learning_rate\": 3.5366203022068456e-05, \"loss\": 0.8128793582279468, \"step\": 212500}\n",
      "{\"learning_rate\": 3.533177055859097e-05, \"loss\": 0.7756161935798591, \"step\": 213000}\n",
      "{\"learning_rate\": 3.529733809511349e-05, \"loss\": 0.7638425354978535, \"step\": 213500}\n",
      "{\"learning_rate\": 3.5262905631636004e-05, \"loss\": 0.8011200746541144, \"step\": 214000}\n",
      "{\"learning_rate\": 3.522847316815851e-05, \"loss\": 0.7720901334192022, \"step\": 214500}\n",
      "{\"learning_rate\": 3.519404070468102e-05, \"loss\": 0.7495683866785839, \"step\": 215000}\n",
      "{\"learning_rate\": 3.515960824120354e-05, \"loss\": 0.7608493517505703, \"step\": 215500}\n",
      "{\"learning_rate\": 3.5125175777726054e-05, \"loss\": 0.7965562380074407, \"step\": 216000}\n",
      "{\"learning_rate\": 3.509074331424857e-05, \"loss\": 0.7953199925782974, \"step\": 216500}\n",
      "{\"learning_rate\": 3.5056310850771086e-05, \"loss\": 0.7666184272587416, \"step\": 217000}\n",
      "{\"learning_rate\": 3.5021878387293595e-05, \"loss\": 0.7407371259686187, \"step\": 217500}\n",
      "{\"learning_rate\": 3.498744592381611e-05, \"loss\": 0.758843574889761, \"step\": 218000}\n",
      "{\"learning_rate\": 3.495301346033863e-05, \"loss\": 0.7987905358255375, \"step\": 218500}\n",
      "{\"learning_rate\": 3.4918580996861136e-05, \"loss\": 0.8057806782021653, \"step\": 219000}\n",
      "{\"learning_rate\": 3.488414853338365e-05, \"loss\": 0.7476142160202726, \"step\": 219500}\n",
      "{\"learning_rate\": 3.484971606990617e-05, \"loss\": 0.7572174776048051, \"step\": 220000}\n",
      "{\"learning_rate\": 3.481528360642868e-05, \"loss\": 0.8189228038343718, \"step\": 220500}\n",
      "{\"learning_rate\": 3.478085114295119e-05, \"loss\": 0.7656701194007183, \"step\": 221000}\n",
      "{\"learning_rate\": 3.474641867947371e-05, \"loss\": 0.7968573288366315, \"step\": 221500}\n",
      "{\"learning_rate\": 3.4711986215996225e-05, \"loss\": 0.783234458074905, \"step\": 222000}\n",
      "{\"learning_rate\": 3.467755375251874e-05, \"loss\": 0.7463278791519115, \"step\": 222500}\n",
      "{\"learning_rate\": 3.464312128904125e-05, \"loss\": 0.7358493091349956, \"step\": 223000}\n",
      "{\"learning_rate\": 3.460868882556376e-05, \"loss\": 0.8168169260922005, \"step\": 223500}\n",
      "{\"learning_rate\": 3.4574256362086275e-05, \"loss\": 0.7765790829475154, \"step\": 224000}\n",
      "{\"learning_rate\": 3.453982389860879e-05, \"loss\": 0.7990801791109261, \"step\": 224500}\n",
      "{\"learning_rate\": 3.4505391435131307e-05, \"loss\": 0.8200554738069186, \"step\": 225000}\n",
      "{\"learning_rate\": 3.447095897165382e-05, \"loss\": 0.7506187466587871, \"step\": 225500}\n",
      "{\"learning_rate\": 3.443652650817634e-05, \"loss\": 0.7912014969596057, \"step\": 226000}\n",
      "{\"learning_rate\": 3.440209404469885e-05, \"loss\": 0.7613821310300846, \"step\": 226500}\n",
      "{\"learning_rate\": 3.4367661581221363e-05, \"loss\": 0.7816493307866039, \"step\": 227000}\n",
      "{\"learning_rate\": 3.433322911774387e-05, \"loss\": 0.7604794140111771, \"step\": 227500}\n",
      "{\"learning_rate\": 3.429879665426639e-05, \"loss\": 0.7674089791653678, \"step\": 228000}\n",
      "{\"learning_rate\": 3.4264364190788904e-05, \"loss\": 0.7456893573350389, \"step\": 228500}\n",
      "{\"learning_rate\": 3.422993172731142e-05, \"loss\": 0.7688074956348282, \"step\": 229000}\n",
      "{\"learning_rate\": 3.419549926383393e-05, \"loss\": 0.8038852039905614, \"step\": 229500}\n",
      "{\"learning_rate\": 3.4161066800356445e-05, \"loss\": 0.8013960754216533, \"step\": 230000}\n",
      "{\"learning_rate\": 3.412663433687896e-05, \"loss\": 0.7926163307343959, \"step\": 230500}\n",
      "{\"learning_rate\": 3.409220187340148e-05, \"loss\": 0.8090611839369521, \"step\": 231000}\n",
      "{\"learning_rate\": 3.4057769409923986e-05, \"loss\": 0.7902752139591612, \"step\": 231500}\n",
      "{\"learning_rate\": 3.40233369464465e-05, \"loss\": 0.7689607175643906, \"step\": 232000}\n",
      "{\"learning_rate\": 3.398890448296901e-05, \"loss\": 0.7708535795411444, \"step\": 232500}\n",
      "{\"learning_rate\": 3.395447201949153e-05, \"loss\": 0.7612348162239069, \"step\": 233000}\n",
      "{\"learning_rate\": 3.392003955601404e-05, \"loss\": 0.7364613087192993, \"step\": 233500}\n",
      "{\"learning_rate\": 3.388560709253656e-05, \"loss\": 0.7882276043032179, \"step\": 234000}\n",
      "{\"learning_rate\": 3.3851174629059075e-05, \"loss\": 0.7830085673353169, \"step\": 234500}\n",
      "{\"learning_rate\": 3.381674216558159e-05, \"loss\": 0.8140949197814916, \"step\": 235000}\n",
      "{\"learning_rate\": 3.37823097021041e-05, \"loss\": 0.7685210182173178, \"step\": 235500}\n",
      "{\"learning_rate\": 3.3747877238626616e-05, \"loss\": 0.7718739589431789, \"step\": 236000}\n",
      "{\"learning_rate\": 3.3713444775149125e-05, \"loss\": 0.8002392257287866, \"step\": 236500}\n",
      "{\"learning_rate\": 3.367901231167164e-05, \"loss\": 0.7705234372715931, \"step\": 237000}\n",
      "{\"learning_rate\": 3.364457984819416e-05, \"loss\": 0.771375570188684, \"step\": 237500}\n",
      "{\"learning_rate\": 3.361014738471667e-05, \"loss\": 0.7544822630820563, \"step\": 238000}\n",
      "{\"learning_rate\": 3.357571492123918e-05, \"loss\": 0.7672622991096577, \"step\": 238500}\n",
      "{\"learning_rate\": 3.35412824577617e-05, \"loss\": 0.8235703196582035, \"step\": 239000}\n",
      "{\"learning_rate\": 3.3506849994284214e-05, \"loss\": 0.7053529596447479, \"step\": 239500}\n",
      "{\"learning_rate\": 3.347241753080673e-05, \"loss\": 0.6888585351850488, \"step\": 240000}\n",
      "{\"learning_rate\": 3.343798506732924e-05, \"loss\": 0.779069173343305, \"step\": 240500}\n",
      "{\"learning_rate\": 3.3403552603851755e-05, \"loss\": 0.8185626026507816, \"step\": 241000}\n",
      "{\"learning_rate\": 3.336912014037427e-05, \"loss\": 0.7587614216069923, \"step\": 241500}\n",
      "{\"learning_rate\": 3.333468767689678e-05, \"loss\": 0.7448737292449222, \"step\": 242000}\n",
      "{\"learning_rate\": 3.3300255213419296e-05, \"loss\": 0.7575633400715306, \"step\": 242500}\n",
      "{\"learning_rate\": 3.326582274994181e-05, \"loss\": 0.7783534976635128, \"step\": 243000}\n",
      "{\"learning_rate\": 3.323139028646433e-05, \"loss\": 0.7452305251599173, \"step\": 243500}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 3.3196957822986844e-05, \"loss\": 0.7511103374394588, \"step\": 244000}\n",
      "{\"learning_rate\": 3.316252535950935e-05, \"loss\": 0.7918159833043464, \"step\": 244500}\n",
      "{\"learning_rate\": 3.312809289603186e-05, \"loss\": 0.7501795361214899, \"step\": 245000}\n",
      "{\"learning_rate\": 3.309366043255438e-05, \"loss\": 0.7422823944471892, \"step\": 245500}\n",
      "{\"learning_rate\": 3.3059227969076894e-05, \"loss\": 0.7486663870817866, \"step\": 246000}\n",
      "{\"learning_rate\": 3.302479550559941e-05, \"loss\": 0.776867061635945, \"step\": 246500}\n",
      "{\"learning_rate\": 3.2990363042121926e-05, \"loss\": 0.7500085404460551, \"step\": 247000}\n",
      "{\"learning_rate\": 3.295593057864444e-05, \"loss\": 0.7772092489778879, \"step\": 247500}\n",
      "{\"learning_rate\": 3.292149811516695e-05, \"loss\": 0.7961380813274882, \"step\": 248000}\n",
      "{\"learning_rate\": 3.288706565168947e-05, \"loss\": 0.7667715988084673, \"step\": 248500}\n",
      "{\"learning_rate\": 3.2852633188211976e-05, \"loss\": 0.7729319072070066, \"step\": 249000}\n",
      "{\"learning_rate\": 3.281820072473449e-05, \"loss\": 0.7665844147673342, \"step\": 249500}\n",
      "{\"learning_rate\": 3.278376826125701e-05, \"loss\": 0.7461072628615657, \"step\": 250000}\n",
      "{\"learning_rate\": 3.2749335797779524e-05, \"loss\": 0.7141043568148744, \"step\": 250500}\n",
      "{\"learning_rate\": 3.271490333430203e-05, \"loss\": 0.7649962923646672, \"step\": 251000}\n",
      "{\"learning_rate\": 3.268047087082455e-05, \"loss\": 0.7943530482040368, \"step\": 251500}\n",
      "{\"learning_rate\": 3.2646038407347065e-05, \"loss\": 0.8175312845912995, \"step\": 252000}\n",
      "{\"learning_rate\": 3.261160594386958e-05, \"loss\": 0.7638550702615757, \"step\": 252500}\n",
      "{\"learning_rate\": 3.257717348039209e-05, \"loss\": 0.7562838315815897, \"step\": 253000}\n",
      "{\"learning_rate\": 3.2542741016914606e-05, \"loss\": 0.7644671196051058, \"step\": 253500}\n",
      "{\"learning_rate\": 3.2508308553437115e-05, \"loss\": 0.7033848888048669, \"step\": 254000}\n",
      "{\"learning_rate\": 3.247387608995963e-05, \"loss\": 0.7511844389460166, \"step\": 254500}\n",
      "{\"learning_rate\": 3.243944362648215e-05, \"loss\": 0.7627067444210407, \"step\": 255000}\n",
      "{\"learning_rate\": 3.240501116300466e-05, \"loss\": 0.7745573159779887, \"step\": 255500}\n",
      "{\"learning_rate\": 3.237057869952718e-05, \"loss\": 0.7108464136414695, \"step\": 256000}\n",
      "{\"learning_rate\": 3.2336146236049694e-05, \"loss\": 0.7178359292123933, \"step\": 256500}\n",
      "{\"learning_rate\": 3.2301713772572204e-05, \"loss\": 0.7535440474628704, \"step\": 257000}\n",
      "{\"learning_rate\": 3.226728130909471e-05, \"loss\": 0.7433768156450242, \"step\": 257500}\n",
      "{\"learning_rate\": 3.223284884561723e-05, \"loss\": 0.7111799073017319, \"step\": 258000}\n",
      "{\"learning_rate\": 3.2198416382139745e-05, \"loss\": 0.7218915281004739, \"step\": 258500}\n",
      "{\"learning_rate\": 3.216398391866226e-05, \"loss\": 0.8148268597215065, \"step\": 259000}\n",
      "{\"learning_rate\": 3.2129551455184776e-05, \"loss\": 0.792272762385779, \"step\": 259500}\n",
      "{\"learning_rate\": 3.2095118991707286e-05, \"loss\": 0.7462298428437789, \"step\": 260000}\n",
      "{\"learning_rate\": 3.20606865282298e-05, \"loss\": 0.778983610093419, \"step\": 260500}\n",
      "{\"learning_rate\": 3.202625406475232e-05, \"loss\": 0.8172134024898405, \"step\": 261000}\n",
      "{\"learning_rate\": 3.1991821601274827e-05, \"loss\": 0.7722715509831324, \"step\": 261500}\n",
      "{\"learning_rate\": 3.195738913779734e-05, \"loss\": 0.8246952239832608, \"step\": 262000}\n",
      "{\"learning_rate\": 3.192295667431986e-05, \"loss\": 0.7357271961931837, \"step\": 262500}\n",
      "{\"learning_rate\": 3.188852421084237e-05, \"loss\": 0.7243841627689545, \"step\": 263000}\n",
      "{\"learning_rate\": 3.1854091747364883e-05, \"loss\": 0.7645609169526724, \"step\": 263500}\n",
      "{\"learning_rate\": 3.18196592838874e-05, \"loss\": 0.7517119229089585, \"step\": 264000}\n",
      "{\"learning_rate\": 3.1785226820409915e-05, \"loss\": 0.7635085862487904, \"step\": 264500}\n",
      "{\"learning_rate\": 3.175079435693243e-05, \"loss\": 0.7765034040733008, \"step\": 265000}\n",
      "{\"learning_rate\": 3.171636189345494e-05, \"loss\": 0.7191975764663076, \"step\": 265500}\n",
      "{\"learning_rate\": 3.168192942997745e-05, \"loss\": 0.7428052334777895, \"step\": 266000}\n",
      "{\"learning_rate\": 3.1647496966499965e-05, \"loss\": 0.7898031408129609, \"step\": 266500}\n",
      "{\"learning_rate\": 3.161306450302248e-05, \"loss\": 0.7516825044014258, \"step\": 267000}\n",
      "{\"learning_rate\": 3.1578632039545e-05, \"loss\": 0.7401556991680409, \"step\": 267500}\n",
      "{\"learning_rate\": 3.154419957606751e-05, \"loss\": 0.7261850405459991, \"step\": 268000}\n",
      "{\"learning_rate\": 3.150976711259003e-05, \"loss\": 0.7536568116230774, \"step\": 268500}\n",
      "{\"learning_rate\": 3.147533464911254e-05, \"loss\": 0.7069431805761415, \"step\": 269000}\n",
      "{\"learning_rate\": 3.1440902185635054e-05, \"loss\": 0.7142930680295103, \"step\": 269500}\n",
      "{\"learning_rate\": 3.140646972215756e-05, \"loss\": 0.7649256089666742, \"step\": 270000}\n",
      "{\"learning_rate\": 3.137203725868008e-05, \"loss\": 0.824570561166911, \"step\": 270500}\n",
      "{\"learning_rate\": 3.1337604795202595e-05, \"loss\": 0.7339301969783264, \"step\": 271000}\n",
      "{\"learning_rate\": 3.130317233172511e-05, \"loss\": 0.7374134089072468, \"step\": 271500}\n",
      "{\"learning_rate\": 3.126873986824762e-05, \"loss\": 0.7502551798899658, \"step\": 272000}\n",
      "{\"learning_rate\": 3.1234307404770136e-05, \"loss\": 0.8008280518677784, \"step\": 272500}\n",
      "{\"learning_rate\": 3.119987494129265e-05, \"loss\": 0.7418130153903622, \"step\": 273000}\n",
      "{\"learning_rate\": 3.116544247781517e-05, \"loss\": 0.7568203645674512, \"step\": 273500}\n",
      "{\"learning_rate\": 3.113101001433768e-05, \"loss\": 0.7271679280070821, \"step\": 274000}\n",
      "{\"learning_rate\": 3.109657755086019e-05, \"loss\": 0.7781223446131335, \"step\": 274500}\n",
      "{\"learning_rate\": 3.10621450873827e-05, \"loss\": 0.7382779131919378, \"step\": 275000}\n",
      "{\"learning_rate\": 3.102771262390522e-05, \"loss\": 0.7146981885849963, \"step\": 275500}\n",
      "{\"learning_rate\": 3.0993280160427734e-05, \"loss\": 0.7467367882470135, \"step\": 276000}\n",
      "{\"learning_rate\": 3.095884769695025e-05, \"loss\": 0.7450099364878261, \"step\": 276500}\n",
      "{\"learning_rate\": 3.0924415233472766e-05, \"loss\": 0.7696433096278342, \"step\": 277000}\n",
      "{\"learning_rate\": 3.088998276999528e-05, \"loss\": 0.7664842924925033, \"step\": 277500}\n",
      "{\"learning_rate\": 3.085555030651779e-05, \"loss\": 0.7780621020047692, \"step\": 278000}\n",
      "{\"learning_rate\": 3.082111784304031e-05, \"loss\": 0.7015447578272433, \"step\": 278500}\n",
      "{\"learning_rate\": 3.0786685379562816e-05, \"loss\": 0.7349616354377358, \"step\": 279000}\n",
      "{\"learning_rate\": 3.075225291608533e-05, \"loss\": 0.7290576254000188, \"step\": 279500}\n",
      "{\"learning_rate\": 3.071782045260785e-05, \"loss\": 0.6985681504237582, \"step\": 280000}\n",
      "{\"learning_rate\": 3.0683387989130364e-05, \"loss\": 0.6970966331990784, \"step\": 280500}\n",
      "{\"learning_rate\": 3.064895552565287e-05, \"loss\": 0.7339677287571831, \"step\": 281000}\n",
      "{\"learning_rate\": 3.061452306217539e-05, \"loss\": 0.7631659461631207, \"step\": 281500}\n",
      "{\"learning_rate\": 3.0580090598697905e-05, \"loss\": 0.741167217479553, \"step\": 282000}\n",
      "{\"learning_rate\": 3.054565813522042e-05, \"loss\": 0.770987055676058, \"step\": 282500}\n",
      "{\"learning_rate\": 3.0511225671742933e-05, \"loss\": 0.7339304991884855, \"step\": 283000}\n",
      "{\"learning_rate\": 3.0476793208265446e-05, \"loss\": 0.7814757566507906, \"step\": 283500}\n",
      "{\"learning_rate\": 3.0442360744787962e-05, \"loss\": 0.7243168233333854, \"step\": 284000}\n",
      "{\"learning_rate\": 3.040792828131047e-05, \"loss\": 0.7687507304391474, \"step\": 284500}\n",
      "{\"learning_rate\": 3.0373495817832987e-05, \"loss\": 0.7210268790640985, \"step\": 285000}\n",
      "{\"learning_rate\": 3.0339063354355503e-05, \"loss\": 0.781258979375416, \"step\": 285500}\n",
      "{\"learning_rate\": 3.0304630890878015e-05, \"loss\": 0.7492550278434065, \"step\": 286000}\n",
      "{\"learning_rate\": 3.027019842740053e-05, \"loss\": 0.7225874279014534, \"step\": 286500}\n",
      "{\"learning_rate\": 3.0235765963923047e-05, \"loss\": 0.7018873935285374, \"step\": 287000}\n",
      "{\"learning_rate\": 3.0201333500445556e-05, \"loss\": 0.7840242109511164, \"step\": 287500}\n",
      "{\"learning_rate\": 3.016690103696807e-05, \"loss\": 0.7150033518190612, \"step\": 288000}\n",
      "{\"learning_rate\": 3.0132468573490585e-05, \"loss\": 0.7402292101338971, \"step\": 288500}\n",
      "{\"learning_rate\": 3.00980361100131e-05, \"loss\": 0.6930270813923562, \"step\": 289000}\n",
      "{\"learning_rate\": 3.0063603646535617e-05, \"loss\": 0.7320716914202203, \"step\": 289500}\n",
      "{\"learning_rate\": 3.002917118305813e-05, \"loss\": 0.7275515429567313, \"step\": 290000}\n",
      "{\"learning_rate\": 2.9994738719580638e-05, \"loss\": 0.7708127022560802, \"step\": 290500}\n",
      "{\"learning_rate\": 2.9960306256103154e-05, \"loss\": 0.7533831485285772, \"step\": 291000}\n",
      "{\"learning_rate\": 2.992587379262567e-05, \"loss\": 0.722067834852729, \"step\": 291500}\n",
      "{\"learning_rate\": 2.9891441329148183e-05, \"loss\": 0.70597668225714, \"step\": 292000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.98570088656707e-05, \"loss\": 0.7078801317150355, \"step\": 292500}\n",
      "{\"learning_rate\": 2.9822576402193214e-05, \"loss\": 0.7051207033359679, \"step\": 293000}\n",
      "{\"learning_rate\": 2.9788143938715724e-05, \"loss\": 0.7384628188645583, \"step\": 293500}\n",
      "{\"learning_rate\": 2.975371147523824e-05, \"loss\": 0.7432608873437857, \"step\": 294000}\n",
      "{\"learning_rate\": 2.9719279011760752e-05, \"loss\": 0.7133902367451228, \"step\": 294500}\n",
      "{\"learning_rate\": 2.9684846548283268e-05, \"loss\": 0.7094753919169307, \"step\": 295000}\n",
      "{\"learning_rate\": 2.9650414084805784e-05, \"loss\": 0.8134497964789044, \"step\": 295500}\n",
      "{\"learning_rate\": 2.96159816213283e-05, \"loss\": 0.6903568398854113, \"step\": 296000}\n",
      "{\"learning_rate\": 2.958154915785081e-05, \"loss\": 0.7219382066019462, \"step\": 296500}\n",
      "{\"learning_rate\": 2.954711669437332e-05, \"loss\": 0.7347362997443997, \"step\": 297000}\n",
      "{\"learning_rate\": 2.9512684230895837e-05, \"loss\": 0.7107219704232993, \"step\": 297500}\n",
      "{\"learning_rate\": 2.9478251767418353e-05, \"loss\": 0.7188432400324382, \"step\": 298000}\n",
      "{\"learning_rate\": 2.9443819303940866e-05, \"loss\": 0.7258346021128819, \"step\": 298500}\n",
      "{\"learning_rate\": 2.9409386840463382e-05, \"loss\": 0.7770222365677473, \"step\": 299000}\n",
      "{\"learning_rate\": 2.937495437698589e-05, \"loss\": 0.7424298593984567, \"step\": 299500}\n",
      "{\"learning_rate\": 2.9340521913508407e-05, \"loss\": 0.7533858237217064, \"step\": 300000}\n",
      "{\"learning_rate\": 2.9306089450030923e-05, \"loss\": 0.7321015484233503, \"step\": 300500}\n",
      "{\"learning_rate\": 2.9271656986553435e-05, \"loss\": 0.7414172732507577, \"step\": 301000}\n",
      "{\"learning_rate\": 2.923722452307595e-05, \"loss\": 0.7050657306692446, \"step\": 301500}\n",
      "{\"learning_rate\": 2.9202792059598467e-05, \"loss\": 0.7683658279113588, \"step\": 302000}\n",
      "{\"learning_rate\": 2.9168359596120976e-05, \"loss\": 0.7544211775074946, \"step\": 302500}\n",
      "{\"learning_rate\": 2.913392713264349e-05, \"loss\": 0.6689562086671358, \"step\": 303000}\n",
      "{\"learning_rate\": 2.9099494669166005e-05, \"loss\": 0.7022131896806532, \"step\": 303500}\n",
      "{\"learning_rate\": 2.906506220568852e-05, \"loss\": 0.680058757918363, \"step\": 304000}\n",
      "{\"learning_rate\": 2.9030629742211037e-05, \"loss\": 0.6959075558163459, \"step\": 304500}\n",
      "{\"learning_rate\": 2.899619727873355e-05, \"loss\": 0.7291634625970037, \"step\": 305000}\n",
      "{\"learning_rate\": 2.8961764815256058e-05, \"loss\": 0.7482617209294112, \"step\": 305500}\n",
      "{\"learning_rate\": 2.8927332351778574e-05, \"loss\": 0.7120958044748986, \"step\": 306000}\n",
      "{\"learning_rate\": 2.889289988830109e-05, \"loss\": 0.7461684637578437, \"step\": 306500}\n",
      "{\"learning_rate\": 2.8858467424823603e-05, \"loss\": 0.70439073642937, \"step\": 307000}\n",
      "{\"learning_rate\": 2.882403496134612e-05, \"loss\": 0.7369596535551828, \"step\": 307500}\n",
      "{\"learning_rate\": 2.8789602497868634e-05, \"loss\": 0.7341346952024033, \"step\": 308000}\n",
      "{\"learning_rate\": 2.8755170034391144e-05, \"loss\": 0.7239797992876266, \"step\": 308500}\n",
      "{\"learning_rate\": 2.872073757091366e-05, \"loss\": 0.7336641661744797, \"step\": 309000}\n",
      "{\"learning_rate\": 2.8651872643958688e-05, \"loss\": 0.750017412083107, \"step\": 310000}\n",
      "{\"learning_rate\": 2.8617440180481204e-05, \"loss\": 0.6737946454141056, \"step\": 310500}\n",
      "{\"learning_rate\": 2.8583007717003716e-05, \"loss\": 0.7402760822830023, \"step\": 311000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.8273115545706343e-05, \"loss\": 0.666385770434048, \"step\": 315500}\n",
      "{\"learning_rate\": 2.8238683082228855e-05, \"loss\": 0.7460331835284596, \"step\": 316000}\n",
      "{\"learning_rate\": 2.820425061875137e-05, \"loss\": 0.7085733144995756, \"step\": 316500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.792879091093148e-05, \"loss\": 0.7457670519700041, \"step\": 320500}\n",
      "{\"learning_rate\": 2.7894358447453994e-05, \"loss\": 0.7872179093390005, \"step\": 321000}\n",
      "{\"learning_rate\": 2.785992598397651e-05, \"loss\": 0.6927761429834646, \"step\": 321500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.7550033812679137e-05, \"loss\": 0.678157329391921, \"step\": 326000}\n",
      "{\"learning_rate\": 2.7515601349201652e-05, \"loss\": 0.6746771611513104, \"step\": 326500}\n",
      "{\"learning_rate\": 2.748116888572416e-05, \"loss\": 0.6846131248038728, \"step\": 327000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.7205709177904275e-05, \"loss\": 0.7620166475606384, \"step\": 331000}\n",
      "{\"learning_rate\": 2.717127671442679e-05, \"loss\": 0.6910430952843745, \"step\": 331500}\n",
      "{\"learning_rate\": 2.7136844250949307e-05, \"loss\": 0.7103583382650978, \"step\": 332000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.6861384543129414e-05, \"loss\": 0.7188261761637404, \"step\": 336000}\n",
      "{\"learning_rate\": 2.682695207965193e-05, \"loss\": 0.7427125561344438, \"step\": 336500}\n",
      "{\"learning_rate\": 2.6792519616174443e-05, \"loss\": 0.7311752675380557, \"step\": 337000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.6482627444877073e-05, \"loss\": 0.6920542022710433, \"step\": 341500}\n",
      "{\"learning_rate\": 2.644819498139958e-05, \"loss\": 0.7521905073089292, \"step\": 342000}\n",
      "{\"learning_rate\": 2.6413762517922098e-05, \"loss\": 0.7574270016791997, \"step\": 342500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.613830281010221e-05, \"loss\": 0.6991853385758586, \"step\": 346500}\n",
      "{\"learning_rate\": 2.6103870346624727e-05, \"loss\": 0.7108871587202884, \"step\": 347000}\n",
      "{\"learning_rate\": 2.606943788314724e-05, \"loss\": 0.7189361297154101, \"step\": 347500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.579397817532735e-05, \"loss\": 0.7039831940280273, \"step\": 351500}\n",
      "{\"learning_rate\": 2.5759545711849863e-05, \"loss\": 0.7097976570728933, \"step\": 352000}\n",
      "{\"learning_rate\": 2.572511324837238e-05, \"loss\": 0.662199203221011, \"step\": 352500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.5415221077075002e-05, \"loss\": 0.7496968929107534, \"step\": 357000}\n",
      "{\"learning_rate\": 2.5380788613597518e-05, \"loss\": 0.6914153278968297, \"step\": 357500}\n",
      "{\"learning_rate\": 2.5346356150120034e-05, \"loss\": 0.7101161346673034, \"step\": 358000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.5070896442300147e-05, \"loss\": 0.7313222089697374, \"step\": 362000}\n",
      "{\"learning_rate\": 2.503646397882266e-05, \"loss\": 0.6845640025360044, \"step\": 362500}\n",
      "{\"learning_rate\": 2.5002031515345176e-05, \"loss\": 0.6409277769409819, \"step\": 363000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.46921393440478e-05, \"loss\": 0.6539081823622109, \"step\": 367500}\n",
      "{\"learning_rate\": 2.4657706880570315e-05, \"loss\": 0.7107003966228803, \"step\": 368000}\n",
      "{\"learning_rate\": 2.4623274417092827e-05, \"loss\": 0.6957298236648785, \"step\": 368500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.4382247172750425e-05, \"loss\": 0.6974742101352894, \"step\": 372000}\n",
      "{\"learning_rate\": 2.434781470927294e-05, \"loss\": 0.6712057191532804, \"step\": 372500}\n",
      "{\"learning_rate\": 2.431338224579545e-05, \"loss\": 0.7222254573391983, \"step\": 373000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.4003490074498077e-05, \"loss\": 0.7258223102230112, \"step\": 377500}\n",
      "{\"learning_rate\": 2.3969057611020592e-05, \"loss\": 0.6568360497647664, \"step\": 378000}\n",
      "{\"learning_rate\": 2.393462514754311e-05, \"loss\": 0.6890550060190727, \"step\": 378500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.365916543972322e-05, \"loss\": 0.6441626700412016, \"step\": 382500}\n",
      "{\"learning_rate\": 2.3624732976245735e-05, \"loss\": 0.674004056379199, \"step\": 383000}\n",
      "{\"learning_rate\": 2.3590300512768247e-05, \"loss\": 0.6957761726356112, \"step\": 383500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 2.3280408341470874e-05, \"loss\": 0.6440868061867077, \"step\": 388000}\n",
      "{\"learning_rate\": 2.3245975877993386e-05, \"loss\": 0.6721380697549321, \"step\": 388500}\n",
      "{\"learning_rate\": 2.3211543414515902e-05, \"loss\": 0.6966499191649491, \"step\": 389000}\n",
      "{\"learning_rate\": 2.3177110951038418e-05, \"loss\": 0.7378219171396923, \"step\": 389500}\n",
      "{\"learning_rate\": 2.3142678487560927e-05, \"loss\": 0.5965011261828477, \"step\": 390000}\n",
      "{\"learning_rate\": 2.3108246024083443e-05, \"loss\": 0.6889020867703948, \"step\": 390500}\n",
      "{\"learning_rate\": 2.307381356060596e-05, \"loss\": 0.6245080675366335, \"step\": 391000}\n",
      "{\"learning_rate\": 2.303938109712847e-05, \"loss\": 0.6930900819236413, \"step\": 391500}\n",
      "{\"learning_rate\": 2.3004948633650984e-05, \"loss\": 0.6689649843821535, \"step\": 392000}\n",
      "{\"learning_rate\": 2.29705161701735e-05, \"loss\": 0.6427200233323965, \"step\": 392500}\n",
      "{\"learning_rate\": 2.2936083706696013e-05, \"loss\": 0.6916865670253756, \"step\": 393000}\n",
      "{\"learning_rate\": 2.290165124321853e-05, \"loss\": 0.7015866970072966, \"step\": 393500}\n",
      "{\"learning_rate\": 2.286721877974104e-05, \"loss\": 0.6758372795317554, \"step\": 394000}\n",
      "{\"learning_rate\": 2.2832786316263554e-05, \"loss\": 0.6969119681786978, \"step\": 394500}\n",
      "{\"learning_rate\": 2.279835385278607e-05, \"loss\": 0.6852752819020534, \"step\": 395000}\n",
      "{\"learning_rate\": 2.2763921389308585e-05, \"loss\": 0.669589947342407, \"step\": 395500}\n",
      "{\"learning_rate\": 2.2729488925831098e-05, \"loss\": 0.7127339140598197, \"step\": 396000}\n",
      "{\"learning_rate\": 2.269505646235361e-05, \"loss\": 0.6562794022525195, \"step\": 396500}\n",
      "{\"learning_rate\": 2.2660623998876126e-05, \"loss\": 0.6274369802883594, \"step\": 397000}\n",
      "{\"learning_rate\": 2.262619153539864e-05, \"loss\": 0.6836600842403714, \"step\": 397500}\n",
      "{\"learning_rate\": 2.2591759071921155e-05, \"loss\": 0.7210718001243659, \"step\": 398000}\n",
      "{\"learning_rate\": 2.2557326608443667e-05, \"loss\": 0.6433515943221282, \"step\": 398500}\n",
      "{\"learning_rate\": 2.252289414496618e-05, \"loss\": 0.6830841408646665, \"step\": 399000}\n",
      "{\"learning_rate\": 2.2488461681488696e-05, \"loss\": 0.6460941368212225, \"step\": 399500}\n",
      "{\"learning_rate\": 2.2454029218011212e-05, \"loss\": 0.6565060552811482, \"step\": 400000}\n",
      "{\"learning_rate\": 2.2419596754533724e-05, \"loss\": 0.695042924425914, \"step\": 400500}\n",
      "{\"learning_rate\": 2.2385164291056237e-05, \"loss\": 0.6658031340448651, \"step\": 401000}\n",
      "{\"learning_rate\": 2.2350731827578753e-05, \"loss\": 0.7243279061877401, \"step\": 401500}\n",
      "{\"learning_rate\": 2.2316299364101265e-05, \"loss\": 0.662981356268283, \"step\": 402000}\n",
      "{\"learning_rate\": 2.228186690062378e-05, \"loss\": 0.7176451171775116, \"step\": 402500}\n",
      "{\"learning_rate\": 2.2247434437146294e-05, \"loss\": 0.6629903036135947, \"step\": 403000}\n",
      "{\"learning_rate\": 2.2213001973668806e-05, \"loss\": 0.7020699965968961, \"step\": 403500}\n",
      "{\"learning_rate\": 2.2178569510191322e-05, \"loss\": 0.6511137430163799, \"step\": 404000}\n",
      "{\"learning_rate\": 2.2144137046713838e-05, \"loss\": 0.691354596354533, \"step\": 404500}\n",
      "{\"learning_rate\": 2.2109704583236347e-05, \"loss\": 0.6616532311270712, \"step\": 405000}\n",
      "{\"learning_rate\": 2.2075272119758863e-05, \"loss\": 0.6890498764085351, \"step\": 405500}\n",
      "{\"learning_rate\": 2.204083965628138e-05, \"loss\": 0.7077865492799319, \"step\": 406000}\n",
      "{\"learning_rate\": 2.200640719280389e-05, \"loss\": 0.6682785862117308, \"step\": 406500}\n",
      "{\"learning_rate\": 2.1971974729326404e-05, \"loss\": 0.6263012091185665, \"step\": 407000}\n",
      "{\"learning_rate\": 2.193754226584892e-05, \"loss\": 0.6476577839737292, \"step\": 407500}\n",
      "{\"learning_rate\": 2.1903109802371433e-05, \"loss\": 0.6849024776677833, \"step\": 408000}\n",
      "{\"learning_rate\": 2.186867733889395e-05, \"loss\": 0.7494832718466642, \"step\": 408500}\n",
      "{\"learning_rate\": 2.183424487541646e-05, \"loss\": 0.6825177529833745, \"step\": 409000}\n",
      "{\"learning_rate\": 2.1799812411938974e-05, \"loss\": 0.6527943319367477, \"step\": 409500}\n",
      "{\"learning_rate\": 2.176537994846149e-05, \"loss\": 0.6920223827528534, \"step\": 410000}\n",
      "{\"learning_rate\": 2.1730947484984005e-05, \"loss\": 0.6777880471576937, \"step\": 410500}\n",
      "{\"learning_rate\": 2.1696515021506518e-05, \"loss\": 0.6286843687167857, \"step\": 411000}\n",
      "{\"learning_rate\": 2.166208255802903e-05, \"loss\": 0.6558039046097547, \"step\": 411500}\n",
      "{\"learning_rate\": 2.1627650094551546e-05, \"loss\": 0.6582603158324491, \"step\": 412000}\n",
      "{\"learning_rate\": 2.159321763107406e-05, \"loss\": 0.6362394452263834, \"step\": 412500}\n",
      "{\"learning_rate\": 2.1558785167596575e-05, \"loss\": 0.6583742400537013, \"step\": 413000}\n",
      "{\"learning_rate\": 2.1524352704119087e-05, \"loss\": 0.6740383433331736, \"step\": 413500}\n",
      "{\"learning_rate\": 2.14899202406416e-05, \"loss\": 0.6731803421922959, \"step\": 414000}\n",
      "{\"learning_rate\": 2.1455487777164116e-05, \"loss\": 0.6868510343129747, \"step\": 414500}\n",
      "{\"learning_rate\": 2.1421055313686632e-05, \"loss\": 0.6514376849498367, \"step\": 415000}\n",
      "{\"learning_rate\": 2.138662285020914e-05, \"loss\": 0.690169842720381, \"step\": 415500}\n",
      "{\"learning_rate\": 2.1352190386731657e-05, \"loss\": 0.6637957158276113, \"step\": 416000}\n",
      "{\"learning_rate\": 2.1317757923254173e-05, \"loss\": 0.6643039420010755, \"step\": 416500}\n",
      "{\"learning_rate\": 2.1283325459776685e-05, \"loss\": 0.7144691773664672, \"step\": 417000}\n",
      "{\"learning_rate\": 2.1248892996299198e-05, \"loss\": 0.6694104730820982, \"step\": 417500}\n",
      "{\"learning_rate\": 2.1214460532821714e-05, \"loss\": 0.6675999213861069, \"step\": 418000}\n",
      "{\"learning_rate\": 2.1180028069344226e-05, \"loss\": 0.6628429576186463, \"step\": 418500}\n",
      "{\"learning_rate\": 2.1145595605866742e-05, \"loss\": 0.6216363455033861, \"step\": 419000}\n",
      "{\"learning_rate\": 2.1111163142389255e-05, \"loss\": 0.6278399072327884, \"step\": 419500}\n",
      "{\"learning_rate\": 2.1076730678911767e-05, \"loss\": 0.6819829602977261, \"step\": 420000}\n",
      "{\"learning_rate\": 2.1042298215434283e-05, \"loss\": 0.6829946730898228, \"step\": 420500}\n",
      "{\"learning_rate\": 2.10078657519568e-05, \"loss\": 0.6649791379048257, \"step\": 421000}\n",
      "{\"learning_rate\": 2.097343328847931e-05, \"loss\": 0.6566242364370264, \"step\": 421500}\n",
      "{\"learning_rate\": 2.0939000825001824e-05, \"loss\": 0.6444990846398286, \"step\": 422000}\n",
      "{\"learning_rate\": 2.090456836152434e-05, \"loss\": 0.6735359135858016, \"step\": 422500}\n",
      "{\"learning_rate\": 2.0870135898046856e-05, \"loss\": 0.6374655885611428, \"step\": 423000}\n",
      "{\"learning_rate\": 2.083570343456937e-05, \"loss\": 0.6832887099473737, \"step\": 423500}\n",
      "{\"learning_rate\": 2.080127097109188e-05, \"loss\": 0.6597583012863761, \"step\": 424000}\n",
      "{\"learning_rate\": 2.0766838507614397e-05, \"loss\": 0.7049088824550854, \"step\": 424500}\n",
      "{\"learning_rate\": 2.073240604413691e-05, \"loss\": 0.6558722101000604, \"step\": 425000}\n",
      "{\"learning_rate\": 2.0663541117181938e-05, \"loss\": 0.6605635430867551, \"step\": 426000}\n",
      "{\"learning_rate\": 2.062910865370445e-05, \"loss\": 0.6532625521495938, \"step\": 426500}\n",
      "{\"learning_rate\": 2.0594676190226966e-05, \"loss\": 0.6986576041473309, \"step\": 427000}\n",
      "{\"learning_rate\": 2.0560243726749482e-05, \"loss\": 0.6276666386175203, \"step\": 427500}\n",
      "{\"learning_rate\": 2.0525811263271995e-05, \"loss\": 0.6314429406338604, \"step\": 428000}\n",
      "{\"learning_rate\": 2.0491378799794507e-05, \"loss\": 0.669398814802873, \"step\": 428500}\n",
      "{\"learning_rate\": 2.0456946336317023e-05, \"loss\": 0.6489114537609275, \"step\": 429000}\n",
      "{\"learning_rate\": 2.0422513872839536e-05, \"loss\": 0.6797438580587041, \"step\": 429500}\n",
      "{\"learning_rate\": 2.0388081409362052e-05, \"loss\": 0.6742409266836475, \"step\": 430000}\n",
      "{\"learning_rate\": 2.0353648945884564e-05, \"loss\": 0.6122947195847519, \"step\": 430500}\n",
      "{\"learning_rate\": 2.0319216482407077e-05, \"loss\": 0.6573124334972817, \"step\": 431000}\n",
      "{\"learning_rate\": 2.0284784018929593e-05, \"loss\": 0.6851899400884286, \"step\": 431500}\n",
      "{\"learning_rate\": 2.025035155545211e-05, \"loss\": 0.6626409911669325, \"step\": 432000}\n",
      "{\"learning_rate\": 2.0215919091974618e-05, \"loss\": 0.6806024312051013, \"step\": 432500}\n",
      "{\"learning_rate\": 2.0181486628497134e-05, \"loss\": 0.6834047693626489, \"step\": 433000}\n",
      "{\"learning_rate\": 2.014705416501965e-05, \"loss\": 0.6168695923475316, \"step\": 433500}\n",
      "{\"learning_rate\": 2.0112621701542162e-05, \"loss\": 0.6091243659380124, \"step\": 434000}\n",
      "{\"learning_rate\": 2.0078189238064675e-05, \"loss\": 0.6961028907620348, \"step\": 434500}\n",
      "{\"learning_rate\": 2.004375677458719e-05, \"loss\": 0.6058146632425487, \"step\": 435000}\n",
      "{\"learning_rate\": 2.0009324311109703e-05, \"loss\": 0.6974254065192071, \"step\": 435500}\n",
      "{\"learning_rate\": 1.997489184763222e-05, \"loss\": 0.6544231415167451, \"step\": 436000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 1.9940459384154732e-05, \"loss\": 0.64695948421082, \"step\": 436500}\n",
      "{\"learning_rate\": 1.9906026920677244e-05, \"loss\": 0.6229276548451744, \"step\": 437000}\n",
      "{\"learning_rate\": 1.987159445719976e-05, \"loss\": 0.662010261772899, \"step\": 437500}\n",
      "{\"learning_rate\": 1.9837161993722276e-05, \"loss\": 0.6436692539805081, \"step\": 438000}\n",
      "{\"learning_rate\": 1.980272953024479e-05, \"loss\": 0.6890841130764457, \"step\": 438500}\n",
      "{\"learning_rate\": 1.97682970667673e-05, \"loss\": 0.6476281849092338, \"step\": 439000}\n",
      "{\"learning_rate\": 1.9733864603289817e-05, \"loss\": 0.659025902314228, \"step\": 439500}\n",
      "{\"learning_rate\": 1.969943213981233e-05, \"loss\": 0.67005514908419, \"step\": 440000}\n",
      "{\"learning_rate\": 1.9664999676334846e-05, \"loss\": 0.632789166830713, \"step\": 440500}\n",
      "{\"learning_rate\": 1.9630567212857358e-05, \"loss\": 0.6606000384489307, \"step\": 441000}\n",
      "{\"learning_rate\": 1.959613474937987e-05, \"loss\": 0.6393109295028262, \"step\": 441500}\n",
      "{\"learning_rate\": 1.9561702285902387e-05, \"loss\": 0.677620333700208, \"step\": 442000}\n",
      "{\"learning_rate\": 1.9527269822424902e-05, \"loss\": 0.6763551742222625, \"step\": 442500}\n",
      "{\"learning_rate\": 1.9492837358947415e-05, \"loss\": 0.7238042346677975, \"step\": 443000}\n",
      "{\"learning_rate\": 1.9458404895469928e-05, \"loss\": 0.670949786812882, \"step\": 443500}\n",
      "{\"learning_rate\": 1.9423972431992443e-05, \"loss\": 0.7047838316577254, \"step\": 444000}\n",
      "{\"learning_rate\": 1.9389539968514956e-05, \"loss\": 0.6776520630653249, \"step\": 444500}\n",
      "{\"learning_rate\": 1.9355107505037472e-05, \"loss\": 0.6374721171702258, \"step\": 445000}\n",
      "{\"learning_rate\": 1.9320675041559984e-05, \"loss\": 0.628202719334513, \"step\": 445500}\n",
      "{\"learning_rate\": 1.9286242578082497e-05, \"loss\": 0.6303509295048425, \"step\": 446000}\n",
      "{\"learning_rate\": 1.9251810114605013e-05, \"loss\": 0.6438142484778072, \"step\": 446500}\n",
      "{\"learning_rate\": 1.921737765112753e-05, \"loss\": 0.65859485024272, \"step\": 447000}\n",
      "{\"learning_rate\": 1.9182945187650038e-05, \"loss\": 0.6441357737540966, \"step\": 447500}\n",
      "{\"learning_rate\": 1.9148512724172554e-05, \"loss\": 0.6842638444680488, \"step\": 448000}\n",
      "{\"learning_rate\": 1.911408026069507e-05, \"loss\": 0.6434008808609797, \"step\": 448500}\n",
      "{\"learning_rate\": 1.9079647797217582e-05, \"loss\": 0.6784901737709297, \"step\": 449000}\n",
      "{\"learning_rate\": 1.9045215333740095e-05, \"loss\": 0.6526445120631251, \"step\": 449500}\n",
      "{\"learning_rate\": 1.901078287026261e-05, \"loss\": 0.6683885693213669, \"step\": 450000}\n",
      "{\"learning_rate\": 1.8976350406785123e-05, \"loss\": 0.7050775153521681, \"step\": 450500}\n",
      "{\"learning_rate\": 1.894191794330764e-05, \"loss\": 0.6588721675839042, \"step\": 451000}\n",
      "{\"learning_rate\": 1.8907485479830152e-05, \"loss\": 0.651994403082761, \"step\": 451500}\n",
      "{\"learning_rate\": 1.8873053016352664e-05, \"loss\": 0.6306038062003209, \"step\": 452000}\n",
      "{\"learning_rate\": 1.883862055287518e-05, \"loss\": 0.6854758348305476, \"step\": 452500}\n",
      "{\"learning_rate\": 1.8804188089397696e-05, \"loss\": 0.6812716270452366, \"step\": 453000}\n",
      "{\"learning_rate\": 1.876975562592021e-05, \"loss\": 0.6740754285572329, \"step\": 453500}\n",
      "{\"learning_rate\": 1.873532316244272e-05, \"loss\": 0.6781761254559969, \"step\": 454000}\n",
      "{\"learning_rate\": 1.8700890698965237e-05, \"loss\": 0.6307717475900426, \"step\": 454500}\n",
      "{\"learning_rate\": 1.866645823548775e-05, \"loss\": 0.6075497948589036, \"step\": 455000}\n",
      "{\"learning_rate\": 1.8632025772010266e-05, \"loss\": 0.6056946648320881, \"step\": 455500}\n",
      "{\"learning_rate\": 1.8597593308532778e-05, \"loss\": 0.6891748848446878, \"step\": 456000}\n",
      "{\"learning_rate\": 1.856316084505529e-05, \"loss\": 0.6693586328477832, \"step\": 456500}\n",
      "{\"learning_rate\": 1.8528728381577807e-05, \"loss\": 0.633555893978104, \"step\": 457000}\n",
      "{\"learning_rate\": 1.8494295918100322e-05, \"loss\": 0.6879744186364114, \"step\": 457500}\n",
      "{\"learning_rate\": 1.845986345462283e-05, \"loss\": 0.6805942781089107, \"step\": 458000}\n",
      "{\"learning_rate\": 1.8425430991145348e-05, \"loss\": 0.6522490070697385, \"step\": 458500}\n",
      "{\"learning_rate\": 1.8390998527667863e-05, \"loss\": 0.6651076714583906, \"step\": 459000}\n",
      "{\"learning_rate\": 1.8356566064190376e-05, \"loss\": 0.6822310055526905, \"step\": 459500}\n",
      "{\"learning_rate\": 1.832213360071289e-05, \"loss\": 0.6123459805089515, \"step\": 460000}\n",
      "{\"learning_rate\": 1.8287701137235404e-05, \"loss\": 0.6406216748419683, \"step\": 460500}\n",
      "{\"learning_rate\": 1.8253268673757917e-05, \"loss\": 0.6575903819713276, \"step\": 461000}\n",
      "{\"learning_rate\": 1.8218836210280433e-05, \"loss\": 0.6358831952249165, \"step\": 461500}\n",
      "{\"learning_rate\": 1.8184403746802945e-05, \"loss\": 0.6340629078799394, \"step\": 462000}\n",
      "{\"learning_rate\": 1.8149971283325458e-05, \"loss\": 0.6584729869650909, \"step\": 462500}\n",
      "{\"learning_rate\": 1.8115538819847974e-05, \"loss\": 0.636306284362101, \"step\": 463000}\n",
      "{\"learning_rate\": 1.808110635637049e-05, \"loss\": 0.6554226123143453, \"step\": 463500}\n",
      "{\"learning_rate\": 1.8046673892893002e-05, \"loss\": 0.6360343437051633, \"step\": 464000}\n",
      "{\"learning_rate\": 1.8012241429415515e-05, \"loss\": 0.6291594618160743, \"step\": 464500}\n",
      "{\"learning_rate\": 1.797780896593803e-05, \"loss\": 0.6526971009479603, \"step\": 465000}\n",
      "{\"learning_rate\": 1.7943376502460547e-05, \"loss\": 0.6877849902455928, \"step\": 465500}\n",
      "{\"learning_rate\": 1.790894403898306e-05, \"loss\": 0.6503352135992609, \"step\": 466000}\n",
      "{\"learning_rate\": 1.7874511575505572e-05, \"loss\": 0.6539647686537355, \"step\": 466500}\n",
      "{\"learning_rate\": 1.7840079112028088e-05, \"loss\": 0.6599314450075617, \"step\": 467000}\n",
      "{\"learning_rate\": 1.78056466485506e-05, \"loss\": 0.6622199303343659, \"step\": 467500}\n",
      "{\"learning_rate\": 1.7771214185073116e-05, \"loss\": 0.6174595796969952, \"step\": 468000}\n",
      "{\"learning_rate\": 1.773678172159563e-05, \"loss\": 0.7028050982421264, \"step\": 468500}\n",
      "{\"learning_rate\": 1.770234925811814e-05, \"loss\": 0.6841254659912084, \"step\": 469000}\n",
      "{\"learning_rate\": 1.7667916794640657e-05, \"loss\": 0.6734670582849067, \"step\": 469500}\n",
      "{\"learning_rate\": 1.7633484331163173e-05, \"loss\": 0.6239105383836432, \"step\": 470000}\n",
      "{\"learning_rate\": 1.7599051867685686e-05, \"loss\": 0.6475650706753368, \"step\": 470500}\n",
      "{\"learning_rate\": 1.7564619404208198e-05, \"loss\": 0.6545949535687687, \"step\": 471000}\n",
      "{\"learning_rate\": 1.7530186940730714e-05, \"loss\": 0.6190888096763519, \"step\": 471500}\n",
      "{\"learning_rate\": 1.7495754477253227e-05, \"loss\": 0.640741965007037, \"step\": 472000}\n",
      "{\"learning_rate\": 1.7461322013775743e-05, \"loss\": 0.6365442247769096, \"step\": 472500}\n",
      "{\"learning_rate\": 1.7426889550298255e-05, \"loss\": 0.5806006802284391, \"step\": 473000}\n",
      "{\"learning_rate\": 1.7392457086820768e-05, \"loss\": 0.658649367370992, \"step\": 473500}\n",
      "{\"learning_rate\": 1.7358024623343284e-05, \"loss\": 0.6652511882368708, \"step\": 474000}\n",
      "{\"learning_rate\": 1.73235921598658e-05, \"loss\": 0.671091424779268, \"step\": 474500}\n",
      "{\"learning_rate\": 1.728915969638831e-05, \"loss\": 0.623612939488492, \"step\": 475000}\n",
      "{\"learning_rate\": 1.7254727232910825e-05, \"loss\": 0.604449605013011, \"step\": 475500}\n",
      "{\"learning_rate\": 1.722029476943334e-05, \"loss\": 0.6437497992478312, \"step\": 476000}\n",
      "{\"learning_rate\": 1.7185862305955853e-05, \"loss\": 0.6165323143919231, \"step\": 476500}\n",
      "{\"learning_rate\": 1.7151429842478366e-05, \"loss\": 0.6509780704794684, \"step\": 477000}\n",
      "{\"learning_rate\": 1.711699737900088e-05, \"loss\": 0.6353759037934942, \"step\": 477500}\n",
      "{\"learning_rate\": 1.7082564915523394e-05, \"loss\": 0.6284316409399034, \"step\": 478000}\n",
      "{\"learning_rate\": 1.704813245204591e-05, \"loss\": 0.6541914014274953, \"step\": 478500}\n",
      "{\"learning_rate\": 1.7013699988568422e-05, \"loss\": 0.688442605353077, \"step\": 479000}\n",
      "{\"learning_rate\": 1.6979267525090935e-05, \"loss\": 0.6435750350718153, \"step\": 479500}\n",
      "{\"learning_rate\": 1.694483506161345e-05, \"loss\": 0.6408987153482157, \"step\": 480000}\n",
      "{\"learning_rate\": 1.6910402598135967e-05, \"loss\": 0.7288231782990042, \"step\": 480500}\n",
      "{\"learning_rate\": 1.687597013465848e-05, \"loss\": 0.630474627604126, \"step\": 481000}\n",
      "{\"learning_rate\": 1.6841537671180992e-05, \"loss\": 0.6167159506877652, \"step\": 481500}\n",
      "{\"learning_rate\": 1.6807105207703508e-05, \"loss\": 0.6115764287940693, \"step\": 482000}\n",
      "{\"learning_rate\": 1.677267274422602e-05, \"loss\": 0.6297638012154494, \"step\": 482500}\n",
      "{\"learning_rate\": 1.6738240280748536e-05, \"loss\": 0.6196673556342721, \"step\": 483000}\n",
      "{\"learning_rate\": 1.670380781727105e-05, \"loss\": 0.606820158164599, \"step\": 483500}\n",
      "{\"learning_rate\": 1.666937535379356e-05, \"loss\": 0.6269661739323056, \"step\": 484000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 1.6634942890316077e-05, \"loss\": 0.6055786013841862, \"step\": 484500}\n",
      "{\"learning_rate\": 1.6600510426838593e-05, \"loss\": 0.6784686324667418, \"step\": 485000}\n",
      "{\"learning_rate\": 1.6566077963361106e-05, \"loss\": 0.6542558470969089, \"step\": 485500}\n",
      "{\"learning_rate\": 1.6531645499883618e-05, \"loss\": 0.6532574157356285, \"step\": 486000}\n",
      "{\"learning_rate\": 1.6497213036406134e-05, \"loss\": 0.6571626173941185, \"step\": 486500}\n",
      "{\"learning_rate\": 1.6462780572928647e-05, \"loss\": 0.6745232541749719, \"step\": 487000}\n",
      "{\"learning_rate\": 1.6428348109451163e-05, \"loss\": 0.6417939631178742, \"step\": 487500}\n",
      "{\"learning_rate\": 1.6393915645973675e-05, \"loss\": 0.6175949116960401, \"step\": 488000}\n",
      "{\"learning_rate\": 1.6359483182496188e-05, \"loss\": 0.6190065406704088, \"step\": 488500}\n",
      "{\"learning_rate\": 1.6325050719018704e-05, \"loss\": 0.6567714810476173, \"step\": 489000}\n",
      "{\"learning_rate\": 1.629061825554122e-05, \"loss\": 0.6830549076892203, \"step\": 489500}\n",
      "{\"learning_rate\": 1.625618579206373e-05, \"loss\": 0.6450321841010591, \"step\": 490000}\n",
      "{\"learning_rate\": 1.6221753328586245e-05, \"loss\": 0.6102252392825903, \"step\": 490500}\n",
      "{\"learning_rate\": 1.618732086510876e-05, \"loss\": 0.6085743386446265, \"step\": 491000}\n",
      "{\"learning_rate\": 1.6152888401631273e-05, \"loss\": 0.656191118432791, \"step\": 491500}\n",
      "{\"learning_rate\": 1.6118455938153786e-05, \"loss\": 0.6447803580887849, \"step\": 492000}\n",
      "{\"learning_rate\": 1.60840234746763e-05, \"loss\": 0.6742112797067966, \"step\": 492500}\n",
      "{\"learning_rate\": 1.6049591011198814e-05, \"loss\": 0.6358376593416324, \"step\": 493000}\n",
      "{\"learning_rate\": 1.601515854772133e-05, \"loss\": 0.6002688931794837, \"step\": 493500}\n",
      "{\"learning_rate\": 1.5980726084243842e-05, \"loss\": 0.609922540962114, \"step\": 494000}\n",
      "{\"learning_rate\": 1.5946293620766355e-05, \"loss\": 0.6933981032703305, \"step\": 494500}\n",
      "{\"learning_rate\": 1.591186115728887e-05, \"loss\": 0.635448439062573, \"step\": 495000}\n",
      "{\"learning_rate\": 1.5877428693811387e-05, \"loss\": 0.6796953941124957, \"step\": 495500}\n",
      "{\"learning_rate\": 1.58429962303339e-05, \"loss\": 0.6216641678899759, \"step\": 496000}\n",
      "{\"learning_rate\": 1.5808563766856412e-05, \"loss\": 0.5992299370962428, \"step\": 496500}\n",
      "{\"learning_rate\": 1.5774131303378928e-05, \"loss\": 0.6189261517031118, \"step\": 497000}\n",
      "{\"learning_rate\": 1.573969883990144e-05, \"loss\": 0.683031483526458, \"step\": 497500}\n",
      "{\"learning_rate\": 1.5705266376423956e-05, \"loss\": 0.659945234798477, \"step\": 498000}\n",
      "{\"learning_rate\": 1.567083391294647e-05, \"loss\": 0.6208378450834425, \"step\": 498500}\n",
      "{\"learning_rate\": 1.563640144946898e-05, \"loss\": 0.6229680987148313, \"step\": 499000}\n",
      "{\"learning_rate\": 1.5601968985991497e-05, \"loss\": 0.6429400457649026, \"step\": 499500}\n",
      "{\"learning_rate\": 1.5567536522514013e-05, \"loss\": 0.6566681148742791, \"step\": 500000}\n",
      "{\"learning_rate\": 1.5533104059036522e-05, \"loss\": 0.6341994036893593, \"step\": 500500}\n",
      "{\"learning_rate\": 1.5498671595559038e-05, \"loss\": 0.6468029947137693, \"step\": 501000}\n",
      "{\"learning_rate\": 1.5464239132081554e-05, \"loss\": 0.613768413904705, \"step\": 501500}\n",
      "{\"learning_rate\": 1.5429806668604067e-05, \"loss\": 0.6066887062300229, \"step\": 502000}\n",
      "{\"learning_rate\": 1.539537420512658e-05, \"loss\": 0.6675646295303013, \"step\": 502500}\n",
      "{\"learning_rate\": 1.5360941741649095e-05, \"loss\": 0.6270500715755625, \"step\": 503000}\n",
      "{\"learning_rate\": 1.532650927817161e-05, \"loss\": 0.6669708753479645, \"step\": 503500}\n",
      "{\"learning_rate\": 1.5292076814694124e-05, \"loss\": 0.6343089048069669, \"step\": 504000}\n",
      "{\"learning_rate\": 1.5257644351216638e-05, \"loss\": 0.6441091322054854, \"step\": 504500}\n",
      "{\"learning_rate\": 1.5223211887739152e-05, \"loss\": 0.6251442495833617, \"step\": 505000}\n",
      "{\"learning_rate\": 1.5188779424261665e-05, \"loss\": 0.6564793279138393, \"step\": 505500}\n",
      "{\"learning_rate\": 1.515434696078418e-05, \"loss\": 0.5954230185232591, \"step\": 506000}\n",
      "{\"learning_rate\": 1.5119914497306695e-05, \"loss\": 0.6899746059475, \"step\": 506500}\n",
      "{\"learning_rate\": 1.5085482033829207e-05, \"loss\": 0.6593994162011658, \"step\": 507000}\n",
      "{\"learning_rate\": 1.5051049570351722e-05, \"loss\": 0.6839108564485796, \"step\": 507500}\n",
      "{\"learning_rate\": 1.5016617106874237e-05, \"loss\": 0.6508594745295122, \"step\": 508000}\n",
      "{\"learning_rate\": 1.4982184643396748e-05, \"loss\": 0.6547931174465921, \"step\": 508500}\n",
      "{\"learning_rate\": 1.4947752179919264e-05, \"loss\": 0.6067903423798271, \"step\": 509000}\n",
      "{\"learning_rate\": 1.4913319716441778e-05, \"loss\": 0.6117933323910693, \"step\": 509500}\n",
      "{\"learning_rate\": 1.4878887252964291e-05, \"loss\": 0.638447116512456, \"step\": 510000}\n",
      "{\"learning_rate\": 1.4844454789486805e-05, \"loss\": 0.6042456426180434, \"step\": 510500}\n",
      "{\"learning_rate\": 1.4810022326009321e-05, \"loss\": 0.6680125722554512, \"step\": 511000}\n",
      "{\"learning_rate\": 1.4775589862531834e-05, \"loss\": 0.6268235428986373, \"step\": 511500}\n",
      "{\"learning_rate\": 1.4741157399054348e-05, \"loss\": 0.6145910479143495, \"step\": 512000}\n",
      "{\"learning_rate\": 1.4706724935576862e-05, \"loss\": 0.6506126061948017, \"step\": 512500}\n",
      "{\"learning_rate\": 1.4672292472099375e-05, \"loss\": 0.5859951889798977, \"step\": 513000}\n",
      "{\"learning_rate\": 1.463786000862189e-05, \"loss\": 0.6135161536005326, \"step\": 513500}\n",
      "{\"learning_rate\": 1.4603427545144405e-05, \"loss\": 0.6198433404132957, \"step\": 514000}\n",
      "{\"learning_rate\": 1.4568995081666917e-05, \"loss\": 0.6378505804941523, \"step\": 514500}\n",
      "{\"learning_rate\": 1.4534562618189432e-05, \"loss\": 0.6369421827923506, \"step\": 515000}\n",
      "{\"learning_rate\": 1.4500130154711947e-05, \"loss\": 0.6524770684039686, \"step\": 515500}\n",
      "{\"learning_rate\": 1.4465697691234458e-05, \"loss\": 0.6169475144267781, \"step\": 516000}\n",
      "{\"learning_rate\": 1.4431265227756974e-05, \"loss\": 0.6697034934520488, \"step\": 516500}\n",
      "{\"learning_rate\": 1.4396832764279488e-05, \"loss\": 0.5962175190702547, \"step\": 517000}\n",
      "{\"learning_rate\": 1.4362400300802001e-05, \"loss\": 0.5986365845242981, \"step\": 517500}\n",
      "{\"learning_rate\": 1.4327967837324515e-05, \"loss\": 0.5955406433610478, \"step\": 518000}\n",
      "{\"learning_rate\": 1.4293535373847031e-05, \"loss\": 0.6325555394648109, \"step\": 518500}\n",
      "{\"learning_rate\": 1.4259102910369542e-05, \"loss\": 0.6192516239823308, \"step\": 519000}\n",
      "{\"learning_rate\": 1.4224670446892058e-05, \"loss\": 0.5938633870803751, \"step\": 519500}\n",
      "{\"learning_rate\": 1.4190237983414572e-05, \"loss\": 0.6204198851112742, \"step\": 520000}\n",
      "{\"learning_rate\": 1.4155805519937085e-05, \"loss\": 0.6130967570432695, \"step\": 520500}\n",
      "{\"learning_rate\": 1.4121373056459599e-05, \"loss\": 0.6294089517280227, \"step\": 521000}\n",
      "{\"learning_rate\": 1.4086940592982115e-05, \"loss\": 0.6486231757682981, \"step\": 521500}\n",
      "{\"learning_rate\": 1.4052508129504627e-05, \"loss\": 0.6179157183410134, \"step\": 522000}\n",
      "{\"learning_rate\": 1.4018075666027142e-05, \"loss\": 0.6328316825606162, \"step\": 522500}\n",
      "{\"learning_rate\": 1.3983643202549656e-05, \"loss\": 0.6528067402683664, \"step\": 523000}\n",
      "{\"learning_rate\": 1.3949210739072168e-05, \"loss\": 0.6127555206794059, \"step\": 523500}\n",
      "{\"learning_rate\": 1.3914778275594684e-05, \"loss\": 0.6040925024786266, \"step\": 524000}\n",
      "{\"learning_rate\": 1.3880345812117199e-05, \"loss\": 0.6287327924028505, \"step\": 524500}\n",
      "{\"learning_rate\": 1.3845913348639711e-05, \"loss\": 0.6247671801031102, \"step\": 525000}\n",
      "{\"learning_rate\": 1.3811480885162225e-05, \"loss\": 0.627900980254286, \"step\": 525500}\n",
      "{\"learning_rate\": 1.3777048421684741e-05, \"loss\": 0.6261042419774457, \"step\": 526000}\n",
      "{\"learning_rate\": 1.3742615958207252e-05, \"loss\": 0.6374410503424005, \"step\": 526500}\n",
      "{\"learning_rate\": 1.3708183494729768e-05, \"loss\": 0.6170527176129399, \"step\": 527000}\n",
      "{\"learning_rate\": 1.3673751031252282e-05, \"loss\": 0.6059360809954815, \"step\": 527500}\n",
      "{\"learning_rate\": 1.3639318567774795e-05, \"loss\": 0.549491566968034, \"step\": 528000}\n",
      "{\"learning_rate\": 1.3604886104297309e-05, \"loss\": 0.5922509612792637, \"step\": 528500}\n",
      "{\"learning_rate\": 1.3570453640819825e-05, \"loss\": 0.612857617140282, \"step\": 529000}\n",
      "{\"learning_rate\": 1.3536021177342337e-05, \"loss\": 0.610109449922922, \"step\": 529500}\n",
      "{\"learning_rate\": 1.3501588713864852e-05, \"loss\": 0.5757707352776779, \"step\": 530000}\n",
      "{\"learning_rate\": 1.3467156250387366e-05, \"loss\": 0.6026638370000291, \"step\": 530500}\n",
      "{\"learning_rate\": 1.3432723786909878e-05, \"loss\": 0.623830451381742, \"step\": 531000}\n",
      "{\"learning_rate\": 1.3398291323432394e-05, \"loss\": 0.581913243912044, \"step\": 531500}\n",
      "{\"learning_rate\": 1.3363858859954909e-05, \"loss\": 0.6203395338449628, \"step\": 532000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 1.3329426396477421e-05, \"loss\": 0.6362486650486244, \"step\": 532500}\n",
      "{\"learning_rate\": 1.3294993932999935e-05, \"loss\": 0.6209467391911894, \"step\": 533000}\n",
      "{\"learning_rate\": 1.3260561469522451e-05, \"loss\": 0.6005638160832459, \"step\": 533500}\n",
      "{\"learning_rate\": 1.3226129006044962e-05, \"loss\": 0.6259371098693227, \"step\": 534000}\n",
      "{\"learning_rate\": 1.3191696542567478e-05, \"loss\": 0.5893335142693249, \"step\": 534500}\n",
      "{\"learning_rate\": 1.3157264079089992e-05, \"loss\": 0.6093031585845164, \"step\": 535000}\n",
      "{\"learning_rate\": 1.3122831615612505e-05, \"loss\": 0.6047191177677596, \"step\": 535500}\n",
      "{\"learning_rate\": 1.3088399152135019e-05, \"loss\": 0.6367885565060424, \"step\": 536000}\n",
      "{\"learning_rate\": 1.3053966688657535e-05, \"loss\": 0.6625697083914419, \"step\": 536500}\n",
      "{\"learning_rate\": 1.3019534225180047e-05, \"loss\": 0.6112505157015985, \"step\": 537000}\n",
      "{\"learning_rate\": 1.2985101761702562e-05, \"loss\": 0.5850109959683614, \"step\": 537500}\n",
      "{\"learning_rate\": 1.2950669298225076e-05, \"loss\": 0.620480833340087, \"step\": 538000}\n",
      "{\"learning_rate\": 1.2916236834747588e-05, \"loss\": 0.6320432118030731, \"step\": 538500}\n",
      "{\"learning_rate\": 1.2881804371270104e-05, \"loss\": 0.6048187518010382, \"step\": 539000}\n",
      "{\"learning_rate\": 1.2847371907792619e-05, \"loss\": 0.5860349326028954, \"step\": 539500}\n",
      "{\"learning_rate\": 1.2812939444315131e-05, \"loss\": 0.6370550005319529, \"step\": 540000}\n",
      "{\"learning_rate\": 1.2778506980837645e-05, \"loss\": 0.5975536933047697, \"step\": 540500}\n",
      "{\"learning_rate\": 1.2744074517360161e-05, \"loss\": 0.6153002164112404, \"step\": 541000}\n",
      "{\"learning_rate\": 1.2709642053882672e-05, \"loss\": 0.6522362622887594, \"step\": 541500}\n",
      "{\"learning_rate\": 1.2675209590405188e-05, \"loss\": 0.617766240169527, \"step\": 542000}\n",
      "{\"learning_rate\": 1.2640777126927702e-05, \"loss\": 0.6109846086213365, \"step\": 542500}\n",
      "{\"learning_rate\": 1.2606344663450215e-05, \"loss\": 0.6151825414499035, \"step\": 543000}\n",
      "{\"learning_rate\": 1.2571912199972729e-05, \"loss\": 0.6347456552691292, \"step\": 543500}\n",
      "{\"learning_rate\": 1.2537479736495245e-05, \"loss\": 0.6390975677334937, \"step\": 544000}\n",
      "{\"learning_rate\": 1.2503047273017759e-05, \"loss\": 0.6191371623954037, \"step\": 544500}\n",
      "{\"learning_rate\": 1.2468614809540272e-05, \"loss\": 0.6635730148026486, \"step\": 545000}\n",
      "{\"learning_rate\": 1.2434182346062786e-05, \"loss\": 0.6236959172365023, \"step\": 545500}\n",
      "{\"learning_rate\": 1.23997498825853e-05, \"loss\": 0.5866107277723495, \"step\": 546000}\n",
      "{\"learning_rate\": 1.2365317419107814e-05, \"loss\": 0.6023501499918057, \"step\": 546500}\n",
      "{\"learning_rate\": 1.2330884955630329e-05, \"loss\": 0.5926248762726318, \"step\": 547000}\n",
      "{\"learning_rate\": 1.2296452492152843e-05, \"loss\": 0.6205282279294916, \"step\": 547500}\n",
      "{\"learning_rate\": 1.2262020028675355e-05, \"loss\": 0.6071987866959535, \"step\": 548000}\n",
      "{\"learning_rate\": 1.2227587565197871e-05, \"loss\": 0.5875825542121893, \"step\": 548500}\n",
      "{\"learning_rate\": 1.2193155101720384e-05, \"loss\": 0.6337356120017357, \"step\": 549000}\n",
      "{\"learning_rate\": 1.2158722638242898e-05, \"loss\": 0.58561480075086, \"step\": 549500}\n",
      "{\"learning_rate\": 1.2124290174765412e-05, \"loss\": 0.6413874343126081, \"step\": 550000}\n",
      "{\"learning_rate\": 1.2089857711287926e-05, \"loss\": 0.5906925754849799, \"step\": 550500}\n",
      "{\"learning_rate\": 1.2055425247810439e-05, \"loss\": 0.581737549536163, \"step\": 551000}\n",
      "{\"learning_rate\": 1.2020992784332955e-05, \"loss\": 0.5509302139261272, \"step\": 551500}\n",
      "{\"learning_rate\": 1.1986560320855467e-05, \"loss\": 0.5508599932618672, \"step\": 552000}\n",
      "{\"learning_rate\": 1.1952127857377982e-05, \"loss\": 0.5655772044303594, \"step\": 552500}\n",
      "{\"learning_rate\": 1.1917695393900496e-05, \"loss\": 0.6008570407516091, \"step\": 553000}\n",
      "{\"learning_rate\": 1.188326293042301e-05, \"loss\": 0.5770641484453809, \"step\": 553500}\n",
      "{\"learning_rate\": 1.1848830466945524e-05, \"loss\": 0.6064726887029829, \"step\": 554000}\n",
      "{\"learning_rate\": 1.1814398003468039e-05, \"loss\": 0.5976265983730554, \"step\": 554500}\n",
      "{\"learning_rate\": 1.1779965539990553e-05, \"loss\": 0.6132195031706942, \"step\": 555000}\n",
      "{\"learning_rate\": 1.1745533076513067e-05, \"loss\": 0.591908423120738, \"step\": 555500}\n",
      "{\"learning_rate\": 1.1711100613035581e-05, \"loss\": 0.6015435212885495, \"step\": 556000}\n",
      "{\"learning_rate\": 1.1676668149558094e-05, \"loss\": 0.6582684112022398, \"step\": 556500}\n",
      "{\"learning_rate\": 1.164223568608061e-05, \"loss\": 0.6446810949437786, \"step\": 557000}\n",
      "{\"learning_rate\": 1.1607803222603122e-05, \"loss\": 0.6143099512063199, \"step\": 557500}\n",
      "{\"learning_rate\": 1.1573370759125637e-05, \"loss\": 0.6116375108096982, \"step\": 558000}\n",
      "{\"learning_rate\": 1.153893829564815e-05, \"loss\": 0.542713192291325, \"step\": 558500}\n",
      "{\"learning_rate\": 1.1504505832170665e-05, \"loss\": 0.6340881937416271, \"step\": 559000}\n",
      "{\"learning_rate\": 1.1470073368693178e-05, \"loss\": 0.6102823669108329, \"step\": 559500}\n",
      "{\"learning_rate\": 1.1435640905215693e-05, \"loss\": 0.6049283328863093, \"step\": 560000}\n",
      "{\"learning_rate\": 1.1401208441738206e-05, \"loss\": 0.5938652173714946, \"step\": 560500}\n",
      "{\"learning_rate\": 1.136677597826072e-05, \"loss\": 0.564638461080729, \"step\": 561000}\n",
      "{\"learning_rate\": 1.1332343514783234e-05, \"loss\": 0.5941761560053564, \"step\": 561500}\n",
      "{\"learning_rate\": 1.1297911051305749e-05, \"loss\": 0.6066821447648107, \"step\": 562000}\n",
      "{\"learning_rate\": 1.1263478587828261e-05, \"loss\": 0.6085828390587121, \"step\": 562500}\n",
      "{\"learning_rate\": 1.1229046124350777e-05, \"loss\": 0.5994235059663188, \"step\": 563000}\n",
      "{\"learning_rate\": 1.119461366087329e-05, \"loss\": 0.6041722617760533, \"step\": 563500}\n",
      "{\"learning_rate\": 1.1160181197395804e-05, \"loss\": 0.6061645796201192, \"step\": 564000}\n",
      "{\"learning_rate\": 1.1125748733918318e-05, \"loss\": 0.5890906587158097, \"step\": 564500}\n",
      "{\"learning_rate\": 1.1091316270440832e-05, \"loss\": 0.5983758731922135, \"step\": 565000}\n",
      "{\"learning_rate\": 1.1056883806963347e-05, \"loss\": 0.5561074396141339, \"step\": 565500}\n",
      "{\"learning_rate\": 1.102245134348586e-05, \"loss\": 0.5936227668309584, \"step\": 566000}\n",
      "{\"learning_rate\": 1.0988018880008375e-05, \"loss\": 0.5468404505817452, \"step\": 566500}\n",
      "{\"learning_rate\": 1.0953586416530888e-05, \"loss\": 0.6270790886601899, \"step\": 567000}\n",
      "{\"learning_rate\": 1.0919153953053403e-05, \"loss\": 0.6111826453900431, \"step\": 567500}\n",
      "{\"learning_rate\": 1.0884721489575916e-05, \"loss\": 0.6072606706123334, \"step\": 568000}\n",
      "{\"learning_rate\": 1.085028902609843e-05, \"loss\": 0.6113535801952239, \"step\": 568500}\n",
      "{\"learning_rate\": 1.0815856562620944e-05, \"loss\": 0.580236700021429, \"step\": 569000}\n",
      "{\"learning_rate\": 1.0781424099143459e-05, \"loss\": 0.6249216696880758, \"step\": 569500}\n",
      "{\"learning_rate\": 1.0746991635665971e-05, \"loss\": 0.5646524745303905, \"step\": 570000}\n",
      "{\"learning_rate\": 1.0712559172188487e-05, \"loss\": 0.5958067837216658, \"step\": 570500}\n",
      "{\"learning_rate\": 1.0678126708711e-05, \"loss\": 0.5574754543736344, \"step\": 571000}\n",
      "{\"learning_rate\": 1.0643694245233514e-05, \"loss\": 0.6247280503913062, \"step\": 571500}\n",
      "{\"learning_rate\": 1.0609261781756028e-05, \"loss\": 0.5909624241392594, \"step\": 572000}\n",
      "{\"learning_rate\": 1.0574829318278542e-05, \"loss\": 0.6050639935815707, \"step\": 572500}\n",
      "{\"learning_rate\": 1.0540396854801057e-05, \"loss\": 0.5635775318226078, \"step\": 573000}\n",
      "{\"learning_rate\": 1.050596439132357e-05, \"loss\": 0.5642151879015146, \"step\": 573500}\n",
      "{\"learning_rate\": 1.0471531927846085e-05, \"loss\": 0.59641530197463, \"step\": 574000}\n",
      "{\"learning_rate\": 1.04370994643686e-05, \"loss\": 0.603105581762502, \"step\": 574500}\n",
      "{\"learning_rate\": 1.0402667000891113e-05, \"loss\": 0.5973786722747609, \"step\": 575000}\n",
      "{\"learning_rate\": 1.0368234537413626e-05, \"loss\": 0.5569832049212419, \"step\": 575500}\n",
      "{\"learning_rate\": 1.0333802073936142e-05, \"loss\": 0.6330782244951697, \"step\": 576000}\n",
      "{\"learning_rate\": 1.0299369610458654e-05, \"loss\": 0.5887248036869569, \"step\": 576500}\n",
      "{\"learning_rate\": 1.0264937146981169e-05, \"loss\": 0.5709739023688016, \"step\": 577000}\n",
      "{\"learning_rate\": 1.0230504683503683e-05, \"loss\": 0.5728491039368091, \"step\": 577500}\n",
      "{\"learning_rate\": 1.0196072220026197e-05, \"loss\": 0.6612238700049929, \"step\": 578000}\n",
      "{\"learning_rate\": 1.016163975654871e-05, \"loss\": 0.6047978211317677, \"step\": 578500}\n",
      "{\"learning_rate\": 1.0127207293071226e-05, \"loss\": 0.6119046615854604, \"step\": 579000}\n",
      "{\"learning_rate\": 1.0092774829593738e-05, \"loss\": 0.6332869350911351, \"step\": 579500}\n",
      "{\"learning_rate\": 1.0058342366116252e-05, \"loss\": 0.5739343447408173, \"step\": 580000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 1.0023909902638767e-05, \"loss\": 0.6151483952075941, \"step\": 580500}\n",
      "{\"learning_rate\": 9.98947743916128e-06, \"loss\": 0.5814437149640871, \"step\": 581000}\n",
      "{\"learning_rate\": 9.955044975683795e-06, \"loss\": 0.6434655097271316, \"step\": 581500}\n",
      "{\"learning_rate\": 9.92061251220631e-06, \"loss\": 0.6274386137584225, \"step\": 582000}\n",
      "{\"learning_rate\": 9.886180048728824e-06, \"loss\": 0.524150544114178, \"step\": 582500}\n",
      "{\"learning_rate\": 9.851747585251336e-06, \"loss\": 0.6297437805389055, \"step\": 583000}\n",
      "{\"learning_rate\": 9.817315121773852e-06, \"loss\": 0.5545966559965163, \"step\": 583500}\n",
      "{\"learning_rate\": 9.782882658296364e-06, \"loss\": 0.6013038169840583, \"step\": 584000}\n",
      "{\"learning_rate\": 9.748450194818879e-06, \"loss\": 0.6292839660121826, \"step\": 584500}\n",
      "{\"learning_rate\": 9.714017731341393e-06, \"loss\": 0.6191668774143327, \"step\": 585000}\n",
      "{\"learning_rate\": 9.679585267863907e-06, \"loss\": 0.5830070460846182, \"step\": 585500}\n",
      "{\"learning_rate\": 9.64515280438642e-06, \"loss\": 0.5660908025117823, \"step\": 586000}\n",
      "{\"learning_rate\": 9.610720340908936e-06, \"loss\": 0.6217035374052357, \"step\": 586500}\n",
      "{\"learning_rate\": 9.576287877431448e-06, \"loss\": 0.586993820286938, \"step\": 587000}\n",
      "{\"learning_rate\": 9.541855413953962e-06, \"loss\": 0.6180383335540537, \"step\": 587500}\n",
      "{\"learning_rate\": 9.507422950476477e-06, \"loss\": 0.6155354055033531, \"step\": 588000}\n",
      "{\"learning_rate\": 9.472990486998991e-06, \"loss\": 0.5753817576610017, \"step\": 588500}\n",
      "{\"learning_rate\": 9.438558023521505e-06, \"loss\": 0.5974227091608336, \"step\": 589000}\n",
      "{\"learning_rate\": 9.40412556004402e-06, \"loss\": 0.5457949919012608, \"step\": 589500}\n",
      "{\"learning_rate\": 9.369693096566534e-06, \"loss\": 0.6147435327464482, \"step\": 590000}\n",
      "{\"learning_rate\": 9.335260633089046e-06, \"loss\": 0.5449378036308336, \"step\": 590500}\n",
      "{\"learning_rate\": 9.300828169611562e-06, \"loss\": 0.6167312805663095, \"step\": 591000}\n",
      "{\"learning_rate\": 9.266395706134075e-06, \"loss\": 0.5450481246492127, \"step\": 591500}\n",
      "{\"learning_rate\": 9.231963242656589e-06, \"loss\": 0.5936094802638981, \"step\": 592000}\n",
      "{\"learning_rate\": 9.197530779179103e-06, \"loss\": 0.6034089297450846, \"step\": 592500}\n",
      "{\"learning_rate\": 9.163098315701617e-06, \"loss\": 0.5751619802896166, \"step\": 593000}\n",
      "{\"learning_rate\": 9.128665852224131e-06, \"loss\": 0.6237951896567829, \"step\": 593500}\n",
      "{\"learning_rate\": 9.094233388746646e-06, \"loss\": 0.6296656486457214, \"step\": 594000}\n",
      "{\"learning_rate\": 9.059800925269158e-06, \"loss\": 0.5634595009414479, \"step\": 594500}\n",
      "{\"learning_rate\": 9.025368461791674e-06, \"loss\": 0.5778142329576658, \"step\": 595000}\n",
      "{\"learning_rate\": 8.990935998314187e-06, \"loss\": 0.5742135451312642, \"step\": 595500}\n",
      "{\"learning_rate\": 8.956503534836701e-06, \"loss\": 0.6239057087053079, \"step\": 596000}\n",
      "{\"learning_rate\": 8.922071071359215e-06, \"loss\": 0.6307404023191193, \"step\": 596500}\n",
      "{\"learning_rate\": 8.88763860788173e-06, \"loss\": 0.5871389330475358, \"step\": 597000}\n",
      "{\"learning_rate\": 8.853206144404244e-06, \"loss\": 0.6137863439363428, \"step\": 597500}\n",
      "{\"learning_rate\": 8.818773680926758e-06, \"loss\": 0.5627955830432475, \"step\": 598000}\n",
      "{\"learning_rate\": 8.784341217449272e-06, \"loss\": 0.6228016972612822, \"step\": 598500}\n",
      "{\"learning_rate\": 8.749908753971785e-06, \"loss\": 0.6202573956844862, \"step\": 599000}\n",
      "{\"learning_rate\": 8.7154762904943e-06, \"loss\": 0.5954362781576347, \"step\": 599500}\n",
      "{\"learning_rate\": 8.681043827016813e-06, \"loss\": 0.582570037928992, \"step\": 600000}\n",
      "{\"learning_rate\": 8.646611363539327e-06, \"loss\": 0.5709067945451243, \"step\": 600500}\n",
      "{\"learning_rate\": 8.612178900061841e-06, \"loss\": 0.5873570705133024, \"step\": 601000}\n",
      "{\"learning_rate\": 8.577746436584356e-06, \"loss\": 0.6076591614002828, \"step\": 601500}\n",
      "{\"learning_rate\": 8.543313973106868e-06, \"loss\": 0.6210671574303415, \"step\": 602000}\n",
      "{\"learning_rate\": 8.508881509629384e-06, \"loss\": 0.6050659286747686, \"step\": 602500}\n",
      "{\"learning_rate\": 8.474449046151897e-06, \"loss\": 0.5949244134246837, \"step\": 603000}\n",
      "{\"learning_rate\": 8.440016582674411e-06, \"loss\": 0.6136038829791359, \"step\": 603500}\n",
      "{\"learning_rate\": 8.405584119196925e-06, \"loss\": 0.6005655410885811, \"step\": 604000}\n",
      "{\"learning_rate\": 8.37115165571944e-06, \"loss\": 0.6105890545472503, \"step\": 604500}\n",
      "{\"learning_rate\": 8.336719192241952e-06, \"loss\": 0.6249864618750289, \"step\": 605000}\n",
      "{\"learning_rate\": 8.302286728764468e-06, \"loss\": 0.5654912410762627, \"step\": 605500}\n",
      "{\"learning_rate\": 8.26785426528698e-06, \"loss\": 0.6004769891327014, \"step\": 606000}\n",
      "{\"learning_rate\": 8.233421801809495e-06, \"loss\": 0.555670784972841, \"step\": 606500}\n",
      "{\"learning_rate\": 8.198989338332009e-06, \"loss\": 0.5971680928596761, \"step\": 607000}\n",
      "{\"learning_rate\": 8.164556874854523e-06, \"loss\": 0.581753921629046, \"step\": 607500}\n",
      "{\"learning_rate\": 8.130124411377037e-06, \"loss\": 0.5713078241513576, \"step\": 608000}\n",
      "{\"learning_rate\": 8.095691947899551e-06, \"loss\": 0.579539623124525, \"step\": 608500}\n",
      "{\"learning_rate\": 8.061259484422066e-06, \"loss\": 0.5998554804529995, \"step\": 609000}\n",
      "{\"learning_rate\": 8.026827020944578e-06, \"loss\": 0.5845557280782377, \"step\": 609500}\n",
      "{\"learning_rate\": 7.992394557467094e-06, \"loss\": 0.6071501166544622, \"step\": 610000}\n",
      "{\"learning_rate\": 7.957962093989607e-06, \"loss\": 0.6007234228062444, \"step\": 610500}\n",
      "{\"learning_rate\": 7.923529630512121e-06, \"loss\": 0.5905971628066617, \"step\": 611000}\n",
      "{\"learning_rate\": 7.889097167034635e-06, \"loss\": 0.5732794105156791, \"step\": 611500}\n",
      "{\"learning_rate\": 7.85466470355715e-06, \"loss\": 0.5672337281297659, \"step\": 612000}\n",
      "{\"learning_rate\": 7.820232240079662e-06, \"loss\": 0.5866161803698633, \"step\": 612500}\n",
      "{\"learning_rate\": 7.785799776602178e-06, \"loss\": 0.5983403327218257, \"step\": 613000}\n",
      "{\"learning_rate\": 7.75136731312469e-06, \"loss\": 0.6153664856239921, \"step\": 613500}\n",
      "{\"learning_rate\": 7.716934849647206e-06, \"loss\": 0.5553803251117934, \"step\": 614000}\n",
      "{\"learning_rate\": 7.682502386169719e-06, \"loss\": 0.6206353493303759, \"step\": 614500}\n",
      "{\"learning_rate\": 7.648069922692233e-06, \"loss\": 0.5510226474462543, \"step\": 615000}\n",
      "{\"learning_rate\": 7.613637459214748e-06, \"loss\": 0.5693526258071652, \"step\": 615500}\n",
      "{\"learning_rate\": 7.5792049957372615e-06, \"loss\": 0.6139228642086965, \"step\": 616000}\n",
      "{\"learning_rate\": 7.544772532259775e-06, \"loss\": 0.6357950624015648, \"step\": 616500}\n",
      "{\"learning_rate\": 7.51034006878229e-06, \"loss\": 0.6016255312606227, \"step\": 617000}\n",
      "{\"learning_rate\": 7.475907605304803e-06, \"loss\": 0.6061261226689676, \"step\": 617500}\n",
      "{\"learning_rate\": 7.441475141827317e-06, \"loss\": 0.5353325349865481, \"step\": 618000}\n",
      "{\"learning_rate\": 7.407042678349832e-06, \"loss\": 0.5911437122765929, \"step\": 618500}\n",
      "{\"learning_rate\": 7.372610214872345e-06, \"loss\": 0.5532447706997627, \"step\": 619000}\n",
      "{\"learning_rate\": 7.338177751394859e-06, \"loss\": 0.6017967687984929, \"step\": 619500}\n",
      "{\"learning_rate\": 7.303745287917374e-06, \"loss\": 0.5335688936037477, \"step\": 620000}\n",
      "{\"learning_rate\": 7.269312824439888e-06, \"loss\": 0.5550475183270173, \"step\": 620500}\n",
      "{\"learning_rate\": 7.234880360962401e-06, \"loss\": 0.6020296579925344, \"step\": 621000}\n",
      "{\"learning_rate\": 7.200447897484916e-06, \"loss\": 0.5962476898069726, \"step\": 621500}\n",
      "{\"learning_rate\": 7.16601543400743e-06, \"loss\": 0.5442224660444772, \"step\": 622000}\n",
      "{\"learning_rate\": 7.131582970529943e-06, \"loss\": 0.6288924803822301, \"step\": 622500}\n",
      "{\"learning_rate\": 7.097150507052458e-06, \"loss\": 0.5995004324140027, \"step\": 623000}\n",
      "{\"learning_rate\": 7.0627180435749715e-06, \"loss\": 0.6221214533415623, \"step\": 623500}\n",
      "{\"learning_rate\": 7.028285580097485e-06, \"loss\": 0.6378745486995904, \"step\": 624000}\n",
      "{\"learning_rate\": 6.99385311662e-06, \"loss\": 0.6053243831534637, \"step\": 624500}\n",
      "{\"learning_rate\": 6.959420653142513e-06, \"loss\": 0.5475971061222954, \"step\": 625000}\n",
      "{\"learning_rate\": 6.924988189665027e-06, \"loss\": 0.538080420112703, \"step\": 625500}\n",
      "{\"learning_rate\": 6.890555726187542e-06, \"loss\": 0.5867978721146937, \"step\": 626000}\n",
      "{\"learning_rate\": 6.856123262710055e-06, \"loss\": 0.6013621911531082, \"step\": 626500}\n",
      "{\"learning_rate\": 6.8216907992325694e-06, \"loss\": 0.5944504259406822, \"step\": 627000}\n",
      "{\"learning_rate\": 6.787258335755084e-06, \"loss\": 0.537172182306298, \"step\": 627500}\n",
      "{\"learning_rate\": 6.752825872277598e-06, \"loss\": 0.5333730796182062, \"step\": 628000}\n",
      "{\"learning_rate\": 6.718393408800111e-06, \"loss\": 0.5695595061328494, \"step\": 628500}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 6.683960945322626e-06, \"loss\": 0.5833994100344134, \"step\": 629000}\n",
      "{\"learning_rate\": 6.64952848184514e-06, \"loss\": 0.5892561943371547, \"step\": 629500}\n",
      "{\"learning_rate\": 6.615096018367653e-06, \"loss\": 0.573047022413928, \"step\": 630000}\n",
      "{\"learning_rate\": 6.580663554890168e-06, \"loss\": 0.6249527226218488, \"step\": 630500}\n",
      "{\"learning_rate\": 6.5462310914126816e-06, \"loss\": 0.5897945310912328, \"step\": 631000}\n",
      "{\"learning_rate\": 6.511798627935195e-06, \"loss\": 0.5470072530498729, \"step\": 631500}\n",
      "{\"learning_rate\": 6.47736616445771e-06, \"loss\": 0.6168138919294579, \"step\": 632000}\n",
      "{\"learning_rate\": 6.442933700980223e-06, \"loss\": 0.5472594911990455, \"step\": 632500}\n",
      "{\"learning_rate\": 6.408501237502737e-06, \"loss\": 0.5904203704475658, \"step\": 633000}\n",
      "{\"learning_rate\": 6.374068774025252e-06, \"loss\": 0.5647705920536537, \"step\": 633500}\n",
      "{\"learning_rate\": 6.339636310547765e-06, \"loss\": 0.6077680653878488, \"step\": 634000}\n",
      "{\"learning_rate\": 6.30520384707028e-06, \"loss\": 0.5855768364662072, \"step\": 634500}\n",
      "{\"learning_rate\": 6.270771383592794e-06, \"loss\": 0.566217775548459, \"step\": 635000}\n",
      "{\"learning_rate\": 6.236338920115307e-06, \"loss\": 0.6077451280745445, \"step\": 635500}\n",
      "{\"learning_rate\": 6.201906456637821e-06, \"loss\": 0.5818459025316406, \"step\": 636000}\n",
      "{\"learning_rate\": 6.1674739931603355e-06, \"loss\": 0.6092377315234626, \"step\": 636500}\n",
      "{\"learning_rate\": 6.13304152968285e-06, \"loss\": 0.5562181275506737, \"step\": 637000}\n",
      "{\"learning_rate\": 6.098609066205364e-06, \"loss\": 0.6533009794999379, \"step\": 637500}\n",
      "{\"learning_rate\": 6.064176602727878e-06, \"loss\": 0.5349263561115367, \"step\": 638000}\n",
      "{\"learning_rate\": 6.029744139250392e-06, \"loss\": 0.6234822614735458, \"step\": 638500}\n",
      "{\"learning_rate\": 5.995311675772906e-06, \"loss\": 0.5455557041073916, \"step\": 639000}\n",
      "{\"learning_rate\": 5.96087921229542e-06, \"loss\": 0.5348212274466642, \"step\": 639500}\n",
      "{\"learning_rate\": 5.926446748817934e-06, \"loss\": 0.5742517018901417, \"step\": 640000}\n",
      "{\"learning_rate\": 5.892014285340448e-06, \"loss\": 0.5876892061325488, \"step\": 640500}\n",
      "{\"learning_rate\": 5.857581821862962e-06, \"loss\": 0.5700024946687045, \"step\": 641000}\n",
      "{\"learning_rate\": 5.823149358385476e-06, \"loss\": 0.6061459576959023, \"step\": 641500}\n",
      "{\"learning_rate\": 5.7887168949079895e-06, \"loss\": 0.5461924156948226, \"step\": 642000}\n",
      "{\"learning_rate\": 5.754284431430504e-06, \"loss\": 0.610712835331331, \"step\": 642500}\n",
      "{\"learning_rate\": 5.719851967953018e-06, \"loss\": 0.6208911028798902, \"step\": 643000}\n",
      "{\"learning_rate\": 5.685419504475531e-06, \"loss\": 0.5559441678824368, \"step\": 643500}\n",
      "{\"learning_rate\": 5.6509870409980456e-06, \"loss\": 0.570437217088649, \"step\": 644000}\n",
      "{\"learning_rate\": 5.61655457752056e-06, \"loss\": 0.5520843398737488, \"step\": 644500}\n",
      "{\"learning_rate\": 5.582122114043074e-06, \"loss\": 0.5972183843069943, \"step\": 645000}\n",
      "{\"learning_rate\": 5.547689650565588e-06, \"loss\": 0.5565973051575711, \"step\": 645500}\n",
      "{\"learning_rate\": 5.5132571870881025e-06, \"loss\": 0.572906697787228, \"step\": 646000}\n",
      "{\"learning_rate\": 5.478824723610616e-06, \"loss\": 0.5897245802253019, \"step\": 646500}\n",
      "{\"learning_rate\": 5.44439226013313e-06, \"loss\": 0.5548194567278261, \"step\": 647000}\n",
      "{\"learning_rate\": 5.409959796655644e-06, \"loss\": 0.5702141056173714, \"step\": 647500}\n",
      "{\"learning_rate\": 5.375527333178158e-06, \"loss\": 0.5201355313599343, \"step\": 648000}\n",
      "{\"learning_rate\": 5.341094869700672e-06, \"loss\": 0.6222538729573134, \"step\": 648500}\n",
      "{\"learning_rate\": 5.306662406223186e-06, \"loss\": 0.5757025522444165, \"step\": 649000}\n",
      "{\"learning_rate\": 5.2722299427457e-06, \"loss\": 0.530326606479357, \"step\": 649500}\n",
      "{\"learning_rate\": 5.237797479268214e-06, \"loss\": 0.6359486582237296, \"step\": 650000}\n",
      "{\"learning_rate\": 5.203365015790728e-06, \"loss\": 0.5410988981600385, \"step\": 650500}\n",
      "{\"learning_rate\": 5.168932552313242e-06, \"loss\": 0.5073169522890821, \"step\": 651000}\n",
      "{\"learning_rate\": 5.134500088835756e-06, \"loss\": 0.5864818545597372, \"step\": 651500}\n",
      "{\"learning_rate\": 5.10006762535827e-06, \"loss\": 0.5731994381393306, \"step\": 652000}\n",
      "{\"learning_rate\": 5.065635161880784e-06, \"loss\": 0.5741628965373384, \"step\": 652500}\n",
      "{\"learning_rate\": 5.031202698403297e-06, \"loss\": 0.5735690151804592, \"step\": 653000}\n",
      "{\"learning_rate\": 4.996770234925812e-06, \"loss\": 0.6064244355253177, \"step\": 653500}\n",
      "{\"learning_rate\": 4.962337771448326e-06, \"loss\": 0.5483588092630962, \"step\": 654000}\n",
      "{\"learning_rate\": 4.92790530797084e-06, \"loss\": 0.5899846002588747, \"step\": 654500}\n",
      "{\"learning_rate\": 4.893472844493354e-06, \"loss\": 0.5864079615726369, \"step\": 655000}\n",
      "{\"learning_rate\": 4.8590403810158686e-06, \"loss\": 0.5902195856579346, \"step\": 655500}\n",
      "{\"learning_rate\": 4.824607917538382e-06, \"loss\": 0.5661635727500542, \"step\": 656000}\n",
      "{\"learning_rate\": 4.790175454060896e-06, \"loss\": 0.5442690001956653, \"step\": 656500}\n",
      "{\"learning_rate\": 4.75574299058341e-06, \"loss\": 0.5381238783532754, \"step\": 657000}\n",
      "{\"learning_rate\": 4.721310527105924e-06, \"loss\": 0.5420861034583068, \"step\": 657500}\n",
      "{\"learning_rate\": 4.686878063628438e-06, \"loss\": 0.5863088120110332, \"step\": 658000}\n",
      "{\"learning_rate\": 4.652445600150952e-06, \"loss\": 0.5510336773560848, \"step\": 658500}\n",
      "{\"learning_rate\": 4.6180131366734665e-06, \"loss\": 0.5993687599364202, \"step\": 659000}\n",
      "{\"learning_rate\": 4.58358067319598e-06, \"loss\": 0.5810486363020027, \"step\": 659500}\n",
      "{\"learning_rate\": 4.549148209718494e-06, \"loss\": 0.6304881999741774, \"step\": 660000}\n",
      "{\"learning_rate\": 4.514715746241008e-06, \"loss\": 0.5788180605522357, \"step\": 660500}\n",
      "{\"learning_rate\": 4.480283282763522e-06, \"loss\": 0.5497851661086315, \"step\": 661000}\n",
      "{\"learning_rate\": 4.445850819286036e-06, \"loss\": 0.5601863146433607, \"step\": 661500}\n",
      "{\"learning_rate\": 4.41141835580855e-06, \"loss\": 0.5734661706708138, \"step\": 662000}\n",
      "{\"learning_rate\": 4.376985892331064e-06, \"loss\": 0.5768603790933267, \"step\": 662500}\n",
      "{\"learning_rate\": 4.342553428853579e-06, \"loss\": 0.5730312764632981, \"step\": 663000}\n",
      "{\"learning_rate\": 4.308120965376093e-06, \"loss\": 0.5949846790787997, \"step\": 663500}\n",
      "{\"learning_rate\": 4.273688501898606e-06, \"loss\": 0.5661482943404699, \"step\": 664000}\n",
      "{\"learning_rate\": 4.23925603842112e-06, \"loss\": 0.6122233553319238, \"step\": 664500}\n",
      "{\"learning_rate\": 4.204823574943635e-06, \"loss\": 0.5738613532128511, \"step\": 665000}\n",
      "{\"learning_rate\": 4.170391111466148e-06, \"loss\": 0.579770873911446, \"step\": 665500}\n",
      "{\"learning_rate\": 4.135958647988662e-06, \"loss\": 0.5581927438529674, \"step\": 666000}\n",
      "{\"learning_rate\": 4.1015261845111765e-06, \"loss\": 0.574841306806542, \"step\": 666500}\n",
      "{\"learning_rate\": 4.06709372103369e-06, \"loss\": 0.5939541587968125, \"step\": 667000}\n",
      "{\"learning_rate\": 4.032661257556204e-06, \"loss\": 0.5730136443930678, \"step\": 667500}\n",
      "{\"learning_rate\": 3.998228794078718e-06, \"loss\": 0.6151022010316374, \"step\": 668000}\n",
      "{\"learning_rate\": 3.963796330601232e-06, \"loss\": 0.5822346588332439, \"step\": 668500}\n",
      "{\"learning_rate\": 3.929363867123746e-06, \"loss\": 0.5349227763657691, \"step\": 669000}\n",
      "{\"learning_rate\": 3.89493140364626e-06, \"loss\": 0.5605614529881859, \"step\": 669500}\n",
      "{\"learning_rate\": 3.860498940168774e-06, \"loss\": 0.5909058139765402, \"step\": 670000}\n",
      "{\"learning_rate\": 3.826066476691289e-06, \"loss\": 0.5547452974531334, \"step\": 670500}\n",
      "{\"learning_rate\": 3.7916340132138024e-06, \"loss\": 0.5447483077945653, \"step\": 671000}\n",
      "{\"learning_rate\": 3.7572015497363166e-06, \"loss\": 0.5832635954129509, \"step\": 671500}\n",
      "{\"learning_rate\": 3.72276908625883e-06, \"loss\": 0.5512533159414307, \"step\": 672000}\n",
      "{\"learning_rate\": 3.6883366227813443e-06, \"loss\": 0.587963238839875, \"step\": 672500}\n",
      "{\"learning_rate\": 3.6539041593038585e-06, \"loss\": 0.5858842322049895, \"step\": 673000}\n",
      "{\"learning_rate\": 3.6194716958263723e-06, \"loss\": 0.6679722924123053, \"step\": 673500}\n",
      "{\"learning_rate\": 3.5850392323488865e-06, \"loss\": 0.531781994981924, \"step\": 674000}\n",
      "{\"learning_rate\": 3.5506067688714007e-06, \"loss\": 0.5402037419998087, \"step\": 674500}\n",
      "{\"learning_rate\": 3.516174305393914e-06, \"loss\": 0.5194019186941441, \"step\": 675000}\n",
      "{\"learning_rate\": 3.4817418419164283e-06, \"loss\": 0.5577406639090041, \"step\": 675500}\n",
      "{\"learning_rate\": 3.4473093784389426e-06, \"loss\": 0.5865061349521856, \"step\": 676000}\n",
      "{\"learning_rate\": 3.4128769149614564e-06, \"loss\": 0.5430454042430501, \"step\": 676500}\n",
      "{\"learning_rate\": 3.3784444514839706e-06, \"loss\": 0.5588614855466876, \"step\": 677000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 3.344011988006485e-06, \"loss\": 0.560349117259495, \"step\": 677500}\n",
      "{\"learning_rate\": 3.3095795245289982e-06, \"loss\": 0.5806249769571005, \"step\": 678000}\n",
      "{\"learning_rate\": 3.2751470610515124e-06, \"loss\": 0.5890685299703619, \"step\": 678500}\n",
      "{\"learning_rate\": 3.2407145975740267e-06, \"loss\": 0.5909782031949143, \"step\": 679000}\n",
      "{\"learning_rate\": 3.206282134096541e-06, \"loss\": 0.5904643914634362, \"step\": 679500}\n",
      "{\"learning_rate\": 3.1718496706190543e-06, \"loss\": 0.5651151937035611, \"step\": 680000}\n",
      "{\"learning_rate\": 3.1374172071415685e-06, \"loss\": 0.5581625293799444, \"step\": 680500}\n",
      "{\"learning_rate\": 3.1029847436640823e-06, \"loss\": 0.5478057687387337, \"step\": 681000}\n",
      "{\"learning_rate\": 3.0685522801865965e-06, \"loss\": 0.5834472351633012, \"step\": 681500}\n",
      "{\"learning_rate\": 3.0341198167091108e-06, \"loss\": 0.5534010106247151, \"step\": 682000}\n",
      "{\"learning_rate\": 2.9996873532316246e-06, \"loss\": 0.5607153835395584, \"step\": 682500}\n",
      "{\"learning_rate\": 2.965254889754139e-06, \"loss\": 0.5828290796492948, \"step\": 683000}\n",
      "{\"learning_rate\": 2.9308224262766526e-06, \"loss\": 0.5432633857183391, \"step\": 683500}\n",
      "{\"learning_rate\": 2.8963899627991664e-06, \"loss\": 0.5777966255323262, \"step\": 684000}\n",
      "{\"learning_rate\": 2.8619574993216806e-06, \"loss\": 0.5786646025188966, \"step\": 684500}\n",
      "{\"learning_rate\": 2.8275250358441944e-06, \"loss\": 0.5611366679543862, \"step\": 685000}\n",
      "{\"learning_rate\": 2.7930925723667087e-06, \"loss\": 0.574029546577949, \"step\": 685500}\n",
      "{\"learning_rate\": 2.758660108889223e-06, \"loss\": 0.5641550218610791, \"step\": 686000}\n",
      "{\"learning_rate\": 2.7242276454117367e-06, \"loss\": 0.5366716003195615, \"step\": 686500}\n",
      "{\"learning_rate\": 2.689795181934251e-06, \"loss\": 0.5554740983301308, \"step\": 687000}\n",
      "{\"learning_rate\": 2.6553627184567647e-06, \"loss\": 0.5606342261424289, \"step\": 687500}\n",
      "{\"learning_rate\": 2.6209302549792785e-06, \"loss\": 0.5428155110306107, \"step\": 688000}\n",
      "{\"learning_rate\": 2.5864977915017928e-06, \"loss\": 0.5872041458875173, \"step\": 688500}\n",
      "{\"learning_rate\": 2.5520653280243066e-06, \"loss\": 0.5605500020483741, \"step\": 689000}\n",
      "{\"learning_rate\": 2.5176328645468204e-06, \"loss\": 0.5944829807634232, \"step\": 689500}\n",
      "{\"learning_rate\": 2.4832004010693346e-06, \"loss\": 0.5024917047418421, \"step\": 690000}\n",
      "{\"learning_rate\": 2.448767937591849e-06, \"loss\": 0.5628389468828682, \"step\": 690500}\n",
      "{\"learning_rate\": 2.4143354741143626e-06, \"loss\": 0.5762383389733732, \"step\": 691000}\n",
      "{\"learning_rate\": 2.379903010636877e-06, \"loss\": 0.5982950307896826, \"step\": 691500}\n",
      "{\"learning_rate\": 2.3454705471593907e-06, \"loss\": 0.5730551298562204, \"step\": 692000}\n",
      "{\"learning_rate\": 2.311038083681905e-06, \"loss\": 0.5682387147170957, \"step\": 692500}\n",
      "{\"learning_rate\": 2.2766056202044187e-06, \"loss\": 0.5712914557848126, \"step\": 693000}\n",
      "{\"learning_rate\": 2.2421731567269325e-06, \"loss\": 0.5218950032691937, \"step\": 693500}\n",
      "{\"learning_rate\": 2.2077406932494467e-06, \"loss\": 0.5658754162814003, \"step\": 694000}\n",
      "{\"learning_rate\": 2.173308229771961e-06, \"loss\": 0.5973453066981165, \"step\": 694500}\n",
      "{\"learning_rate\": 2.1388757662944748e-06, \"loss\": 0.4976495967763476, \"step\": 695000}\n",
      "{\"learning_rate\": 2.104443302816989e-06, \"loss\": 0.5282720869908808, \"step\": 695500}\n",
      "{\"learning_rate\": 2.0700108393395028e-06, \"loss\": 0.5458648124953034, \"step\": 696000}\n",
      "{\"learning_rate\": 2.0355783758620166e-06, \"loss\": 0.546806859025266, \"step\": 696500}\n",
      "{\"learning_rate\": 2.001145912384531e-06, \"loss\": 0.5599047064495971, \"step\": 697000}\n",
      "{\"learning_rate\": 1.9667134489070446e-06, \"loss\": 0.6020093977425713, \"step\": 697500}\n",
      "{\"learning_rate\": 1.932280985429559e-06, \"loss\": 0.5525325202004752, \"step\": 698000}\n",
      "{\"learning_rate\": 1.8978485219520729e-06, \"loss\": 0.5664484352446161, \"step\": 698500}\n",
      "{\"learning_rate\": 1.8634160584745867e-06, \"loss\": 0.5500879344056593, \"step\": 699000}\n",
      "{\"learning_rate\": 1.828983594997101e-06, \"loss\": 0.5518995322400005, \"step\": 699500}\n",
      "{\"learning_rate\": 1.794551131519615e-06, \"loss\": 0.5653593736578477, \"step\": 700000}\n",
      "{\"learning_rate\": 1.7601186680421287e-06, \"loss\": 0.5636689295271644, \"step\": 700500}\n",
      "{\"learning_rate\": 1.725686204564643e-06, \"loss\": 0.5705842984280316, \"step\": 701000}\n",
      "{\"learning_rate\": 1.6912537410871568e-06, \"loss\": 0.539999537217198, \"step\": 701500}\n",
      "{\"learning_rate\": 1.656821277609671e-06, \"loss\": 0.5318424529430922, \"step\": 702000}\n",
      "{\"learning_rate\": 1.622388814132185e-06, \"loss\": 0.6069643505507847, \"step\": 702500}\n",
      "{\"learning_rate\": 1.5879563506546988e-06, \"loss\": 0.5757566356058232, \"step\": 703000}\n",
      "{\"learning_rate\": 1.5535238871772128e-06, \"loss\": 0.6190000961236656, \"step\": 703500}\n",
      "{\"learning_rate\": 1.519091423699727e-06, \"loss\": 0.5236647480347892, \"step\": 704000}\n",
      "{\"learning_rate\": 1.484658960222241e-06, \"loss\": 0.5340203497633338, \"step\": 704500}\n",
      "{\"learning_rate\": 1.4502264967447549e-06, \"loss\": 0.5602040187427774, \"step\": 705000}\n",
      "{\"learning_rate\": 1.4157940332672689e-06, \"loss\": 0.5623891432713717, \"step\": 705500}\n",
      "{\"learning_rate\": 1.381361569789783e-06, \"loss\": 0.5613245598919456, \"step\": 706000}\n",
      "{\"learning_rate\": 1.3469291063122971e-06, \"loss\": 0.5793514884629986, \"step\": 706500}\n",
      "{\"learning_rate\": 1.312496642834811e-06, \"loss\": 0.5348774174702121, \"step\": 707000}\n",
      "{\"learning_rate\": 1.278064179357325e-06, \"loss\": 0.5059673620229587, \"step\": 707500}\n",
      "{\"learning_rate\": 1.243631715879839e-06, \"loss\": 0.5466203971368959, \"step\": 708000}\n",
      "{\"learning_rate\": 1.2091992524023532e-06, \"loss\": 0.5455774619935546, \"step\": 708500}\n",
      "{\"learning_rate\": 1.174766788924867e-06, \"loss\": 0.5832618279872694, \"step\": 709000}\n",
      "{\"learning_rate\": 1.140334325447381e-06, \"loss\": 0.5337609754547011, \"step\": 709500}\n",
      "{\"learning_rate\": 1.105901861969895e-06, \"loss\": 0.6089713303672616, \"step\": 710000}\n",
      "{\"learning_rate\": 1.0714693984924092e-06, \"loss\": 0.5684837141258177, \"step\": 710500}\n",
      "{\"learning_rate\": 1.037036935014923e-06, \"loss\": 0.5642995040249079, \"step\": 711000}\n",
      "{\"learning_rate\": 1.002604471537437e-06, \"loss\": 0.5355785913931904, \"step\": 711500}\n",
      "{\"learning_rate\": 9.68172008059951e-07, \"loss\": 0.5772400925866096, \"step\": 712000}\n",
      "{\"learning_rate\": 9.33739544582465e-07, \"loss\": 0.5202876893357606, \"step\": 712500}\n",
      "{\"learning_rate\": 8.993070811049791e-07, \"loss\": 0.5132178649350535, \"step\": 713000}\n",
      "{\"learning_rate\": 8.648746176274931e-07, \"loss\": 0.5190637770033208, \"step\": 713500}\n",
      "{\"learning_rate\": 8.304421541500071e-07, \"loss\": 0.5092505473465426, \"step\": 714000}\n",
      "{\"learning_rate\": 7.960096906725211e-07, \"loss\": 0.6059916699900059, \"step\": 714500}\n",
      "{\"learning_rate\": 7.615772271950352e-07, \"loss\": 0.5666250154360896, \"step\": 715000}\n",
      "{\"learning_rate\": 7.271447637175492e-07, \"loss\": 0.5431840444405097, \"step\": 715500}\n",
      "{\"learning_rate\": 6.927123002400631e-07, \"loss\": 0.5764892400571844, \"step\": 716000}\n",
      "{\"learning_rate\": 6.582798367625772e-07, \"loss\": 0.613030456579756, \"step\": 716500}\n",
      "{\"learning_rate\": 6.238473732850911e-07, \"loss\": 0.5542300376986387, \"step\": 717000}\n",
      "{\"learning_rate\": 5.894149098076053e-07, \"loss\": 0.5672023222460412, \"step\": 717500}\n",
      "{\"learning_rate\": 5.549824463301192e-07, \"loss\": 0.5715626493138262, \"step\": 718000}\n",
      "{\"learning_rate\": 5.205499828526332e-07, \"loss\": 0.5576800559628755, \"step\": 718500}\n",
      "{\"learning_rate\": 4.861175193751472e-07, \"loss\": 0.5543340572675224, \"step\": 719000}\n",
      "{\"learning_rate\": 4.516850558976612e-07, \"loss\": 0.5686204679736402, \"step\": 719500}\n",
      "{\"learning_rate\": 4.1725259242017523e-07, \"loss\": 0.5783776227285853, \"step\": 720000}\n",
      "{\"learning_rate\": 3.8282012894268925e-07, \"loss\": 0.5286025959716644, \"step\": 720500}\n",
      "{\"learning_rate\": 3.4838766546520326e-07, \"loss\": 0.5597958910847083, \"step\": 721000}\n",
      "{\"learning_rate\": 3.139552019877173e-07, \"loss\": 0.5430868841795018, \"step\": 721500}\n",
      "{\"learning_rate\": 2.7952273851023124e-07, \"loss\": 0.5539126639041351, \"step\": 722000}\n",
      "{\"learning_rate\": 2.4509027503274526e-07, \"loss\": 0.5557718194886111, \"step\": 722500}\n",
      "{\"learning_rate\": 2.1065781155525928e-07, \"loss\": 0.5385798432304291, \"step\": 723000}\n",
      "{\"learning_rate\": 1.7622534807777332e-07, \"loss\": 0.5336881401162827, \"step\": 723500}\n",
      "{\"learning_rate\": 1.417928846002873e-07, \"loss\": 0.58419080840901, \"step\": 724000}\n",
      "{\"learning_rate\": 1.0736042112280131e-07, \"loss\": 0.5669754602024332, \"step\": 724500}\n",
      "{\"learning_rate\": 7.292795764531533e-08, \"loss\": 0.560460108233965, \"step\": 725000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"learning_rate\": 3.8495494167829335e-08, \"loss\": 0.5429929321088129, \"step\": 725500}\n",
      "{\"learning_rate\": 4.063030690343347e-09, \"loss\": 0.5804766270373948, \"step\": 726000}\n",
      "\n",
      "\n",
      "CPU times: user 1d 14h 18min 28s, sys: 4min 12s, total: 1d 14h 22min 40s\n",
      "Wall time: 1d 14h 17min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=726059, training_loss=0.7227578997399938)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ZkooHz1-_2h"
   },
   "source": [
    "#### Save final model (+ tokenizer + config) to disk\n",
    "\n",
    "For the paper, the saved model is in directory './models':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QDNgPls7_l13"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"./model_bert\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "01_how-to-train.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "016d7c8318f742c1943464b08232a510": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04e7e6d291da49d5816dc98a2904e95c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39c23c6a972b419eb2eeeebafeaedc22",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8388e9da9da4492c98c19235ca5fc1b5",
      "value": " 15228/15228 [2:46:46&lt;00:00,  1.52it/s]"
     }
    },
    "0989d41a4da24e9ebff377e02127642c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d295dd80550447d88da0f04ce36a22ff",
       "IPY_MODEL_04e7e6d291da49d5816dc98a2904e95c"
      ],
      "layout": "IPY_MODEL_42c6061ef7e44f179db5a6e3551c0f17"
     }
    },
    "39c23c6a972b419eb2eeeebafeaedc22": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40bf955ba0284e84b198da6be8654219": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "42c6061ef7e44f179db5a6e3551c0f17": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6feb10aeb43147e6aba028d065947ae8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "837c9ddc3d594e088891874560c646b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Epoch: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe20a8dae6e84628b5076d02183090f5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40bf955ba0284e84b198da6be8654219",
      "value": 1
     }
    },
    "8388e9da9da4492c98c19235ca5fc1b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93b3f9eae3cb4e3e859cf456e3547c6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a491e8caa0a048beb3b5259f14eb233f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a58a66392b644b1384661e850c077a6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_837c9ddc3d594e088891874560c646b8",
       "IPY_MODEL_dbf50873d62c4ba39321faefbed0cca5"
      ],
      "layout": "IPY_MODEL_a491e8caa0a048beb3b5259f14eb233f"
     }
    },
    "d295dd80550447d88da0f04ce36a22ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Iteration: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_016d7c8318f742c1943464b08232a510",
      "max": 15228,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7d8c3a4fecd40778e32966b29ea65a1",
      "value": 15228
     }
    },
    "dbf50873d62c4ba39321faefbed0cca5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6feb10aeb43147e6aba028d065947ae8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_93b3f9eae3cb4e3e859cf456e3547c6d",
      "value": " 1/1 [2:46:46&lt;00:00, 10006.17s/it]"
     }
    },
    "e7d8c3a4fecd40778e32966b29ea65a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fe20a8dae6e84628b5076d02183090f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
