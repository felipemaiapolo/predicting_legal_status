{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning classifiers (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run -i 'random_state.py'\n",
    "from packages import *\n",
    "from clean_functions import *\n",
    "from tokenizer import *\n",
    "from tuners import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyper_mlp = {'neurons': [10, 25, 50, 75, 100, 150, 200], #hidden LSTM\n",
    "             'lamb1': [.0, 10**-6, 5*10**-6, 10**-5, 5*10**-5, 10**-4, 5*10**-4, 10**-3, 5*10**-3], #regularization\n",
    "             'lamb2': [.0, 10**-6, 5*10**-6, 10**-5, 5*10**-5, 10**-4, 5*10**-4, 10**-3, 5*10**-3],\n",
    "             'score': [0], \n",
    "             'lower_ci': [0], \n",
    "             'upper_ci': [0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V/MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y=np.load('data/X_w2v.npy'),np.load('data/y_w2v.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N=np.sum(X[:,:,:,0]!=0, axis=2)\n",
    "N=np.expand_dims(N, axis=2)\n",
    "N[N==0]=1\n",
    "X=np.sum(X, axis=2)\n",
    "X=X/N\n",
    "X=X.reshape((X.shape[0],-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning y into numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode={'H:Arquivado': 1,'H:Ativo': 2,'H:Suspenso': 3}\n",
    "decode={1:'H:Arquivado',2:'H:Ativo',3:'H:Suspenso'}\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y[i]=encode[y[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset in train, test and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4514, 500), (4514,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=2/3, random_state=random_seed)\n",
    "\n",
    "y_train2=np.array(pd.get_dummies(y_train))\n",
    "y_val2=np.array(pd.get_dummies(y_val))\n",
    "y_test2=np.array(pd.get_dummies(y_test))\n",
    "\n",
    "np.shape(X_train),np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper=expand_grid(hyper_mlp.copy(), random_seed=random_seed)\n",
    "hyper=hyper[['neurons','lamb1','lamb2','score','lower_ci','upper_ci']]\n",
    "\n",
    "np.shape(hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:21<00:00,  4.04s/it]\n"
     ]
    }
   ],
   "source": [
    "hyper=tune_mlp(hyper, X_train, y_train2, X_val, y_val2)\n",
    "hyper.to_csv('hyper/hyper_mlp_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neurons</th>\n",
       "      <th>lamb1</th>\n",
       "      <th>lamb2</th>\n",
       "      <th>score</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.902326</td>\n",
       "      <td>0.879414</td>\n",
       "      <td>0.925237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.902326</td>\n",
       "      <td>0.879414</td>\n",
       "      <td>0.925237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.902326</td>\n",
       "      <td>0.879414</td>\n",
       "      <td>0.925237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.903876</td>\n",
       "      <td>0.881128</td>\n",
       "      <td>0.926624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.903876</td>\n",
       "      <td>0.881128</td>\n",
       "      <td>0.926624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.905426</td>\n",
       "      <td>0.882843</td>\n",
       "      <td>0.928010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.905426</td>\n",
       "      <td>0.882843</td>\n",
       "      <td>0.928010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.905426</td>\n",
       "      <td>0.882843</td>\n",
       "      <td>0.928010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.905426</td>\n",
       "      <td>0.882843</td>\n",
       "      <td>0.928010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.905426</td>\n",
       "      <td>0.882843</td>\n",
       "      <td>0.928010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.884560</td>\n",
       "      <td>0.929393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.884560</td>\n",
       "      <td>0.929393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.908527</td>\n",
       "      <td>0.886279</td>\n",
       "      <td>0.930775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.908527</td>\n",
       "      <td>0.886279</td>\n",
       "      <td>0.930775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.908527</td>\n",
       "      <td>0.886279</td>\n",
       "      <td>0.930775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.910078</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.932155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.910078</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.932155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.910078</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.932155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.910078</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.932155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.893175</td>\n",
       "      <td>0.936282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neurons     lamb1     lamb2     score  lower_ci  upper_ci\n",
       "10       75  0.000000  0.000001  0.902326  0.879414  0.925237\n",
       "17       50  0.000050  0.000050  0.902326  0.879414  0.925237\n",
       "23      100  0.000010  0.000001  0.902326  0.879414  0.925237\n",
       "39       75  0.000001  0.000005  0.903876  0.881128  0.926624\n",
       "38       25  0.000005  0.000010  0.903876  0.881128  0.926624\n",
       "40       25  0.000010  0.000010  0.905426  0.882843  0.928010\n",
       "22      150  0.000100  0.000050  0.905426  0.882843  0.928010\n",
       "19       75  0.000050  0.000010  0.905426  0.882843  0.928010\n",
       "32      200  0.000050  0.000001  0.905426  0.882843  0.928010\n",
       "28      200  0.000100  0.000100  0.905426  0.882843  0.928010\n",
       "31       50  0.000050  0.000100  0.906977  0.884560  0.929393\n",
       "9        10  0.000500  0.000100  0.906977  0.884560  0.929393\n",
       "37       25  0.000100  0.000001  0.908527  0.886279  0.930775\n",
       "21       25  0.000050  0.000100  0.908527  0.886279  0.930775\n",
       "24       10  0.000010  0.000001  0.908527  0.886279  0.930775\n",
       "30       10  0.000100  0.000001  0.910078  0.888000  0.932155\n",
       "8        75  0.000005  0.000100  0.910078  0.888000  0.932155\n",
       "1        10  0.000010  0.000010  0.910078  0.888000  0.932155\n",
       "13      200  0.000100  0.000001  0.910078  0.888000  0.932155\n",
       "5       200  0.000100  0.000010  0.914729  0.893175  0.936282"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper.iloc[np.argsort(hyper.loc[:,'score']),:].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT/MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = np.load('data/X_bert.npy'),np.load('data/y_bert.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=X.reshape((X.shape[0],-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning y into numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode={'H:Arquivado': 1,'H:Ativo': 2,'H:Suspenso': 3}\n",
    "decode={1:'H:Arquivado',2:'H:Ativo',3:'H:Suspenso'}\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y[i]=encode[y[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset in train, test and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4514, 3840), (4514,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=2/3, random_state=random_seed)\n",
    "\n",
    "y_train2=np.array(pd.get_dummies(y_train))\n",
    "y_val2=np.array(pd.get_dummies(y_val))\n",
    "y_test2=np.array(pd.get_dummies(y_test))\n",
    "\n",
    "np.shape(X_train),np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper=expand_grid(hyper_mlp.copy(), random_seed=random_seed)\n",
    "hyper=hyper[['neurons','lamb1','lamb2','score','lower_ci','upper_ci']]\n",
    "\n",
    "np.shape(hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [06:32<00:00,  7.85s/it]\n"
     ]
    }
   ],
   "source": [
    "hyper=tune_mlp(hyper, X_train, y_train2, X_val, y_val2)\n",
    "hyper.to_csv('hyper/hyper_mlp_bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neurons</th>\n",
       "      <th>lamb1</th>\n",
       "      <th>lamb2</th>\n",
       "      <th>score</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.884560</td>\n",
       "      <td>0.929393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.908527</td>\n",
       "      <td>0.886279</td>\n",
       "      <td>0.930775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.908527</td>\n",
       "      <td>0.886279</td>\n",
       "      <td>0.930775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.911628</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.933533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.911628</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.933533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.911628</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.933533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.913178</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.934909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913178</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.934909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.913178</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.934909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.893175</td>\n",
       "      <td>0.936282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.893175</td>\n",
       "      <td>0.936282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.916279</td>\n",
       "      <td>0.894904</td>\n",
       "      <td>0.937654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.916279</td>\n",
       "      <td>0.894904</td>\n",
       "      <td>0.937654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.916279</td>\n",
       "      <td>0.894904</td>\n",
       "      <td>0.937654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.916279</td>\n",
       "      <td>0.894904</td>\n",
       "      <td>0.937654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.896635</td>\n",
       "      <td>0.939024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.896635</td>\n",
       "      <td>0.939024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.919380</td>\n",
       "      <td>0.898369</td>\n",
       "      <td>0.940391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.919380</td>\n",
       "      <td>0.898369</td>\n",
       "      <td>0.940391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.920930</td>\n",
       "      <td>0.900105</td>\n",
       "      <td>0.941756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neurons     lamb1     lamb2     score  lower_ci  upper_ci\n",
       "14       50  0.000001  0.001000  0.906977  0.884560  0.929393\n",
       "5       200  0.000100  0.000010  0.908527  0.886279  0.930775\n",
       "29       50  0.000001  0.000005  0.908527  0.886279  0.930775\n",
       "12       75  0.000001  0.000010  0.911628  0.889723  0.933533\n",
       "38       25  0.000005  0.000010  0.911628  0.889723  0.933533\n",
       "19       75  0.000050  0.000010  0.911628  0.889723  0.933533\n",
       "23      100  0.000010  0.000001  0.913178  0.891448  0.934909\n",
       "44       25  0.000010  0.000000  0.913178  0.891448  0.934909\n",
       "46      150  0.000005  0.000010  0.913178  0.891448  0.934909\n",
       "31       50  0.000050  0.000100  0.914729  0.893175  0.936282\n",
       "32      200  0.000050  0.000001  0.914729  0.893175  0.936282\n",
       "42      100  0.000010  0.000005  0.916279  0.894904  0.937654\n",
       "49      150  0.000001  0.000001  0.916279  0.894904  0.937654\n",
       "8        75  0.000005  0.000100  0.916279  0.894904  0.937654\n",
       "13      200  0.000100  0.000001  0.916279  0.894904  0.937654\n",
       "40       25  0.000010  0.000010  0.917829  0.896635  0.939024\n",
       "11       50  0.000000  0.000050  0.917829  0.896635  0.939024\n",
       "36      200  0.000000  0.000050  0.919380  0.898369  0.940391\n",
       "1        10  0.000010  0.000010  0.919380  0.898369  0.940391\n",
       "28      200  0.000100  0.000100  0.920930  0.900105  0.941756"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper.iloc[np.argsort(hyper.loc[:,'score']),:].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec/MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y=np.load('data/X_d2v.npy'),np.load('data/y_d2v.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=X.reshape((X.shape[0],-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning y into numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode={'H:Arquivado': 1,'H:Ativo': 2,'H:Suspenso': 3}\n",
    "decode={1:'H:Arquivado',2:'H:Ativo',3:'H:Suspenso'}\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y[i]=encode[y[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset in train, test and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4514, 500), (4514,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=2/3, random_state=random_seed)\n",
    "\n",
    "y_train2=np.array(pd.get_dummies(y_train))\n",
    "y_val2=np.array(pd.get_dummies(y_val))\n",
    "y_test2=np.array(pd.get_dummies(y_test))\n",
    "\n",
    "np.shape(X_train),np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper=expand_grid(hyper_mlp.copy(), random_seed=random_seed)\n",
    "hyper=hyper[['neurons','lamb1','lamb2','score','lower_ci','upper_ci']]\n",
    "\n",
    "np.shape(hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:28<00:00,  4.17s/it]\n"
     ]
    }
   ],
   "source": [
    "hyper=tune_mlp(hyper, X_train, y_train2, X_val, y_val2)\n",
    "hyper.to_csv('hyper/hyper_mlp_d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neurons</th>\n",
       "      <th>lamb1</th>\n",
       "      <th>lamb2</th>\n",
       "      <th>score</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.784496</td>\n",
       "      <td>0.752764</td>\n",
       "      <td>0.816228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.784496</td>\n",
       "      <td>0.752764</td>\n",
       "      <td>0.816228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.784496</td>\n",
       "      <td>0.752764</td>\n",
       "      <td>0.816228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.786047</td>\n",
       "      <td>0.754398</td>\n",
       "      <td>0.817696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.786047</td>\n",
       "      <td>0.754398</td>\n",
       "      <td>0.817696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.786047</td>\n",
       "      <td>0.754398</td>\n",
       "      <td>0.817696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.786047</td>\n",
       "      <td>0.754398</td>\n",
       "      <td>0.817696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.786047</td>\n",
       "      <td>0.754398</td>\n",
       "      <td>0.817696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.786047</td>\n",
       "      <td>0.754398</td>\n",
       "      <td>0.817696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.787597</td>\n",
       "      <td>0.756032</td>\n",
       "      <td>0.819162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.787597</td>\n",
       "      <td>0.756032</td>\n",
       "      <td>0.819162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.787597</td>\n",
       "      <td>0.756032</td>\n",
       "      <td>0.819162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.789147</td>\n",
       "      <td>0.757667</td>\n",
       "      <td>0.820628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.759302</td>\n",
       "      <td>0.822093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.759302</td>\n",
       "      <td>0.822093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.792248</td>\n",
       "      <td>0.760938</td>\n",
       "      <td>0.823558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.793798</td>\n",
       "      <td>0.762575</td>\n",
       "      <td>0.825022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.793798</td>\n",
       "      <td>0.762575</td>\n",
       "      <td>0.825022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.793798</td>\n",
       "      <td>0.762575</td>\n",
       "      <td>0.825022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.767490</td>\n",
       "      <td>0.829409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neurons     lamb1     lamb2     score  lower_ci  upper_ci\n",
       "9        10  0.000500  0.000100  0.784496  0.752764  0.816228\n",
       "5       200  0.000100  0.000010  0.784496  0.752764  0.816228\n",
       "47      100  0.001000  0.001000  0.784496  0.752764  0.816228\n",
       "37       25  0.000100  0.000001  0.786047  0.754398  0.817696\n",
       "8        75  0.000005  0.000100  0.786047  0.754398  0.817696\n",
       "30       10  0.000100  0.000001  0.786047  0.754398  0.817696\n",
       "40       25  0.000010  0.000010  0.786047  0.754398  0.817696\n",
       "10       75  0.000000  0.000001  0.786047  0.754398  0.817696\n",
       "46      150  0.000005  0.000010  0.786047  0.754398  0.817696\n",
       "49      150  0.000001  0.000001  0.787597  0.756032  0.819162\n",
       "22      150  0.000100  0.000050  0.787597  0.756032  0.819162\n",
       "38       25  0.000005  0.000010  0.787597  0.756032  0.819162\n",
       "1        10  0.000010  0.000010  0.789147  0.757667  0.820628\n",
       "20       10  0.000000  0.000005  0.790698  0.759302  0.822093\n",
       "24       10  0.000010  0.000001  0.790698  0.759302  0.822093\n",
       "28      200  0.000100  0.000100  0.792248  0.760938  0.823558\n",
       "32      200  0.000050  0.000001  0.793798  0.762575  0.825022\n",
       "26       50  0.000500  0.000010  0.793798  0.762575  0.825022\n",
       "23      100  0.000010  0.000001  0.793798  0.762575  0.825022\n",
       "13      200  0.000100  0.000001  0.798450  0.767490  0.829409"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper.iloc[np.argsort(hyper.loc[:,'score']),:].tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF/MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y=np.load('data/X_tfidf.npy'),np.load('data/y_tfidf.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=X.reshape((X.shape[0],-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning y into numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode={'H:Arquivado': 1,'H:Ativo': 2,'H:Suspenso': 3}\n",
    "decode={1:'H:Arquivado',2:'H:Ativo',3:'H:Suspenso'}\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y[i]=encode[y[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset in train, test and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4514, 20000), (4514,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=2/3, random_state=random_seed)\n",
    "\n",
    "y_train2=np.array(pd.get_dummies(y_train))\n",
    "y_val2=np.array(pd.get_dummies(y_val))\n",
    "y_test2=np.array(pd.get_dummies(y_test))\n",
    "\n",
    "np.shape(X_train),np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper=expand_grid(hyper_mlp.copy(), random_seed=random_seed)\n",
    "hyper=hyper[['neurons','lamb1','lamb2','score','lower_ci','upper_ci']]\n",
    "\n",
    "np.shape(hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [30:46<00:00, 36.93s/it]\n"
     ]
    }
   ],
   "source": [
    "hyper=tune_mlp(hyper, X_train, y_train2, X_val, y_val2)\n",
    "hyper.to_csv('hyper/hyper_mlp_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neurons</th>\n",
       "      <th>lamb1</th>\n",
       "      <th>lamb2</th>\n",
       "      <th>score</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>upper_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.910078</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.932155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.911628</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.933533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.911628</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.933533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.911628</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.933533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.911628</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.933533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.911628</td>\n",
       "      <td>0.889723</td>\n",
       "      <td>0.933533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.913178</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.934909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.913178</td>\n",
       "      <td>0.891448</td>\n",
       "      <td>0.934909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>150</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.893175</td>\n",
       "      <td>0.936282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.893175</td>\n",
       "      <td>0.936282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.893175</td>\n",
       "      <td>0.936282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.893175</td>\n",
       "      <td>0.936282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.893175</td>\n",
       "      <td>0.936282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>150</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.893175</td>\n",
       "      <td>0.936282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.916279</td>\n",
       "      <td>0.894904</td>\n",
       "      <td>0.937654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.896635</td>\n",
       "      <td>0.939024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.896635</td>\n",
       "      <td>0.939024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.896635</td>\n",
       "      <td>0.939024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.917829</td>\n",
       "      <td>0.896635</td>\n",
       "      <td>0.939024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.920930</td>\n",
       "      <td>0.900105</td>\n",
       "      <td>0.941756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    neurons     lamb1     lamb2     score  lower_ci  upper_ci\n",
       "24       10  0.000010  0.000001  0.910078  0.888000  0.932155\n",
       "31       50  0.000050  0.000100  0.911628  0.889723  0.933533\n",
       "5       200  0.000100  0.000010  0.911628  0.889723  0.933533\n",
       "13      200  0.000100  0.000001  0.911628  0.889723  0.933533\n",
       "14       50  0.000001  0.001000  0.911628  0.889723  0.933533\n",
       "0        25  0.000050  0.000500  0.911628  0.889723  0.933533\n",
       "21       25  0.000050  0.000100  0.913178  0.891448  0.934909\n",
       "3       150  0.000001  0.001000  0.913178  0.891448  0.934909\n",
       "35      150  0.000100  0.000500  0.914729  0.893175  0.936282\n",
       "17       50  0.000050  0.000050  0.914729  0.893175  0.936282\n",
       "27       75  0.000005  0.001000  0.914729  0.893175  0.936282\n",
       "6        75  0.001000  0.000000  0.914729  0.893175  0.936282\n",
       "47      100  0.001000  0.001000  0.914729  0.893175  0.936282\n",
       "25      150  0.001000  0.000500  0.914729  0.893175  0.936282\n",
       "48       50  0.000500  0.000500  0.916279  0.894904  0.937654\n",
       "18       25  0.001000  0.000050  0.917829  0.896635  0.939024\n",
       "33       50  0.001000  0.000010  0.917829  0.896635  0.939024\n",
       "9        10  0.000500  0.000100  0.917829  0.896635  0.939024\n",
       "45      100  0.000500  0.001000  0.917829  0.896635  0.939024\n",
       "26       50  0.000500  0.000010  0.920930  0.900105  0.941756"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper.iloc[np.argsort(hyper.loc[:,'score']),:].tail(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
